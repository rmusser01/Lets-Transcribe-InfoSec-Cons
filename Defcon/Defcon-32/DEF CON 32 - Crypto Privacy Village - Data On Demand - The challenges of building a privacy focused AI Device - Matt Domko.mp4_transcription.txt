{
  "webpage_url": "local:1731819595:c1aa335e:DEF CON 32 - Crypto Privacy Village - Data On Demand - The challenges of building a privacy focused AI Device - Matt Domko.mp4",
  "title": "DEF CON 32 - Crypto Privacy Village - Data On Demand - The challenges of building a privacy focused AI Device - Matt Domko.mp4",
  "description": "Local file",
  "channel_url": null,
  "duration": null,
  "channel": null,
  "uploader": null,
  "upload_date": null
}

0.00s - 6.00s | This text was transcribed using whisper model: large-v2

 So, hi, everybody. My name is Matt Domko. I don't know who that was, but they're my
6.00s - 11.96s |  new best friend. So, you are at Data on Demand, the Challenges of Building a Privacy-Focused
11.96s - 23.28s |  AI Device. And in reality, what I want to talk about is I am a consumer and also a supporter
23.28s - 30.78s |  of the AI magical things. And if I have the one that I work on at work or if I have one
30.78s - 34.22s |  from somebody else, there are just certain things that I really want to make sure that
34.22s - 40.86s |  they happen. And that's kind of the goal of this thing. So, I do have a job. They pay
40.86s - 47.84s |  me to do stuff. These are my thoughts, things in my brain that I wrote down in order to
47.88s - 57.28s |  make a device safer. But this is not the thoughts and ideas of my company. My company. The
57.28s - 62.66s |  company I work at. So, I'm into 3D printing, laser cutting, cosplay, mostly steampunk
62.66s - 67.80s |  stuff. If you ever want to nerd out about any of that or just security education in general,
67.80s - 73.76s |  I'm super, super into it. I'm also the director of fun at Tynes, if anybody's familiar with
73.76s - 81.00s |  Tynes. It's an unofficial title and they don't pay me. But I'm the director of fun. Here's the
81.00s - 87.56s |  agenda we'll work through. So, the problem. There's all these things. And it's funny, when I
87.56s - 91.44s |  was creating these slides, it was like, okay, what are the AI devices that exist? And there
91.44s - 96.28s |  were like three. And then all of a sudden, we had two new ones appear that are the exact same
96.28s - 100.34s |  but different with the same name. I don't know. Anyway, the point is, is I want a hardware
100.34s - 107.10s |  device that makes AI easy for just the general consumer. But I want to respect their privacy
107.10s - 114.06s |  because it's the right thing to do. And so, it's kind of a challenge when you think about the
114.06s - 120.02s |  difference between working in the consumer space, where it's like, anyone in my family who's not
120.02s - 126.46s |  into technology might actually purchase one of these versus the team that I work with at an
126.46s - 131.58s |  organization and they already have an understanding of how they treat their data and where it's
131.58s - 141.46s |  going. So, before we get into the pipelines that we should be using to protect that data, I want to
141.46s - 146.70s |  start off talking about some basic request workflows. So, when I think about doing something
146.74s - 153.06s |  with any kind of AI, it's really four different types of requests. And they're two, it's basically
153.06s - 157.82s |  two with a little differences. So, the first one is just a general knowledge request. I don't need
157.82s - 164.78s |  to know anything about you. I can just make this request. The second one is a contextual knowledge
164.82s - 169.74s |  request. So, I need to know some things about you, but I don't need any super sensitive data.
170.42s - 175.50s |  Generic actions requests. So, if I want to do something for you, but it could be anybody, it could
175.50s - 180.02s |  be done for Matt, it could be done for Steve, it could be done for Jay. I think that's who that was
180.02s - 186.66s |  now. That's what we would do. But if I wanted to do something on behalf of you, on your Spotify
186.66s - 191.06s |  account, on your Grubhub account, whatever it is, I need to be authenticated. And so that's that
191.06s - 200.71s |  fourth type that I like to think about. So, if we look at the general knowledge request, it's fairly
200.71s - 208.31s |  simple. So, I have my AI walkie talkie, I push the button, and I say, whatever it is I'm going to say
208.31s - 214.91s |  what, what's the weather out today? It's going to go up through the internet into my cloud
214.91s - 220.15s |  provider. There's a routing and storage and replay engine that sort of glues everything together. But
220.15s - 227.87s |  at its core, we're really just doing speech to text, text to speech, and some LLM calls to figure
227.87s - 235.71s |  out what the right answer is. So, that's a knowledge request. When we're doing those, those
235.71s - 241.55s |  types of requests, right? What kind of data are we thinking about? Well, if my request is tell me a
241.55s - 249.59s |  cat about a fact about cats, super easy. If I say I've got a weird rash, should I see a doctor? A
249.59s - 254.59s |  little bit more sensitive than tell me a fact about cats. And so, when I think about protecting
254.59s - 260.19s |  this data, it's really three different kinds. I've got audio data, that recording of my voice that
260.19s - 266.91s |  needs to get converted into speech to text. I've got the transcript data, which is the result of
266.91s - 272.43s |  that speech to text call. And then I've got my response data, which is where I took that, that
272.43s - 280.91s |  text, ran it through an LLM and had the LLM give me an answer. When we think about generic action
280.91s - 286.83s |  requests, it's very, very similar to what we just saw. The only difference is now we insert an
286.83s - 293.51s |  actuator. So, an actuator is just a thing that can perform a task when you provide an input. And
293.51s - 303.66s |  so, this is the thing that calls the Google weather API for you. As far as the types of data that we
303.66s - 308.90s |  need and that we need to protect, we've still got our audio transcript and response data, but we
308.90s - 314.86s |  also have some contextual data, right? Things like your location, things like your interests. If I
315.42s - 325.98s |  ask my AI walkie talkie for five restaurants in the area that are good, ideally, if I absolutely do
325.98s - 330.38s |  not like cheeseburgers, it would not give me the greatest cheeseburger restaurant in the
330.38s - 335.26s |  neighborhood because it knows. And so, that contextual data is also something super sensitive
335.26s - 342.78s |  that we want to protect. And the last piece is the authenticated action request. Exact same flow as
342.78s - 348.54s |  everything else. The only difference is now we have to store some sort of credential somewhere,
348.54s - 354.46s |  right? I can't order you food from your Uber Eats account unless I have a way to tell Uber,
354.46s - 365.10s |  hey, Matt wants food from Uber. So, whenever I think about that, more examples. Call me an Uber,
365.10s - 371.58s |  order me some tacos. Did Jimmy do his homework? Same data as before, but we have additional
371.58s - 377.18s |  context. We have the identity of the person that's asking for it. We have additional context
377.18s - 384.06s |  about who this Jimmy person is, right? Some like familial connection. And then authentication
384.06s - 396.36s |  information. So, this is like the sticky point that I feel like it's always a really fun discussion.
397.32s - 402.52s |  And so, yeah, I don't want to just make authentication information something tiny on
402.52s - 409.24s |  the slide. I want to actually talk about it. So, if I think about how can I authenticate a customer?
410.20s - 416.84s |  Well, or as a customer, sorry. I can do one of three things, really. I can save their username
416.84s - 421.96s |  and password in a database and then anytime I need to do something as them, I just log in as them.
423.24s - 429.88s |  That's cool, right? Probably not. I can have them log in and I can store their cookies. So,
429.88s - 434.36s |  at least I can't create a new session. I can only use that same session again.
435.24s - 442.97s |  And then the last option is I can just use OAuth. The problem is as security professionals, it's
442.97s - 448.33s |  really easy to just say, go be a grown-up and use OAuth. But whenever you're working with a
448.33s - 453.21s |  business that has to make money, you actually have to think about these things and consider
453.21s - 457.61s |  some of the trade-offs. So, we're going to talk about some of the trade-offs. So, if I just store
457.61s - 464.25s |  the username and password, it's great. We can log in whenever we want. Sorry. Yeah, wherever we
464.25s - 469.85s |  want, whenever we want. I don't actually have to store any session information because if I get
469.85s - 474.33s |  logged out, I'll just log back in because I know their username and password. Downside,
475.77s - 483.05s |  I have their username and password and someone can steal it. Bonus, we can log in whenever we
483.05s - 490.65s |  want. I covered that part already. And then the downside to that is in order to actually revoke
490.65s - 497.37s |  our access, a customer has to change their password. Again, another bonus, we can do anything
497.37s - 502.49s |  that the customer can do because we have their username and password. But the downside, we can do
502.49s - 509.45s |  anything the customer can do, including change their password. So, if we're thinking about trade-offs,
509.45s - 516.25s |  this one doesn't feel like the right thing to do. So, the next thing we have, right? Session
516.25s - 523.21s |  cookies. So, lots of pros here. Sessions expire regularly. The downside for the engineering team
523.21s - 529.61s |  is sessions expire regularly. I can have access to almost everything that a user can do. If you've
529.61s - 537.37s |  ever tried to go in and add someone to a repository in GitHub, like you can create a repository,
537.37s - 542.25s |  just I'm logged in. But in order to add a person to that repository, you have to step up, you have
542.25s - 548.57s |  to type in your password again, you have to do an MFA push. And so, this is really great because
548.57s - 554.09s |  if the provider supports it, we can actually scope down what it is that we're able to do.
555.21s - 559.85s |  But the downside is the provider actually has to support that. So, while GitHub might have
559.85s - 567.69s |  that requirement, the McDonald's mobile app maybe doesn't. Another nice thing on the engineering
567.69s - 576.17s |  side is typically MFA requirements, bot protection, all of that happens at sign-in and before you
576.17s - 584.33s |  actually get your session token for the site. The downside is that it also doesn't usually
584.33s - 589.53s |  generate a new login event. So, if you're like me and every time you get a message from Google that
589.53s - 594.97s |  says, hey, you just logged in from somewhere new, was that you? And you get like super paranoid,
594.97s - 599.53s |  you're not going to get those because most providers just say, oh, you've got a session
599.53s - 604.97s |  token that already works, so we're just going to use that. So, that's not great.
606.25s - 611.77s |  A good thing, users can actually manually expire those sessions for themselves,
611.77s - 616.89s |  which is great, right? Because if I go to Gmail and I say, where am I logged in? And it says,
616.89s - 620.89s |  I'm logged into AWS, I'm not logged into AWS, I'm going to click log out.
622.41s - 627.45s |  So, that's great. But again, it requires the provider to actually create that opportunity
627.45s - 633.85s |  for their customer. And then the other nice thing about this is it can be used on almost
633.85s - 641.85s |  any website, right? When we get to the OAuth piece, the biggest limitation is if you look at
641.85s - 645.61s |  all of the websites on the internet, how many of them actually support OAuth?
646.17s - 654.97s |  If we're in the B2B world, and we're focusing just on, oh, I want Datadog, I want GitLab, I want
655.53s - 659.61s |  all of these commercial enterprises, absolutely, there's OAuth because it's a thing that we've
659.61s - 665.69s |  been hounding vendors about for the last, I don't know, 20 years. But there's a benefit there,
665.69s - 671.61s |  and that is if they do it, they get our business. Whereas if you're a local mechanic shop,
671.61s - 678.65s |  and you just want people to book spots online with you, you're not incentivized to invest in
678.65s - 683.85s |  OAuth. And so, how do we support the general consumer with a technology that doesn't exist
683.85s - 690.17s |  everywhere? The other thing that I think sort of makes OAuth tricky in situations like this
690.73s - 698.57s |  is you have to configure it for each site. And so, if there are 100 million sites on the internet,
698.57s - 705.53s |  and I hire a 10X engineer who can knock out one integration every six hours, okay,
705.53s - 711.85s |  so that's 600 million. Did I say 100 million sites? I don't know. But the point is, it's a very,
711.85s - 718.25s |  very long time to actually be able to reach the entire internet. So, we've done our pros and cons.
718.25s - 723.53s |  Let's put them on a graph. That graph saying low effort to high effort. Obviously, the business
723.53s - 729.21s |  likes it whenever we do things low effort, not secure to more secure. Obviously, as professionals,
729.21s - 733.37s |  we like to be over there on the far right-hand side. So, we look at this graph, and we say,
733.37s - 737.69s |  you know what, there's just so much risk with username and password that's out. And then we go
737.69s - 741.93s |  to our CTO, and we say, hey, I want to do OAuth to the world. We're going to call get token every
741.93s - 747.61s |  time we need this. And I tell them it's going to take 1000 years to get all of the sites that they
747.61s - 751.93s |  want to cover done. And I get told, no, you know what, that's probably not. And even as a
751.93s - 758.97s |  practitioner, right, I realized that if I try to make the world's most secure company, that's just
758.97s - 764.25s |  us not making money with all the computers turned off. And I like having a place to work. I like
764.25s - 770.89s |  building cool things for consumers. And so, working with cookies for now is kind of like the way that
770.89s - 779.29s |  I see us going. So, let's talk about that user context, that authentication information.
780.25s - 785.77s |  So, there's sort of like the naive way, right, where you can just do it, make it work, it's going
785.77s - 790.49s |  to work great. And then there's more of a more secure way. So, first, let's talk about the naive
790.49s - 796.33s |  way. So, the first thing that I'll do is recognize, oh, the user wants to store a cookie. I'll create
796.33s - 801.29s |  context. The intention controller is going to recognize that and say, oh, they want to store a
801.29s - 809.69s |  cookie. Cool. It's going to create a context container. That container exists purely to allow
809.69s - 815.61s |  the user to store those cookies. So, some companies do it in a web browser. Some companies do it with
815.61s - 822.57s |  a Chrome extension. Lots of different ways that you could do it. But the point is, we're going to
822.57s - 828.65s |  collect that context. We're going to write it into a database. Whenever it comes time to use that
828.65s - 834.41s |  cookie, again, it all fits on one slide. I recognize I want to use this context. I say, oh,
834.41s - 839.29s |  this is Matt's user account. I'm going to go ahead and go into the database, grab Matt's cookie,
839.93s - 846.57s |  and then stuff it into an actuator. That actuator now has a login session for me. And it can order
846.57s - 851.13s |  the thing that I asked for. It goes off into the third party space and does the thing it's
851.13s - 860.35s |  supposed to do. What's the problem with this? What makes you nervous? Stolen cookies. I heard
860.35s - 867.07s |  that in the front. Awesome. Yeah, exactly. I don't want to be the guy that has a database just full
867.07s - 872.75s |  of cookies that other people can just come in and take from me. That would be really, really bad.
873.39s - 878.43s |  So, let's think about a way that we could do this a little bit more securely. So, again,
878.43s - 883.95s |  I'll recognize I want to create some context. I want to store that cookie. The intention controller
883.95s - 889.23s |  is going to recognize that. Very similar to before. It's going to create that web browser
889.23s - 894.99s |  so that the customer can log in. But then notice we have a vault service down below. And so,
894.99s - 900.99s |  once that cookie's collected, instead of just stuffing it into a vault and then returning it
900.99s - 904.67s |  to the database, what we're actually going to do is we're going to stuff it into the vault,
904.67s - 909.63s |  but we're also going to add the identity of the customer it belongs to. And so, when we get to
909.63s - 915.39s |  the next slide, you'll see that we should actually say, hey, yes, I want this cookie. Also, Matt said
915.39s - 923.87s |  I could have it two minutes ago. So, by having a short-lived JWT that the user provides to you,
923.87s - 929.31s |  your life just gets a lot better. I can sleep a lot better at night knowing that I'm not storing
929.31s - 935.07s |  cookies for 100,000 people. I'm storing things that I'm storing encrypted blobs,
935.07s - 940.59s |  and you would have to actually have a request from the user in order to go get that cookie.
942.86s - 947.66s |  So, when we get to using the context securely, I kind of already covered this, but we'll walk
947.66s - 953.74s |  through it again. We recognize the user wants to take an authenticated action. We get the object ID
953.74s - 961.26s |  and not the actual object from the database. We send that object ID and the user's JWT to our vault
962.22s - 968.54s |  or, sorry, to our context actuator. The context actuator now is the thing that reaches out to the
968.54s - 976.62s |  vault and gets that cookie. And so, this one tiny space in our network is the only place that,
976.62s - 981.26s |  with a request from the customer, you can actually go get their cookie.
983.02s - 989.26s |  Once the actuator performs the action, we tear it down. We never use it again. It was just that
989.26s - 995.74s |  one thing. And so, the risk of someone coming in and stealing a token off of the actuator
996.38s - 1002.86s |  gets a lot smaller, right? Essentially, we're looking at build system compromises that allow
1002.86s - 1011.53s |  you to get in versus earlier it was just, can someone access my database? So, it's a lot as far
1011.53s - 1018.33s |  as securing the customer context. So, some do's and don'ts to sort of take away. Don't collect
1018.33s - 1028.09s |  context that'll make you a target. If you are only storing cookies for DoorDash, Spotify,
1028.81s - 1034.81s |  and Uber, not a lot of people are going to come after you, right? Like, why do I want
1035.37s - 1041.37s |  this cookie that is likely going to get caught? There's much better things for me to spend my
1041.37s - 1047.69s |  time on as an attacker. So, if we ever get to a world where somebody wants to use their AI walkie
1047.69s - 1054.09s |  talkie to spend money, I don't want to store that financial instrument because that makes me a
1054.09s - 1062.25s |  target. And so, allowing vendors, service providers to actually own that piece is super, super
1062.25s - 1071.29s |  important to me. The second piece is don't reuse context or yeah, context containers or actuators
1071.29s - 1076.89s |  across users. So, anytime I'm taking something sensitive from the customer, it should be a one
1076.89s - 1081.61s |  off thing. And then when it's done, it should go away. And then I don't ever have to worry about,
1081.61s - 1090.25s |  oh, well, I accidentally ordered $1,000 worth of tacos on Jay's Uber Eats account instead of on
1090.25s - 1100.73s |  Matt's. And now, Jay has a ton of tacos to share with who? I don't know. So, not doing those. And
1100.73s - 1108.65s |  then the other don't, big don't, is don't trust that context as being true, right? It's really
1108.65s - 1113.37s |  easy for our engineers and developers to think, oh, yeah, no, this is a cookie that the customer
1113.37s - 1118.17s |  gave us to order for them. So, that's good, right? No, the answer is no. This is data that came from
1118.17s - 1121.69s |  the internet and we should just treat it like all the other data that came from the internet.
1122.49s - 1130.25s |  A couple of do's. Allow this vault access to only that one thing that actually needs to go
1130.25s - 1139.45s |  get it. This way, if you do have any issues with people trying or having the ability to connect to
1139.45s - 1144.33s |  your vault service, they can't actually do anything, right? Because you have to be running in
1144.33s - 1151.21s |  that one specific container in order to access those tokens. And then the last piece, which is
1151.29s - 1160.25s |  kind of my favorite, is correlation IDs. So, any time I need to ask for a cookie from the vault,
1160.25s - 1165.45s |  I should be able to match that up to a request that came from a physical device. And if I can't,
1166.25s - 1171.21s |  that means that somebody that I work with is going to have a bad day or I'm going to have a bad day
1171.21s - 1176.01s |  because somebody else is creating those requests. And so, I think that's a thing that we sort of
1176.01s - 1180.73s |  owe to our customers when we build devices like this is a way to tell them not only are we doing
1180.73s - 1186.57s |  our best to protect your authentication information from random people on the internet,
1186.57s - 1191.77s |  but we also recognize your data is important to you. We are not you. So, we shouldn't have access
1191.77s - 1199.29s |  to it either. And so, by introducing those correlation IDs, you can do really cool things
1199.29s - 1205.29s |  like requiring that correlation ID to exist before the request gets routed into the vault.
1205.29s - 1209.29s |  Or you can just set up automated alerting so that you know if it ever happens,
1210.25s - 1215.05s |  you at least know about it. So, do's and don'ts for context.
1216.33s - 1222.65s |  So, the next piece, securing customer conversations. This one was really, really fun to
1222.65s - 1230.89s |  think about. So, if I take out my AI walkie-talkie and I say, what's my favorite color? There's a
1230.89s - 1237.13s |  couple of types of data that happen there. We still have our same speech-to-text request and
1237.13s - 1243.21s |  response. We still have the LLM request and response and the text-to-speech back as well.
1243.21s - 1247.37s |  So, essentially, I have audio data and I have text data that I need to worry about.
1249.37s - 1254.57s |  As far as what type of binary data, it might be an audio recording, but it also might be a picture.
1255.29s - 1260.49s |  Maybe your magic AI walkie-talkie takes magic photos, and when it takes the photo,
1260.49s - 1268.17s |  it converts it into some cool 8-bit format. I probably don't want random people on the
1268.17s - 1272.33s |  internet or even the company that makes that AI walkie-talkie to have access to those pictures,
1272.33s - 1275.85s |  right? Because I'm a general consumer. Why do people need access to that?
1277.93s - 1282.73s |  Same thing goes with all of the text-to-speech that we just talked about. We have a transcript
1282.73s - 1288.57s |  of what the user said, we have an answer to their question, and we have what we want the device to
1288.57s - 1296.25s |  echo back. So, how do we store that? Well, a really, really easy way is I have my magic AI gadget.
1297.21s - 1304.65s |  It sends a request to that super awesome router that will take everything that I wrote and then
1304.65s - 1311.21s |  just store it in a database. If it's binary data, it'll just store it in S3. In the database,
1311.21s - 1317.05s |  I just put a pointer to S3. Life's great. This is super easy, right? Again, we're storing sensitive
1317.05s - 1324.41s |  things about people in a database. I don't want to be going to sleep at night knowing that that
1324.41s - 1334.89s |  happens. So, what do we do to make life a little bit safer? So, instead of just receiving that data
1334.89s - 1340.49s |  from the magical device and then writing it all down, again, we'll do the same thing
1341.77s - 1350.25s |  with our Vault Engine. And so, whenever we receive the data, we'll actually reach out to the Vault
1350.25s - 1357.37s |  Engine and say, can I have... kind of got two really cool options here. So, you could have the
1358.01s - 1364.65s |  service send that data to the Vault Engine, have it encrypt it, and then return back to you the
1364.97s - 1369.13s |  ciphertext. And now, you can just write that. Now, in the future, you just have to take that
1369.13s - 1372.49s |  ciphertext and say, Vault Engine, can you give me this data in plain text, please?
1373.13s - 1378.01s |  The other option that you have is you can request the customer's storage key. And you can say,
1378.01s - 1380.97s |  please give me the key for Matt Domko. I have a bunch of stuff I want to write.
1381.77s - 1388.81s |  In both cases, I'm not storing things that I have access to. I'm storing things that I only
1388.81s - 1394.25s |  have access to for that two-minute window whenever Matt Domko pushes the button.
1400.20s - 1403.32s |  So, I've got some do's and don'ts for securing those conversations.
1404.52s - 1411.96s |  So, please don't use built-in types for these things, right? My worst day ever is whenever
1411.96s - 1416.04s |  someone says, oh, yeah, no, we're just sending this JSON. And there's just like a string there.
1416.04s - 1419.32s |  And I look at it. I'm like, oh, okay, cool. It's just a string. No big deal. And that string is
1419.32s - 1425.48s |  actually like six hours of me watching Gilmore Girls because I started a meeting transcription
1425.48s - 1430.36s |  during it. So, rather than taking these things and just going with the defaults, let's create a
1430.36s - 1436.44s |  custom object. Use a strongly typed language that allows you to say, okay, this is actually a type
1436.44s - 1441.40s |  of sensitive data. And the only way that it's allowed to be logged is either through that
1442.28s - 1450.60s |  vault controller interaction or through a secure logger. So, yeah, don't, please, one second.
1451.56s - 1460.64s |  So, the other thing that definitely in the business-to-business space, it happens and it's
1460.64s - 1467.12s |  not great, but it could be worse, right? Essentially, if I need to do analytics on data and I
1467.12s - 1472.16s |  have the data in a place, well, let me just go grab that data and do analytics. It's one thing
1472.96s - 1479.12s |  to do it whenever it's how many times did my employees click on a phishing link. It's another
1479.12s - 1485.68s |  thing altogether for it to be a recording of me and my kid talking about something.
1487.76s - 1496.24s |  So, don't let it happen, right? Don't share data between production and anything else. If you're
1496.24s - 1500.88s |  not using that data to provide a direct value to the user, you're essentially stealing their data
1500.88s - 1508.40s |  right now. And I'm not a fan. And then the last one, don't allow new log types without a privacy
1508.96s - 1515.44s |  and security review. And so, this is a thing that I've sort of started harping on a lot more at
1515.44s - 1521.92s |  work, which is just like, if you want to do something new and it has to do with customer data,
1521.92s - 1527.60s |  we owe it to our customers to spend 15 minutes drawing out what we're going to do, identifying
1527.60s - 1531.20s |  the data that we're going to write down and talking about whether or not that is a good
1531.20s - 1540.64s |  thing to do with our customers' data. So, yeah, don't do that. Do move encryption to client side
1540.64s - 1549.04s |  where possible. So, the way that it is in this diagram that I just showed you, as the service
1549.04s - 1556.24s |  provider, you can just grab a JWT and go get the data. Wouldn't it be great if the only person that
1556.24s - 1561.04s |  had your data was like you in your web browser when you get to go view your pictures? That would
1561.04s - 1567.28s |  be great. That's a technology that exists. It's not a technology that exists, as far as I'm aware,
1567.28s - 1573.28s |  that works really well with AI use cases where we want to get your permission to use your data to
1573.28s - 1582.16s |  make things better. And so, that's a tough road to climb. But I think that it's a goal to move
1582.16s - 1590.16s |  towards. Require a short-lived JWT. Like, this is sort of really, really easy to do. You just,
1590.16s - 1594.88s |  when your user wants to do something, make them send you a token that says that they want to do
1594.88s - 1600.72s |  it and have that expire quickly. If you look into the different types of vault providers that exist,
1601.60s - 1607.28s |  I know of at least one that does that. And you can give them a JWT and they will only give you
1607.28s - 1613.20s |  the data back if that JWT is signed by the customer, the person who owns the data. I sleep
1613.20s - 1618.80s |  a lot better at night knowing that I have that. And then the last piece, if you've ever worked
1618.80s - 1625.20s |  at an AI company, you probably have like a chat room where it's just AI news. And people are
1625.20s - 1631.04s |  excited about new models and new things that are coming out. And Anthropic has this. AWS has this.
1631.52s - 1639.04s |  OpenAI has this. And they want to try it out. The problem is, unless you have like a commercial
1639.04s - 1644.64s |  agreement with them, a lot of times, you're just sort of giving them free reign to do whatever
1644.64s - 1651.84s |  they want with your customer data. And so, one of the things that I've worked really hard on at the
1651.84s - 1657.84s |  last few jobs has been making sure that we actually make those thoughtful decisions. We say,
1657.84s - 1663.12s |  okay, this type of data, maybe we're okay with that company using it for whatever they want.
1663.12s - 1667.52s |  But this other type of data, super, super important to us. And we're not going to allow
1667.52s - 1674.72s |  it to go to those levels of LLMs. Essentially, pay more to protect our customers. I think it's
1674.72s - 1684.24s |  worth it. So, the last one is privacy-focused logging. So, if you're an engineer and you're
1684.24s - 1688.32s |  coming up with logs for this new service you built, this is probably how you're going to do
1688.32s - 1691.20s |  your logs. You're just going to take everything that you know, and you're like, I might need this
1691.20s - 1696.56s |  someday, ship it to Datadog. And then one of your SRE managers is going to be like, hey, so your
1696.56s - 1700.64s |  Datadog bill's kind of high. Can you cut it back? And you're like, no, I need all of this. I need
1700.64s - 1707.44s |  every single piece of data that comes in, or I can't do my job. Okay. That's a way. But again,
1707.44s - 1713.44s |  we're talking about consumers. We're not talking about business-to-business operations. And so,
1713.44s - 1721.52s |  if I'm a consumer and I have to worry about every single thing being stored on my behalf,
1721.52s - 1730.00s |  I start to get nervous. And so, what I like to do in these cases is require a custom logging handler.
1730.00s - 1735.12s |  Engineers are already creating these to make their lives easier. All you have to do as the security
1735.12s - 1739.92s |  person is say, hey, so right now it looks like you're taking everything, you're formatting it,
1739.92s - 1745.12s |  and then you're shipping it out. What I would love for you to do is instead explicitly declare
1745.12s - 1750.72s |  these are the fields that we're going to log. And by forcing them to explicitly declare the
1750.72s - 1756.00s |  fields that they're going to log, you don't have to worry about, oh, I just updated the code to
1756.00s - 1762.72s |  log this extra field. Also, it's everyone's birthday and social security number. That's okay,
1762.72s - 1766.96s |  right? You don't have to worry about that because the logger won't allow it. And now,
1766.96s - 1774.08s |  instead of monitoring your entire code base for a change that might log something in a wrong way,
1774.08s - 1779.68s |  you only have to monitor that base privacy logger. So, it's definitely worth investment.
1781.76s - 1789.12s |  This code is from ChatGPT, write me a privacy-focused log handler in Python. It might
1789.12s - 1795.68s |  work. I don't know. But the point is it's not super difficult and your engineers are likely
1795.68s - 1805.71s |  already doing it anyway. So, some highlights on privacy-focused logging. Prefer metrics
1806.91s - 1812.43s |  over, like, actual counts and group by statements whenever you're thinking about things. You don't
1812.43s - 1817.79s |  need to log every single request in order to know how many requests happened, right? And so,
1819.39s - 1825.39s |  if you don't need to store the data, don't. A thing that I've been big about for a very long
1825.39s - 1833.07s |  time has been the fact that business metrics and that type of work needs to be a feature request
1833.07s - 1838.27s |  of the product. This is not something where, oh, I've got a really strong program manager,
1838.27s - 1842.27s |  they're going to go into Datadog and create these dashboards that are going to tell them, like,
1842.27s - 1847.63s |  what our most popular feature is. It's a very, very easy shortcut, but it's also a very, very
1847.63s - 1852.99s |  easy, easy way to lose control of the way that you're managing the privacy of your customer data.
1853.63s - 1861.95s |  And so, rather than getting into that, when we do a product design doc, right, let's explicitly
1861.95s - 1867.47s |  call out, I need these metrics. And now it's part of the product. You don't have to go look
1867.47s - 1873.23s |  through logs because you've already decided I'm going to use counters instead. Engineering logs
1873.23s - 1880.59s |  for engineering things. We talked about using custom logging classes. Anonymize where possible,
1880.59s - 1888.91s |  pseudo-anonymize everywhere else. So, I might need to know which user I'm dealing with whenever
1888.91s - 1895.31s |  I'm solving an engineering challenge. I don't need to know that user's email. I don't need to know
1895.31s - 1901.15s |  that user's address. I don't need to know any of those things. I just need to be able to say,
1901.15s - 1907.79s |  user one, two, three of 1,000. And so, this is where when we do logging, rather than logging
1907.79s - 1913.15s |  all of the information we have about that customer, let's just log a pseudo-anonymized
1913.79s - 1918.67s |  user ID. It doesn't provide access to anything, but it lets us sort of work through the streams
1918.67s - 1927.07s |  and track down when bugs happen. Set an extremely short time limit for your engineering logs.
1927.07s - 1932.91s |  If you need something for longer than a week, two weeks, that should probably live somewhere else.
1932.91s - 1936.19s |  Probably doesn't need to be in Datadog. Your CFO is going to thank you,
1937.31s - 1941.23s |  and so are your customers, because you're not storing their personal data somewhere
1941.23s - 1948.99s |  that you don't need to. Enforce just-in-time logging. So, I think one of the coolest and
1948.99s - 1955.31s |  scariest things about joining an engineering team at Facebook is the first two days when they're
1955.31s - 1959.79s |  like, oh, yeah, and by the way, if you look at anyone that you work with's data, we're going
1959.79s - 1963.39s |  to fire you. And I'm just like, I don't even want to accidentally do that. You're paying me really
1963.39s - 1971.07s |  well. I get free pizza. Why would I mess that up? And the way that they enforce that is if you need
1971.07s - 1976.19s |  access to something and you don't have it by default, you just go find the table and say,
1976.19s - 1981.55s |  I would like access to this. I need it for this long, and this is my business purpose behind it.
1982.19s - 1990.27s |  And as long as it's not like your ex-partner's page, it'll just grant you access and log it.
1991.15s - 1997.87s |  And I feel like it's way better to have that than, oh, yeah, just everybody in engineering has access
1997.87s - 2004.11s |  to everything all the time. So, that just-in-time access gives us, again, a little bit more safety
2004.11s - 2008.27s |  and a little bit better of a way to recognize when something's going off the rails.
2009.23s - 2015.55s |  All of the do's and don'ts that we talked about in the other two sort of apply to privacy-focused
2015.55s - 2024.83s |  logging as well. All right. The last one, privacy-focused analytics. So, if I've got a
2024.83s - 2029.55s |  feature that's out there, it's doing great things, but I want to make it faster, but I don't understand
2029.55s - 2035.63s |  what requests are happening. And so, I need to actually see these requests in order to make
2035.63s - 2042.59s |  the product work better. Well, 18-year-old Matt Domko goes into the routing engine, and he just
2042.59s - 2050.19s |  adds a new branch of code for 2A that says, yeah, so, anytime somebody makes a request, I want you
2050.19s - 2056.19s |  to go do the thing that you always do, but also log a copy of it to my analytics storage. And then
2056.19s - 2061.23s |  once that table is super full or that bucket has all the data I need, I can go in and do some sort
2061.31s - 2068.03s |  of analytics process on it. The problem with that is in order to solve whatever challenge I'm facing,
2068.03s - 2073.87s |  again, I probably don't need to know the customer's name. I don't need to know all of the
2073.87s - 2081.31s |  things that they did. I probably just need to know what's the length of their request and what time
2081.31s - 2086.75s |  was it when they made the request. Well, whatever the thing is that I need, it's probably not
2086.75s - 2096.99s |  everything. So, the way that I've thought about handling this, we have our new
2097.63s - 2105.79s |  analytics logger. And again, we still insert it into 2A, but instead of having it directly
2105.79s - 2110.83s |  write data outside of my little nice fancy production bubble where data never leaves,
2110.83s - 2115.31s |  I write it to a privacy filtering account. And so, that privacy filtering account,
2115.31s - 2121.15s |  whenever it receives new data, it reaches in and it says, oh, I'm expecting that Matt needs to know
2121.15s - 2129.87s |  the locations of every failed Uber request. And so, what that privacy filtering Lambda will do
2129.87s - 2137.87s |  is it will just extract the location and the time that it happened. Because I don't need to know
2137.87s - 2143.63s |  anything else about that conversation or what's going on except for that one single line. So,
2143.63s - 2149.63s |  why would I allow myself to copy the entire thing out? So, I create this process where in order to
2149.63s - 2154.75s |  get data out of production, I ensure that it's anonymized. I ensure that I only have the data
2154.75s - 2161.71s |  that I need. Once that data has been cleaned, we've ran it through something like Amazon Macy
2161.71s - 2167.39s |  to check for PII and things like that. Then we'll go ahead and copy it from the privacy account
2167.39s - 2175.55s |  into the analytics account. Analytics is already expensive. And so, like this additional process
2175.55s - 2185.26s |  that we're introducing in order to protect our customers is totally worth it. And so,
2186.22s - 2193.02s |  we've got a summary of the things that have made my life easier in protecting
2193.98s - 2201.90s |  customers' privacy. The first thing, simple data classification guide. Anyone that was
2201.90s - 2205.42s |  ever in the military, they've got like those colors. And when you see colors, you're like,
2205.42s - 2210.30s |  oh, this is sensitive. I shouldn't do anything wrong with this. Oh, this is green. I think I can
2210.30s - 2215.90s |  do whatever I want with this, but let me check. Having some sort of simple guide where your
2215.90s - 2223.42s |  engineers know if data is labeled as red, that means it can't leave prod. If data is labeled
2223.42s - 2230.62s |  as yellow, it means it can go from prod into the privacy account into an analytics account.
2230.62s - 2237.58s |  If data is labeled as green, it's on the website, so who cares? But coming up with those shortcuts
2237.58s - 2243.90s |  for your engineers is going to make your life a lot easier. Build that culture of design reviews.
2243.90s - 2248.62s |  Show up to them. I know that our engineers build a lot of really cool stuff all the time,
2249.66s - 2253.98s |  and that means I'm going to be at more meetings. But again, it's worth it. You're learning more
2253.98s - 2259.02s |  about the product. You have a chance to actually step in and say, well, what is this data and why
2259.02s - 2265.82s |  do you actually need to store it or move it or read it? So, build that culture. Show up to those
2265.82s - 2274.30s |  things. Service control policies. So, these exist. I know in AWS and Azure, does GCP have
2274.30s - 2277.74s |  something like this where you can say you're not allowed to break this rule no matter what? I don't
2277.74s - 2285.26s |  care who you are? Yeah? Okay. So, set that up. If you have a production account where all of your
2285.26s - 2290.86s |  day-to-day data exists, make it so you can't mess it up. No data is allowed to leave production
2290.86s - 2296.78s |  except for to go to this singular privacy account. It works fairly well and it keeps
2296.78s - 2301.10s |  you out of trouble when you're traveling or at a conference talking about privacy.
2303.66s - 2307.58s |  The two-step filtering process that we talked about, I feel like that's the only way that we
2307.58s - 2314.54s |  can truly ensure we're not accidentally moving data somewhere we shouldn't. And so, think about
2314.54s - 2319.10s |  how to implement something like that. There's tons of services and all the different cloud
2319.10s - 2326.62s |  providers that will parse your data and tell you yes or no, this can go or this yes or no,
2326.62s - 2335.58s |  this has sensitive data in it. I just learned about S3 bucket filtering? I don't remember
2335.58s - 2343.42s |  the exact name. But anyway, you can create a new S3 access point. We'll go with that. You can create
2343.42s - 2350.30s |  a new S3 access point and say, through this access point, you can only read filtered data.
2350.30s - 2354.22s |  Which kind of takes your hands away from having to do anything as long as you only let your
2354.22s - 2365.37s |  developers read through that singular access point. Oh, yes. Almost done. So, a couple of
2365.37s - 2371.61s |  guidelines that I've set with the teams that I've worked with in the past, this is the one that you
2371.61s - 2379.21s |  screenshot and send to everyone. And it's really just four questions. Are you logging new type of
2379.21s - 2386.17s |  data? We should talk. Are you moving data outside of prod? We should talk. Are you connecting to
2386.17s - 2394.01s |  prod databases? We should talk. Are you bringing in a new tool or vendor? We should talk. I think
2394.57s - 2401.21s |  like those are fairly easy to do in practice. And it's worth the extra time that we have to
2401.21s - 2413.88s |  invest. That's it. What time is it? 442? Time for questions, if anybody has any. If not, I'm gonna
2413.88s - 2424.49s |  get off the stage and chug a bunch of water. Oh, contact page. So, hashtag cyber on the Twitter.
2424.81s - 2432.41s |  And if like you're worried about your Rabbit R1, security at rabbit.tech.
2436.09s - 2445.68s |  I don't know. That guy right there. So, cool. Well, thank you, everybody. Have a great con.