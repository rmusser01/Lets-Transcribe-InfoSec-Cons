{
  "webpage_url": "https://www.youtube.com/watch?v=7k3zOylPKbM",
  "title": "DEF CON 32 - AWS CloudQuarry: Digging for secrets in public AMIs - Eduard Agavriloae, Matei Josephs",
  "description": "Join us as we unravel another story of public resources from AWS, digging in 3.1 million AMIs for secrets. Beyond the findings, we'll delve into the ominous connection between exfiltrated AWS access credentials from these AMIs and the heightened risk of AWS account takeover. This talk will highlight key methodologies, tools, and lessons learned, emphasizing the critical need for robust security measures in the cloud to prevent both data exposure and potential account compromise.",
  "channel_url": "https://www.youtube.com/channel/UC6Om9kAkl32dWlDSNlDS9Iw",
  "duration": 2372,
  "channel": "DEFCONConference",
  "uploader": "DEFCONConference",
  "upload_date": "20241016"
}

0.43s - 8.05s | This text was transcribed using whisper model: large-v2

 Hello DEF CON. So I'm very happy to be here. This has been a dream of mine for uh many
8.05s - 16.05s |  many years and uh thanks for being part of it. This research is about a cool story about
16.05s - 23.79s |  um secrets in public cloud resources and um you know uh who thinks we will never run out
23.79s - 32.73s |  of customers public public sharing secrets in public cloud resources. Yeah I think I think we
32.73s - 39.53s |  will never run out of that. And uh my name is Edward Agaduluia. I was a senior penetration
39.53s - 45.25s |  tester at KPMG Romania while I've done uh this research. Uh huge shout out to them for
45.25s - 50.81s |  supporting the the the research and uh trusting this idea. Uh I was also a contractor at
50.81s - 56.31s |  Syncubes uh I I mean I still am and I'm doing offensive cloud uh projects there. I also
56.31s - 66.09s |  work one month at CrowdStrike but I resigned on Friday so so I'm open for new opportunities
66.09s - 71.09s |  and um yeah I'm trying to do some uh cloud security research. Now I started um a cloud
75.09s - 80.09s |  configuration review uh for a customer of uh Syncubes and um I got the initial access um and
81.09s - 86.09s |  I started using uh Scout Suite as I uh uh always uh as I always do. And um I checked the
92.73s - 99.33s |  report. I saw the S3 findings, the CloudTrail findings, the YAM findings and when I looked at
99.33s - 104.35s |  the EC2 dashboard I saw for the first time the critical finding AMI is set to public and who
104.71s - 109.71s |  knows what an AMI is? Ok cool and um who used at least once an EC2 instance? Ok so if you
116.25s - 122.03s |  used an EC2 instance you kind of know what an AMI is because every time you start a an EC2
122.03s - 128.73s |  instance you are using an AMI. It's like a snapshot of a virtual machine and you can
128.75s - 133.75s |  pre-configure an an AMI to contain your applications, secrets, um so to have a baseline
137.33s - 142.47s |  right? And then you can start new EC2 instances starting from this AMI. And you have AWS
142.47s - 148.07s |  Marketplace AMI that are official and from trusted vendors which are the recommended ones
148.07s - 154.45s |  you can use. And you can also have community AMIs that are published by anyone. And you
154.47s - 159.91s |  have to be careful with uh with them because if you don't trust the publisher you might have
159.91s - 164.91s |  some backdoors malware and so on. But in any case the thing is that an AMI can be public or
168.09s - 173.05s |  private and by default they are private and it's actually hard to make one public. And I
173.05s - 178.69s |  think you can see where I'm going with this. The issue is that they can be public and this
178.71s - 183.71s |  customer had 5 public AMIs um exposed for multiple years and when I asked them hey can I
187.01s - 192.65s |  take a look uh inside the AMIs to to see what's inside of them? And um they were like no and so
192.65s - 198.93s |  I I regretted I even asked. But I got this question what was inside the AMIs? And this
198.93s - 205.33s |  actually gave me the research idea if there are other companies with secrets in public
205.51s - 210.51s |  AMIs out there. So um first we wanted to do this research so bad that we haven't checked any
215.81s - 221.89s |  previous work but when we are when we were in the middle of it we discovered the work done
221.89s - 227.99s |  by Dolev Farhi who scanned based on keywords AMIs in a single AWS region which was was
227.99s - 234.13s |  fine but it was not enough uh from our perspective. And also the work done by Ben Morris
234.17s - 240.17s |  who searched secrets in public ABS snapshots but we will see shortly that that there is very
240.17s - 245.17s |  little overlap between his work. And funny story um last days um I was talking about uh the
247.61s - 252.75s |  research with someone and he was like hey you know who did something similar? Um he searched
252.75s - 257.39s |  public ABS snapshots uh he's Ben and he pointed at someone and it was Ben Morris and he was
257.43s - 263.94s |  like yeah and sorry. So yeah we um I've met mo- Ben Morris um I've been saying his name a
267.14s - 272.14s |  lot um uh rehearsing the presentation it was uh it was a pleasure to to meet him in person
274.62s - 280.96s |  he's a lovely guy. Now uh we set some goals for the research to dig for secrets in every
280.96s - 286.66s |  public AMI across all AWS regions to have some fun and do some responsible disclosure. We
286.66s - 292.26s |  also had a hidden goal to get some bounties and uh my colleague Matei will tell you more
292.26s - 299.18s |  about it. Starting the research we had to collect every public AMI across all A- all AWS
299.18s - 305.92s |  regions and to do that you have to um you have to use the CLI because AWS automatically
305.92s - 311.68s |  deprecates images after two years uh after they were published. And if they are
311.68s - 317.02s |  deprecated you can find them in the in the web portal. Also customers can deprecate their
317.04s - 322.12s |  images whenever they want. So we have to uh you have to use the CLI and specify the flag
322.12s - 328.16s |  include deprecated to make sure you get all the AMIs. And we did that and we got 3.1
328.16s - 333.16s |  million AMIs and um we were sure that this was too much for us to scan all of them and we
335.26s - 340.26s |  started asking if we can remove AMIs based on the chances of having secrets. So we removed
341.02s - 346.02s |  AMIs for from marketplace that left us with 1.5 million. We removed AMIs owned by AWS that
349.62s - 355.96s |  were not in the marketplace that left us with 1 million and we went further and uh we
355.96s - 362.00s |  removed the owners that had more than 50 public AMIs because honestly if you are a company
362.00s - 367.64s |  and you have more than 50 public AMIs security wise you are in a point of no return or you
367.66s - 373.90s |  are or you are uh an official publisher an unofficial publisher right? And that left us
373.90s - 378.90s |  with 27,000 AMIs. Now we did some sanity filtering because some AMIs had 17 volumes or
382.84s - 389.12s |  volumes uh as big as 20 terabytes. Obviously I'm very curious what's inside of them but for
389.12s - 396.12s |  our budget we had to remove them uh and that left us with 26,000 AMIs. Now the distribution
396.14s - 401.14s |  uh from our list looks like this. Obviously the most AMIs were in U.S. East 1 and um region
403.62s - 409.72s |  with the smallest number of AMIs was IL Central 1, Israel Central 1 with only 30 public
409.72s - 414.72s |  AMIs after uh after our filtering. And when I'm saying that we collected the AMIs this is
418.46s - 423.46s |  what I mean by it. So we got the JSON definition for each AMI and uh you have a lot of
423.58s - 430.28s |  information like the ones highlighted, the image ID, the information about the snapshot,
430.28s - 436.12s |  but you also have other important information like description, title and the owner of the
436.12s - 441.12s |  AMI and we'll see how we can use that uh shortly. Now that we had our list we need a way to
444.10s - 449.80s |  access the contents of the AMI and this should be time and cost effective, automated and as
449.84s - 456.32s |  reliable as possible. And we looked for various methods, some of them might work in certain
456.32s - 461.32s |  situations but only the fourth option was the right one for us. So first we tried to copy the
463.62s - 468.62s |  snapshot uh of the AMI in our own AWS account and download it but even if the AMI is
471.40s - 477.00s |  public the ABS snapshot is not by default and that's why it's very little overlap between our
477.00s - 483.22s |  work and the work done by Ben Morris. Next we tried to start an EC2 instance based on the
483.22s - 488.22s |  target AMI, create a an ABS snapshot of its volume and download it. But we we we quickly we
490.52s - 495.52s |  quickly realized that this will take a lot of time for an ABS snapshot of uh 100 gigabytes.
498.40s - 504.04s |  It took around 20, 30 minutes to download and we were sure that AWS will block our IP since
504.08s - 511.18s |  we are downloading uh terabytes of data, right? So definitely not an option but we realized we
511.18s - 517.46s |  had to operate as much as possible within the native AWS features to to achieve the faster
517.46s - 522.46s |  uh the faster method. And we we tried to start a new EC2 instance based on the target AMI and
525.34s - 531.98s |  connect directly to the instance but for some reason the instances were not in a state that
531.98s - 537.36s |  allowed us to connect to them. Either through SSH or through SSM features it just didn't
537.36s - 542.36s |  work. But we did a work around a work around and um we got to this method. So we have a secret
545.66s - 551.64s |  searcher instance. We call it like this because it's a sec- it's an instance that we already
551.64s - 557.24s |  have in our own AWS account and it's working we can connect to it. And next we start an EC2
557.24s - 562.28s |  instance based on the target AMI, detach its volume and reattach it to our secret searcher
562.28s - 568.32s |  instance where we can connect and analyze the data. It's like having a working laptop and
568.32s - 573.56s |  someone brought a laptop that doesn't work but you can get out the hard disk and connect it to
573.56s - 577.66s |  your laptop and basically that's how you can access the data. And everything is happening
577.66s - 584.54s |  within the AWS environment so it was both fast and with it was both as reliable as possible.
584.54s - 592.28s |  Now I'll show you a demo on how you can manually access the contents of one AMI. Let me
592.28s - 599.31s |  see if I can start this. So we can search based on the uh description. You can use this to
599.31s - 604.05s |  target certain technologies or companies. You have to mention the right region because
604.05s - 610.01s |  otherwise you will not find the the the AMI and you also have to specify the flag include
610.01s - 617.03s |  deprecated to make sure you get all the images right? If you know the AWS account ID you can
617.03s - 622.03s |  try to find all the images owned by that account so that's that might be useful for uh for
622.03s - 627.03s |  bug pound-hunter right? But let's stick with uh our uh description based search. So let's try
629.61s - 636.40s |  to copy the ABS snapshot as um as a first step. So you you will see that if you try to copy
639.54s - 644.00s |  the snapshot in our own AWS account we will get the error message source snapshot is not
644.00s - 650.66s |  found. That's because the ABS snapshot is not public only the AMI is. Now we will do the
650.66s - 655.20s |  method uh with the secret search searcher instance so we have our instance that it's
655.20s - 660.18s |  running and now we will start a new instance based on the target AMI and we will place it in
660.18s - 665.58s |  the same availability zone as our secret searcher instance. We you need the same availability
665.58s - 672.26s |  zone to make sure you have you you can move the volume between the instances. Now the
672.28s - 678.38s |  instance is running we will stop it and we will detach the volume and we will reattach it to
678.38s - 685.40s |  the secret searcher instance. After you detach the volume you can delete the initial ins- the
685.40s - 690.40s |  the EC2 instance that is based on the AMI if you want to reduce some cost but in any case uh you
694.40s - 699.54s |  can just attach the volume and then you can connect to it. We use the web portal uh because
699.56s - 704.76s |  it was easier for the demo but you can also connect through SSH. A common error that we
704.76s - 710.26s |  encountered was an ID collision between the new volume and the root volume that was
710.26s - 716.68s |  attached to to the instance. And we had to use all kind of weird tools I've never heard
716.68s - 723.68s |  about uh in order to fix this issue but once that is done you will be able to mount the
723.82s - 729.56s |  volume and connect um to mount the volume and access the files. And now that it's mounted
729.56s - 734.70s |  let's look for some AWS credentials right? We found some and now let's check if they are
734.70s - 741.24s |  valid. Because for some older instances the secrets might not be valid anymore so every
741.24s - 750.34s |  time you have to check them. So surprise yes they are working and that's exactly how we
750.34s - 756.44s |  felt when we found our first AWS access keys and in the same day we found 10 other valid
756.44s - 762.72s |  access keys so we realized that this was a big issue indeed. This is the high level
762.72s - 767.98s |  architecture we put in place. We had a master EC2 instance where we round uh we we ran our
767.98s - 774.66s |  big script and in each region we started the secret searcher instance um and then we
774.66s - 781.50s |  started batches of twenty uh twenty instances based on AMIs to um to make sure we um we
781.50s - 786.64s |  reduce the time. And for each instance we detach the volume, we reattach it to the secret
786.64s - 793.24s |  searcher instance where we will search for secrets and sensitive files. And after run
793.24s - 798.24s |  run after writing 1.2K lines of code, 14 days of scanning time and a bill of 450 dollars, we
801.18s - 806.18s |  collected 500 gigabytes of carefully selected files and data um that we had now to to
806.54s - 811.94s |  analyze and I invite my colleague Matej Josic to tell you more about it.
811.94s - 820.08s |  Thank you. Cool. Good morning everybody and thank you so much for being here. It's actually an
822.16s - 827.16s |  absolute pleasure to be on stage at DEF CON 32. This is the secret searcher section where I'm
830.60s - 837.04s |  going to talk about how we search for secrets, what sorts of secrets we found, and what we
837.06s - 844.74s |  were able to do with them. I am Matej Anthony-Josephs. I've been with KPMG for about an
844.74s - 849.34s |  year and a half and I'd like to take this opportunity to thank them for the time and the
849.34s - 855.66s |  budget for this project right here. Other than that, I'm a senior security researcher with
855.66s - 860.32s |  experience in pen testing, threat hunting, vulnerability management, and a bit of people
860.32s - 865.32s |  management as well. Now, completely unrelated to this research, I've also set up a company
866.00s - 870.60s |  alongside my wife, Alexa. Our company's called Hivehack, because we're absolutely
870.60s - 876.28s |  fascinated by the collaborative trace of bees, whereby up to 60,000 bees work together in a
876.28s - 881.28s |  colony for the greater good of the community. Similarly, we think that uh collaboration is
886.08s - 891.86s |  probably the most important part of cyber security. And while I don't know the exact
891.86s - 898.88s |  numbers, just looking around Dafcon, I can see why. There's quite a hive of hackers around
898.88s - 905.68s |  here. That's enough about me, back to Cloud Query. For our initial strategy, we decided to
905.68s - 911.76s |  be as lazy as possible. And trust me, being lazy is a good thing here. We wanted to avoid
911.76s - 916.66s |  reinventing the wheel, and wanted to use known tools as much as possible, such as
916.66s - 921.66s |  TruffleHog. But we quickly realized that this was not going to work. In fact, the tools which
924.10s - 930.00s |  we tried to use were quite slow, and produced loads of false positives. And while we could
930.00s - 934.78s |  have worked through the false positives, the fact that the tools were slow was the main
934.78s - 940.08s |  issue, because slow scanning times meant that our EC2 instances ran longer, which in turn
940.08s - 945.76s |  meant that uh our AWS bill would have been way higher, leaving us broke and lazy, rather
945.76s - 952.68s |  than just lazy. So, with this in mind, we had to pivot, and we went back to the Zen of Python.
954.78s - 961.02s |  More specifically, the following section of it. Simple is better than complex, complex is
961.02s - 967.86s |  better than complicated, and special cases aren't special enough to break the rules. So, with
967.86s - 974.40s |  this in mind, we reduced our scope even further, and became even lazier. We ended up only
974.40s - 980.50s |  looking for specific types of files or directories, such as uh, well, environment secrets,
980.50s - 985.50s |  secrets leaked within git repositories, AWS credentials, private keys, and a few others. Now
987.98s - 993.84s |  we faced an other issue, and that is, finding the right tool for this. We had to find the
993.84s - 999.78s |  tool, which allowed us to search for files and directories on the file system, based on
999.80s - 1006.10s |  their names. The tool had to be quick and simple. So, you can probably see where I'm going
1006.10s - 1011.12s |  with this. We ended up using the native Unix utility, find, of course. So, uh, we, we
1014.08s - 1019.12s |  skipped the Windows directory, program files directories, because they're full of junk and
1019.12s - 1025.26s |  slowed down our scans. We skipped everything about, above 25 megabytes, because, well, this
1025.28s - 1030.68s |  is only a proof of concept. We didn't need to find everything, really. And searched for all of
1030.68s - 1037.46s |  these various files and directories. So, besides our, well, proprietary and very complex use
1037.46s - 1043.32s |  of find, and I'm only joking as well, it's not that complex, we had to set up a few other
1043.32s - 1049.86s |  things. And one of them was an automation for verifying AWS credentials. And you'll see in a
1049.88s - 1056.28s |  minute exactly why we needed that. Secondly, we used Git leaks for checking Git repositories
1056.28s - 1061.28s |  for secrets. Also, we had to set up a few other automations for verifying API keys and other
1064.86s - 1070.82s |  types of credentials. And for this we used key hacks, which is a fantastic repository of
1070.82s - 1076.66s |  methods for validating keys and credentials. However, even if we had all of these
1076.66s - 1081.88s |  automations set up, we, we're still left with, well, a shit load of manual work, to be
1081.88s - 1086.88s |  fair. Um, so, following our data collection phase, we were left with 2 million generic API
1089.64s - 1095.48s |  keys, and of course many of them are false positives. Over 100,000 potential AWS
1095.48s - 1102.46s |  credentials. Several private keys, you can see some slack tokens, uh, uh, Stripe, Telegram,
1102.46s - 1107.40s |  and so on and so forth. So you can probably see why we needed all of these automations for
1107.40s - 1112.40s |  validating the keys and credentials. So, out of the, about 100,000 AWS credentials, only
1116.04s - 1121.04s |  about 120 of them were valid, out of which 20 were root. Now, I know that this does not seem
1124.18s - 1129.18s |  like a lot. I mean, what is, 120 out of 100,000 is nothing, right? But, think about it this
1132.46s - 1137.46s |  way. These, these keys allowed us to access the AWS accounts of over 100 companies. So, this
1143.00s - 1149.44s |  gave us initial access there, and for 20 of them we had absolute complete control. So, let
1149.44s - 1155.94s |  that sink in for a bit. Now, we faced another issue, and that is identifying the owners. And
1158.38s - 1163.78s |  for this, we used the get contact information call, which gave us, well, the
1163.78s - 1169.48s |  company name, in some cases the name of the contact, uh, phone number, email address, and
1169.48s - 1174.48s |  so on and so forth. So, with this in mind, we found something surprising. And that is, that
1178.02s - 1183.56s |  it's not only small boutique-like companies affected by this. In fact, many of the companies
1183.56s - 1188.56s |  are on the Fortune 500 list. Some of the most valuable ones were worth 200, respectively 50
1188.92s - 1193.92s |  billion dollars. We found three large telecom companies, which you've definitely heard about in
1196.86s - 1201.30s |  the past. Ten relevant security and tech companies, and several others in consulting,
1201.30s - 1208.04s |  education, health, manufacturing. Now, unfortunately, we cannot disclose much more about the
1208.04s - 1213.88s |  companies at the moment, but maybe in the coming weeks or months we will be able to do so. Now,
1213.90s - 1218.90s |  you may ask, well, anybody can write whatever they like in the contact information in the AWS
1221.24s - 1226.58s |  account, right? And you're absolutely right. And then our efforts for identifying the
1226.58s - 1233.22s |  owners could have been completely in vain. However, here is where our OSINT came in. We did
1233.22s - 1237.12s |  quite a bit of OSINT, went on social media, including LinkedIn, and found several of these
1237.12s - 1242.76s |  owners. Funnily enough, many of them had several AWS certifications on their accounts,
1242.78s - 1248.14s |  suggesting that they are security aware and know how to properly configure their AWS
1248.14s - 1255.37s |  accounts. Now, one of these companies, which was and still is actually on the Fortune 500
1255.37s - 1260.37s |  list, had a program on bug crowd. So we reported it. And this way we got our first P1, our
1262.77s - 1267.71s |  first confirmed critical vulnerability on a bug bounty platform. That was absolutely
1267.71s - 1275.24s |  fantastic for us. Oh, thank you. Thank you. Now, let's see, how much do you guys think
1276.68s - 1281.82s |  we made out of it? So, who thinks we made between $10,000 and $100,000? So, let's say
1281.82s - 1286.82s |  5 digits. Yeah, only a few hands up. Maybe 4 digits, so 1,000 and 10,000? Right, a few
1289.46s - 1294.50s |  more. Well, let's say AWS or cloud in general is niche, maybe they don't really care about
1294.50s - 1299.50s |  these accounts. Maybe 3 digits? Okay, yeah, that's pretty low. Um, yeah, we made $0 out
1299.50s - 1304.50s |  of it, nothing. Uh, yeah, thank you, absolutely. Um, well, to be fair, there's a bit of a
1312.12s - 1318.62s |  catch. It wasn't a bug bounty program, it's, it was a vulnerability discloser program. And
1318.62s - 1323.86s |  we weren't too disappointed to be fair. Because we didn't really aim to make money out of
1323.86s - 1328.86s |  this research. We just wanted to make the internet a safer place. Although this sounds a
1328.86s - 1335.20s |  bit cliche. But still, we quickly forgot about this because we found something else which I
1335.20s - 1341.30s |  think was more interesting than this. I like to call this story, how we earned and lost $3
1341.30s - 1346.68s |  million in a week. And, well, we're in Vegas right now, we all know a thing or two about
1346.68s - 1353.38s |  losing and earning money quickly, right? Um, maybe not quite $3 million. For a bit of
1353.38s - 1359.82s |  context, we found this company which had a public AMI, there was a git repository within that
1359.82s - 1366.82s |  AMI, and within the git repository we found, um, a Stripe API key. And for those of you who
1366.82s - 1373.20s |  don't know, Stripe is a payment service not unlike PayPal. So our first thought was, okay,
1373.20s - 1378.20s |  let's run a balance call to the API and that's what we got. Uh, 7 digits in the USD currency. So
1378.56s - 1383.56s |  what looked like $3.1 million. Fantastic. So our first thought, of course, was, well, how
1387.44s - 1392.74s |  would a threat actor go about transferring these funds into their own account for research
1392.74s - 1399.32s |  purposes only, trust me. Only research. So we went to the documentation and we quickly
1399.32s - 1406.57s |  realized that the amount is in cents. So what we thought was $3.1 million was actually
1406.59s - 1413.23s |  $31,000. Of course, we were very disappointed. Um, we had to get over the disappointment
1413.23s - 1418.51s |  that our net worth reduced from $3.1 million to $31,000 by simply reading the
1418.51s - 1425.01s |  documentation. So if there's any conclusion here, don't read the documentation. Um, just
1425.01s - 1430.91s |  joking of course. Uh, so we wrote an email to their security contact, let them know what's up
1430.93s - 1438.11s |  and waited and waited and waited. And all we got was radio silence for a few weeks. It was
1438.11s - 1442.37s |  pretty annoying to be fair. We thought, well, did we do something wrong? Didn't we prove
1442.37s - 1447.39s |  impact? So we thought of proving impact and that's what we did. We, or I, uh, registered to
1451.15s - 1458.40s |  their, uh, cheapest plan which was $9.99 per month. Confirmed the transaction from the
1458.46s - 1463.46s |  API. And did a refund call which was successful. Fantastic. And a second level of validation
1466.96s - 1472.40s |  was that, uh, the transaction was reverted. So my money was back in my account and I could
1472.40s - 1477.84s |  still use their services which I didn't do because I didn't need their services. But now this
1477.84s - 1482.58s |  was a bingo moment for us cause we knew that we can talk about money. So we contacted the
1482.58s - 1488.08s |  CEO but for this we had to go on LinkedIn, found the CEO, do a bit of OSINT, get their email
1488.10s - 1493.64s |  address, and write to them. And guess what? Within a couple of hours we got a response where
1493.64s - 1498.64s |  he also CC'd the CTO and asked us for more info. And we provided more info. We gave them a
1501.78s - 1507.72s |  comprehensive report including the finding, the impact of the finding, uh, and steps for
1507.72s - 1512.72s |  remediating this. And what we got in response was a pretty dry message from the CTO saying,
1513.08s - 1518.08s |  thanks for sharing the relevant information, we have made the AMI private. For now. Like what?
1520.32s - 1525.32s |  For now? Okay. And we'll be replacing the keys. Thanks so much for responsible disclosure.
1529.02s - 1534.96s |  We took that as a thanks bye. And yeah, honestly we were a bit disappointed but we had a lot
1534.96s - 1539.04s |  of research to do. We had to go back to our research and just, uh, dig through the 500
1539.06s - 1545.70s |  gigabytes of data which we already got. However, one month later I was forced to remember the
1545.70s - 1550.70s |  issue. I checked my bank account and there's a 999 transaction. So I was so excited about
1553.24s - 1558.24s |  being able to do the refund that I completely forgot to cancel my subscription. Oh. Well,
1561.02s - 1567.26s |  remember that we are fairly broke so we, I didn't want to let 999 go by just like that. So I
1567.28s - 1572.28s |  went back into the API, did the same call again and guess what? Money was back in my account.
1574.36s - 1580.86s |  Yes, thank you. Yup. Well, we were disappointed initially by the dry response. But you cannot
1584.10s - 1589.10s |  even imagine our disappointment that the issue was still not fixed one month later. Now,
1591.94s - 1597.20s |  there's way more impact than just this. Think about it this way. We had to spawn several EC2
1597.22s - 1602.88s |  instances in our account. We got a bill of 500 dollars which, well, I'd have preferred to
1602.88s - 1607.86s |  avoid. So, yeah, if we weren't ethical we could have went and used the, um, victims, so to
1610.40s - 1615.40s |  speak, AWS accounts, uh, to do this research for free. Now, a second potential area of impact,
1618.14s - 1623.14s |  uh, which I think has a bit more potential, um, well, AWS based ransomware. Um, and this way I
1623.32s - 1628.32s |  could have come to DefCon for free. Um, so, typically when we think about ransomware, we
1631.32s - 1637.16s |  think about these teams of developers working 24-7, uh, working on evasion and stuff like
1637.16s - 1643.04s |  that. Uh, perhaps when, when we talk about ransomware as a service, uh, they're using, uh,
1643.04s - 1648.04s |  24-7, uh, customer support teams and call centers. Well, in here, with access to the
1648.38s - 1653.38s |  profiles, to the accounts, we could have used this, well, one liner or four liner, depends
1657.46s - 1662.46s |  how you write it, to list every S3 bucket within the accounts, copy all of the data to our
1666.46s - 1671.46s |  local systems and then remove all the data. Now, instead of the data which they expect to
1671.76s - 1678.26s |  have on their accounts, they could find something along these lines, a ransom note. All your
1678.26s - 1682.50s |  files have been stolen, you must buy us a Romania, Las Vegas ticket to get your files. And
1682.50s - 1687.08s |  honestly, that would have been pretty reasonable, it's only what, 500, a thousand dollars, so
1687.08s - 1692.08s |  yeah, pretty decent ransom. And I need this disclaimer here, this is just a joke. We didn't
1694.48s - 1700.48s |  do this and we wouldn't do this, but it's pretty cool that we could have done this, right?
1700.48s - 1705.48s |  Now, Eduard, wanna take over? So, the research was done, uh, we collected the data, we found
1708.12s - 1715.12s |  secrets, we validated them, but we wanted to bring down the impact of the effective companies
1715.12s - 1721.10s |  before we, we published the research. So, we looked for, uh, contacted, contact details and
1721.10s - 1727.10s |  we couldn't find many, we had to search for websites to go find their contact information,
1727.10s - 1734.10s |  give some generic email just to make sure we don't give out too much information to, to
1734.10s - 1739.30s |  someone that doesn't need to know it. So, we sent almost 70 responsible disclosure emails
1739.30s - 1744.48s |  and we received less than 10 responses. We had to do some weird things like contacting the
1744.48s - 1749.08s |  national search for one company, scheduled a sales call just to tell them about the
1749.08s - 1754.08s |  vulnerability and 90 days later after we did all this, only 10 AWS keys were invalidated. So,
1758.10s - 1764.70s |  that sucked and it's like companies are using AWS and they are ignoring responsible
1764.70s - 1768.64s |  disclosure, they don't have contact details, they never wrote an access keys and they are
1768.64s - 1774.14s |  like, man, this cloud thing is so unsafe. It's not like that, right? And in a desperate
1774.14s - 1781.04s |  attempt to invalidate more keys, we notified AWS security team and we were, we were like, I
1781.06s - 1787.06s |  know this is weird but we got 120 access keys that are valid. Here are, here is the proof,
1787.06s - 1793.40s |  um, can you invalidate them? We have a research we want to publish it. And the AWS security
1793.40s - 1800.34s |  team, the most amazing team we, we worked with, um, they made me rethink about the whole
1800.34s - 1805.34s |  responsible disclosure process and after a few days after contacting them, more than 60
1805.34s - 1810.48s |  AWS keys were invalidated. We had a meeting about the research, we provided some, some
1810.52s - 1816.10s |  ideas, we discussed fixes and it was overall an amazing experience and I want to give a
1816.10s - 1821.90s |  huge high, uh, a huge shout out to Christian Severt from, uh, from AWS security team and
1821.90s - 1826.90s |  uh, AWS security outreach team. So, please give them a round of applause. Thank you.
1830.04s - 1834.04s |  Now, to discuss a bit about detecting and defending against this and let's start with
1834.04s - 1842.04s |  defending. So, if your AWS account has this, um, yellow warning signs, you, you, you might
1842.04s - 1847.76s |  want to look into it. So, the settings block public access for AMIs and ABS snapshots
1847.76s - 1852.56s |  should be enabled. They should look like this, they should, should have this green check
1852.56s - 1859.24s |  mark. You can also use the CLI to validate if you have public AMIs. Make sure to check
1859.24s - 1865.08s |  every region and uh, make sure to check for deprecated images. You have to be careful
1865.08s - 1870.58s |  about this because one technique attackers are using to exfiltrate data is by making AMIs
1870.58s - 1876.66s |  public and accessing them from their account and if that happens to you, you should look
1876.66s - 1882.16s |  in CloudTrail for this event, shared snapshot volume created. This is the only event you
1882.16s - 1887.26s |  get in CloudTrail if someone accesses your public AMI and it doesn't have a lot of
1887.26s - 1894.10s |  information. As you can see the IP address is hidden which I get it. It's protecting the,
1894.10s - 1900.00s |  the, the customer that is accessing the API, the, the AMI, that is cool. But the only
1900.00s - 1904.94s |  identifiable information you have is the account ID which you can't do much uh, with it,
1904.94s - 1909.78s |  right? So, better be careful, better protect your account and enable uh, enable the
1909.78s - 1916.22s |  settings if you don't plan to publish AMIs or uh, or uh, ABS snapshots. Now, we have a lot
1916.22s - 1921.22s |  of data and we did other research with uh, with it. And one idea we had was, so we had
1923.72s - 1930.06s |  20K JSON web tokens and we looked if there are any tokens that were not expired, maybe
1930.06s - 1934.70s |  they had some secrets in them, any other misconfigurations but nothing came out of it.
1934.70s - 1941.08s |  However, it was a, it was a good try. Next, we looked through our 4K unique SSH private
1941.08s - 1945.94s |  keys, we generated public keys and a figure print and we searched on showdown but nothing
1945.94s - 1951.98s |  uh, nothing came out of it. Uh, one idea was to perform the same scan from within the AWS
1951.98s - 1956.96s |  network. Maybe that's how uh, we might find some, some servers but that was just too much
1956.96s - 1961.96s |  work and uh, it wasn't worth it. Another cool idea we had but we haven't started this yet. So,
1964.30s - 1969.84s |  we collected a lot of private, a lot of repositories and some of them are surely private.
1969.84s - 1974.80s |  We wanted to identify the private repositories to identify the deployed web application in
1974.80s - 1981.20s |  the wild and then perform source code review um, in order to find some vulnerabilities, get
1981.20s - 1987.88s |  some CVs, get some bounties but that is a lot of work and we, we are keeping it for um, for
1987.88s - 1994.76s |  later. And that is not all. Matei if you will. Yep, so while we're on the topic of further
1994.78s - 2001.88s |  research, well we still have about 500 gigabytes of potential secrets and we tried our best to
2001.88s - 2008.46s |  dig, dig through that data but there's definitely way more to find. Moreover, our colleague
2008.46s - 2015.06s |  from KPMG Romania, Stefan Tica, worked on some similar research uh, on Azure and we are
2015.06s - 2020.64s |  looking forward to his research being published as well in the near future. Also, we will
2020.66s - 2025.66s |  soon make a word list public with all the files which we found in all these public AMIs which
2028.06s - 2034.06s |  we scanned. Now, going back to the research objectives formulated by Edward at the
2034.06s - 2039.06s |  beginning of this talk. We aim to dig for secrets in every public AMI across all AWS regions. And
2041.38s - 2048.38s |  while we didn't dig into all public AMIs, we dug into all public AMIs which we found
2048.38s - 2055.36s |  interesting. So I'd say that this was achieved. Also, we aim to have fun and yeah, we did. We
2055.36s - 2060.50s |  found a lot more stuff than we expected. It was a roller coaster and thanks Edward for this.
2060.50s - 2067.38s |  Lastly, responsible disclosure. Well, I was a bit disappointed by the responsible
2067.38s - 2074.38s |  disclosure process in general. Well, many of the owners uh, didn't, didn't respond to us.
2074.38s - 2079.38s |  Others, well, didn't have any sort of information for us to contact them. Um, however, the
2081.62s - 2087.52s |  experience of responsibly disclosing this to the AWS team definitely made up for all of the
2087.52s - 2093.90s |  less pleasant experiences so this was definitely achieved as well. Now, that we are
2093.90s - 2100.64s |  approaching the end of this talk, here are our conclusions. Firstly, the impact of this
2100.66s - 2105.66s |  research is not yet fully uncovered. There's still way more to find out there. We have found
2109.44s - 2115.08s |  several secrets already in the data which we collected. There's definitely more in the data
2115.08s - 2118.78s |  which we already collected but there's definitely way more out there which we did not
2118.78s - 2125.02s |  collect yet. Potentially, a nice area of research would be continuously monitoring new AMIs
2125.04s - 2131.38s |  becoming public. Secondly, security by obscurity is definitely insufficient. So many
2131.38s - 2135.98s |  developers definitely thought that their Git repositories were safe because they're private,
2135.98s - 2142.26s |  right? But how is anything private if it's placed in a public resource? Also, you may be
2142.26s - 2148.86s |  thinking, hey, I won't be a target of this, right? Nobody cares about my AMIs. Well, think
2148.86s - 2154.70s |  about it this way. Edward and I, two cyber security guys from Romania, were able to do this.
2154.72s - 2160.86s |  Think about what the threat actors could do. So definitely, don't make your AMIs public if you
2160.86s - 2165.86s |  don't have to. Now, AMIs are only the tip of the iceberg here. There are still a lot of other
2169.40s - 2175.74s |  interesting things to find across several other public cloud providers. Who knows, maybe
2175.74s - 2181.94s |  next year we'll be back here talking about how we dug for secrets in a different cloud
2181.96s - 2187.72s |  resource. And still, we encourage you to do your own research as well. And please, let us
2187.72s - 2194.74s |  know if you have any sort of ideas. We're happy to help. Actually, going back to my initial
2194.74s - 2200.90s |  point within the secret searcher section. Collaboration is definitely the most important
2200.90s - 2206.58s |  aspect of cyber security. So please, connect with us. Let us know if you need any help with
2206.58s - 2212.38s |  any sort of research in the future. And we'll definitely be happy to help. This being said,
2212.38s - 2228.51s |  thank you very much everybody. We appreciate you being here. Any questions? Yep. Sure, go
2228.51s - 2246.72s |  ahead. Is the mic on? Not yet. Can we get the question mic on please? Oh, perhaps just speak
2246.72s - 2258.31s |  really loudly. Well go ahead Edward. Uh, we don't know. So, we, we didn't perform any calls
2259.31s - 2264.31s |  beside the contact information. Um, so we tried to get uh, security operation and uh, another
2267.49s - 2272.39s |  type of contact details but we, we didn't check the permissions. I'm sure for some of them, we
2272.39s - 2277.19s |  surely could have. But yeah, that, that was too much because surely there were some
2277.19s - 2282.95s |  automation based on the uh, access keys and uh, we might have broke, uh, broken something.
2282.97s - 2288.51s |  So, yeah. Also, please note that just having the uh, S3 ransomware sort of code in my
2288.51s - 2302.57s |  terminal got my adrenaline rushing. So we, we didn't try to do anything like that. Yes. I
2302.57s - 2318.60s |  didn't have to, I wanted to. Sorry? Yeah, actually, so yeah, I'm looking for new
2318.60s - 2323.54s |  opportunities. If you have something in mind in the offensive security, cloud research or
2323.54s - 2328.28s |  cloud security, just give me a message. I'll, I'll start applying next week. So, thanks.
2333.32s - 2345.36s |  Cool. Any other questions? Yes, please. Uh, no, and to be fair, we didn't even expect that. I
2345.36s - 2351.94s |  mean, we had KPMG for that. So, thanks KPMG. And uh, we are waiting some t-shirts from the
2351.94s - 2361.02s |  companies we disclosed this. Thank you. Mic's working, so if anybody has any questions,
2361.02s - 2366.40s |  you can speak in the mic. Cool. Doesn't look like any other questions. We'll just be around
2366.40s - 2370.00s |  here, so please let us know guys. Nice talking to you. Thank you.