{
  "webpage_url": "https://www.youtube.com/watch?v=sp91zygVcmE",
  "title": "DEF CON 32 - Curious Case of Alice&Bob: What You Can Do as Digital Investigators - Catherine Ullman",
  "description": "The game is afoot! The curious case of Alice and Bob will explore beyond the surface of technical know-how. Attendees will navigate the intricate labyrinth of digital investigation, learning not just 'where' to seek digital clues \u2013 perhaps hidden in the registry \u2013 but crucially, 'why' these details matter and 'how' they fit into the larger puzzle of our investigation. Join me on a narrative adventure illuminating the practical use of tools in a real-world scenario. For both seasoned and aspiring digital sleuths, this talk aims to sharpen investigative skills, setting or recalibrating your expectations of what digital forensics can realistically achieve.",
  "channel_url": "https://www.youtube.com/channel/UC6Om9kAkl32dWlDSNlDS9Iw",
  "duration": 3233,
  "channel": "DEFCONConference",
  "uploader": "DEFCONConference",
  "upload_date": "20241016"
}

0.00s - 6.44s | This text was transcribed using whisper model: large-v2

 Alright, good afternoon everyone! Good afternoon. Welcome to DEF CON, welcome to Creator
6.44s - 13.22s |  Stage. Thank you for all being here. Um, before we begin, just a couple of quick notes. Uh,
13.22s - 18.22s |  number one, that these talks are being recorded and also being streamed. Um, as far as we
21.32s - 26.40s |  just got word that there is some technical difficulty with the slides on the stream, so we
26.40s - 32.64s |  apologize for that. Um, and yes, these, uh, the video of the talks will be available, uh,
32.64s - 38.84s |  eventually. Uh, you know, having done this for years, usually around, could be really
38.84s - 43.84s |  quick, or it could be in September or October. Um, for those of you, this is, if this is your
46.12s - 51.12s |  first DEF CON, welcome, welcome, enjoy. And, um, for this talk, it is proudly presented by
51.52s - 56.52s |  the Packet Hacking Village. And it is my pleasure to introduce to you someone we consider a
64.66s - 69.66s |  friend for years. She is the author of The Active Defender. Uh, and, uh, she also, and you
69.66s - 74.66s |  are all in for a treat today, that she has some, she has fascination and also, uh, good
86.14s - 91.14s |  knowledge on mysteries and, um, also the afterlife as well. Mmm, mmm. And it is my immense
91.14s - 96.14s |  pleasure to introduce to you all our first talk and our friend, Dr. Katherine Allman.
108.20s - 115.48s |  Thanks, Ming. So, uh, my, my handle's investigatorchick, for anyone who's looking, we'll
115.48s - 121.06s |  cover that in a minute. Um, this talk has essentially two things going on in it. So, you're
121.08s - 127.12s |  going to hit, see me giving a talk, but I'm also going to play the narrator role. So, you will see
127.12s - 132.12s |  two different things happening within this talk. So, this is just me telling you a little bit
134.26s - 138.50s |  first about what we're going to discuss. So, I'm going to give you a little bit of information
138.50s - 143.34s |  about myself, then we're going to talk specifically about the investigative process, then we're
143.34s - 147.58s |  going to talk specifically about some individual elements of that process, scoping, data
147.60s - 151.90s |  gathering, data analysis, data correlation, timeline analysis, and what goes on in
151.90s - 157.14s |  post-incident. Um, and then I'll summarize and we'll do some Q&A. Who here has some
157.14s - 162.74s |  background in digital forensics? A few of you. And who of you are just kind of like curious
162.74s - 167.66s |  about digital forensics? A bunch of you. Okay, cool. It's good for me to really have a good
167.66s - 172.66s |  feel for this. All right. So, a little bit about me. Um, as I said, my handle's investigatorchick.
173.18s - 178.18s |  Um, it's one letter too long. So, if you look for me on Twitter or X, whatever they're calling
180.42s - 186.32s |  it these days, it's investigatorchick, uh, only because there's a letter missing. Um, and
186.32s - 190.86s |  then on all the other platforms, it's investigatorchick. So, I've been at the University of
190.86s - 196.66s |  Buffalo for over 24 years, going on to 25. I'm on staff at a bunch of conferences, um,
196.70s - 202.90s |  including here, I'm with Packet Hacking Village. Um, I volunteer and am not full staff, but
202.90s - 207.24s |  volunteer for a bunch of other things. I've done a ton of speaking and I really love
207.24s - 213.36s |  sloths. So, this is my boy Flash that you can kind of see up here in that corner. Uh, I
213.36s - 219.90s |  adopted him at the zoo. So, let's talk about the investigative process. First of all, let's
222.50s - 226.54s |  back up and talk about what forensic science is, especially since many of you are new to
226.54s - 231.96s |  this field. So, it's this idea that we're going to apply science, right, to criminal and
231.96s - 236.96s |  civil law, although in some cases, we're not even looking at the details of law. So, um, in
238.30s - 243.20s |  my case, um, I do a combination of things, both with law enforcement, where that is the
243.20s - 248.20s |  case, and I also do things like employee relations. So, sometimes it's, it's policies.
249.48s - 255.48s |  But generally speaking, one of the history, the historians who is most important in this
255.48s - 261.62s |  field is this awesome guy named Edmund Locard. Who's heard of Locard? Anybody? A couple
261.62s - 266.56s |  people. All right. So, he's, he's awesome. He was a French criminologist. And where he's
266.56s - 272.40s |  really started was this idea of, um, dactylography, which is the study of fingerprints. And a
272.40s - 277.40s |  lot of what we use today came from what he originally created, which is pretty awesome. Um,
279.68s - 283.88s |  and he was a pioneer and, and worked in this field. And there were other folks who were
283.88s - 289.32s |  involved with it. And ultimately, he was the guy that we, we followed for the, for the
289.32s - 294.32s |  fingerprint stuff. So, this is his famous exchange principle. And it's this idea that, you
295.52s - 298.70s |  know, ultimately, if a criminal's going to do something, they're going to leave something
298.70s - 303.70s |  behind, right? So, every contact leaves a trace, is the sort of generalization that we make
304.90s - 309.90s |  for these folks. Um, but really what we're talking about, um, is the, the exact quote is
310.80s - 315.80s |  what you see on the slide here. That is what he actually said. So, for, for digital
315.80s - 320.80s |  forensics, we're talking about logs, typically. So, what do we mean by digital forensics?
322.54s - 327.64s |  Well, it's digital forensics because we're talking about digital mediums, right? So, digital
327.64s - 331.92s |  devices, we're usually talking about computer crime. And we're going to identify, we're
331.92s - 337.56s |  going to examine digital media and look for evidence of whatever it is in a forensically
337.62s - 342.56s |  sound manner. I'm not going to read these, um, descriptions to you because I know you can
342.56s - 348.60s |  all read them yourselves. Um, but this is the basic idea. And the process in digital
348.60s - 353.60s |  forensics, and we'll see how this is a little different from traditional forensics. So,
353.60s - 358.94s |  things like DNA, um, we'll talk about in just a second. But what's really important is
358.94s - 364.84s |  that we acquire this evidence that we're going to take a look at and we're going to
364.84s - 369.30s |  acquire it with the understanding that we're not going to change anything. We need
369.30s - 374.48s |  something called chain of custody. So, you can see that form on the, on the one side
374.48s - 378.84s |  that talks about specifically, um, I know the, the form itself is sort of hard to read,
378.84s - 383.68s |  but it, it's a property evidence form. So, what happens is when you collect this
383.68s - 388.02s |  information, so you, you, you get a computer, you get a drive, or you get something that
388.02s - 393.60s |  you're going to image, it shows the transition of who had it from one to another. Because
393.62s - 400.02s |  if you can't show a clear and distinct path that that evidence went, then something could
400.02s - 404.54s |  have changed or been messed with. I'm sure at least some of you have heard about this
404.54s - 409.60s |  on the news. Yes? Yeah. So, this is really important, especially in the, in the criminal
409.60s - 415.04s |  side of things. Um, we use sometimes what are called right blockers. In fact, I, I almost
415.04s - 420.72s |  always use right blockers because they, uh, there are physical and there are, um, software
420.72s - 425.10s |  kinds of right blockers. The thing you see the picture of in that bottom corner is a
425.10s - 431.02s |  physical right blocker. So, you plug your device into, uh, whatever thing. So, in that
431.02s - 436.00s |  picture there, you see a thumb drive plugged into it. And then that prevents anything from
436.00s - 441.82s |  being written or changed on the disk. Same basic concept with software, but, um, hardware
441.82s - 446.50s |  tends to be kind of the gold standard. And so, we, we have to, you know, authenticate.
446.50s - 451.92s |  We have to make a copy of that information without changing the original. And that is
451.92s - 457.58s |  how we do that. So, I mentioned there's a distinction between traditional and digital
457.58s - 465.80s |  forensics. Who watches things like CSI or, um, you know, any of the TV shows that deal
465.80s - 470.60s |  with criminalistics? At least a few people, right? Yeah. And I get a lot of people who
470.60s - 474.64s |  say, oh, that stuff's crap. And what I'll tell you is that's actually not true. There's
474.64s - 480.44s |  a lot of stuff that's, like, legit on those shows. What's not real is the time frame.
480.44s - 486.70s |  The time frames are like, you know, we're going to do a DNA analysis. It took 30 minutes.
486.70s - 491.26s |  Badass. Except that, you know, in real life, DNA could take, like, months to come back
491.26s - 497.50s |  because it's a very, very slow process. But with traditional forensics, like DNA, you
497.50s - 503.64s |  have to destroy the evidence to actually collect it and analyze it. So, for DNA, you take a
503.64s - 508.60s |  sample and that sample's run through a process and the act of running it through a process
508.60s - 513.28s |  changes it. Same thing with, like, something like fingerprints, right? When I collect a
513.28s - 519.40s |  fingerprint, whether it's using tape or some other mechanism, you're altering that. You
519.40s - 525.56s |  can't keep it pristine. But they don't expect that you can do that with digital forensics.
525.56s - 531.76s |  It's a very big distinction. They don't want us changing anything. All right. So, let's
531.76s - 536.80s |  move along to the actual investigative process. So, we have a number of steps. This is a very
536.80s - 543.20s |  high-level talk. I'm going to talk a little bit about tools, mostly to kind of give you
543.20s - 548.76s |  a hint about what kind of tools we use and maybe how we use them. But this is not a tool
548.76s - 555.00s |  talk. So, lots and lots and lots of talks cover forensic tools. So, there's lots of
555.00s - 559.48s |  stuff out there. But I wanted to focus more on the process and the mindset and the thinking
559.52s - 564.56s |  behind this than I do about the specific tools. So, these are going to be our steps. So, the
564.56s - 570.56s |  first step is the scoping call. And, oh, and I want to mention that you're going to see
570.56s - 576.20s |  this process often is not linear. We go from one to another and then we may go back and
576.20s - 596.29s |  we may see that process need to be repeated. So, let's go on to our next slide. So, here,
596.29s - 602.41s |  this is where I get to be your narrator. The scoping call. Detective Olivia Hart sat
602.41s - 607.41s |  in her dimly lit office, the soft glow of her desk lamp casting long shadows across
607.41s - 612.69s |  the worn wooden surface. The room was silent, save the occasional creak of the floorboards
612.69s - 618.85s |  beneath her feet. She leaned back in her chair, running a hand over her tired eyes. Her cell
618.85s - 625.05s |  phone rang, shattering the eerie silence. Detective, it's Captain Anderson. We've gathered
625.05s - 629.33s |  some members of the digital forensics team to assist us with this latest homicide. The
629.33s - 636.17s |  victim is Bob Byte. The sound of shuffling papers filled the air as team members began
636.17s - 640.57s |  to take notes and prepare themselves for the investigation ahead. The captain ran through
640.57s - 646.65s |  the basics, the time of discovery, the initial observations, and the victim's identity.
646.65s - 651.21s |  Any leads, Hart asked, her voice cutting through the background noise on the line. We're focused
651.21s - 657.61s |  on Alice Askey, Anderson replied, his mind racing as he considered the possibilities.
657.61s - 662.61s |  We're currently interviewing friends and neighbors that they interacted with regularly. All right,
662.61s - 675.14s |  Hart said, her tone firm and decisive. Keep us updated. All right. So, the goals of the
675.14s - 679.98s |  scoping call were things we just heard a little bit in the narrative, right? So, we need a
679.98s - 685.34s |  summary of what happened. We need a bunch of details about any individuals. We're going
685.34s - 690.54s |  to get some time stamps of some key events. And we're going to get some other details
690.54s - 697.04s |  around that incident. And we're going to establish the objective. What is it that you as a forensicator
697.04s - 703.46s |  are tasked with doing? And today, you all get to be a little bit of a forensic investigator
703.46s - 711.58s |  because I'm going to ask you to join me in this story. So, this is the initial information
711.58s - 719.46s |  you as the forensic investigator are given. Bob is dead. We knew this. He, the police
719.46s - 728.30s |  are called to 456 Central Avenue. Bob is found deceased. He's found deceased at 1201 a.m.
728.30s - 735.78s |  on February 13th, 2022. And they estimate his time of death to be about three hours
735.78s - 744.38s |  before that. Important note. What the cops tell us is that he appears to have been stabbed.
744.38s - 750.30s |  And he's known to have this existing relationship with Alice Askey, the other name that we heard.
750.30s - 756.62s |  And she lives at 123 Main Street. The police are pretty sure Alice went to Bob's house
756.62s - 764.62s |  and killed him. And you've been asked to work with the team to investigate the digital relevant
764.62s - 771.02s |  information and determine Alice's involvement. These are the specific objectives you are
771.02s - 777.82s |  given. The police have asked you to perform an analysis on the information. And they want
777.82s - 784.06s |  to know what evidence exists that proves Alice killed Bob and why did Alice kill Bob? Now,
784.06s - 791.54s |  I'm here to tell you in the talk title of my talk hints at this. These are not good
791.54s - 799.14s |  questions for forensics. Forensics cannot tell you why somebody did something. It cannot
799.14s - 805.38s |  tell you that someone did something at all. It can tell you what happened on a system.
805.38s - 813.32s |  It cannot always put hands behind keyboards. So these are not necessarily good objectives.
813.32s - 818.34s |  This kind of challenge is presented to us regularly in forensics. Open-ended questions
818.34s - 823.50s |  are not things forensics can typically answer. We just discuss what kinds of questions forensics
823.50s - 830.42s |  is not meant to cover. So like, you know, why someone did something, who did something
830.42s - 836.82s |  specifically. You often have incorrect assumptions, right? What assumption did we hear that was
836.82s - 844.30s |  a problem? Alice killed Bob, right? Like we're just getting started and we're already assuming
844.30s - 850.42s |  Alice killed Bob. That is not a good thing. They're often unrealistic timeframes and there
850.42s - 857.70s |  are limitations to what we can recover. Sometimes the scope winds up being too huge and it has
857.70s - 864.36s |  to be broken down. And sometimes requests are incomplete. So like asking for a particular
864.36s - 870.56s |  type of social media, but really wanting all the social media. So these are all challenges.
870.56s - 875.48s |  So as a result, we revise those objectives to fit more with what forensics really can
875.48s - 882.32s |  answer. So better questions that forensics can handle. Was there any activity on the
882.32s - 889.04s |  devices around the time of death? Is there evidence to indicate involvement, right? Not
889.04s - 894.64s |  to say that someone definitely did something, but could there have been a person involved?
894.64s - 899.12s |  And we want to look at all that relevant digital communication between Alice and Bob since
899.12s - 911.66s |  we know there is an existing relationship. That is a reasonable thing to do. The forensics
911.66s - 917.46s |  team sprang into action, setting up their equipment and connecting cables to Bob's laptop.
917.46s - 922.50s |  One technician began the process of creating a forensic image of the laptop while another
922.50s - 928.78s |  meticulously documented every step, ensuring the integrity of the evidence. Meanwhile,
928.78s - 933.12s |  Detective Hart scanned the room for any other digital devices that might hold clues. She
933.12s - 937.84s |  spotted a smartphone lying on the floor near the victim's body and carefully bagged it
937.84s - 943.48s |  for further analysis. Finally, after what felt like an eternity, the forensic team finished
943.48s - 950.32s |  their work. They carefully packed up the equipment, leaving the room as they had found it. Simultaneously,
950.32s - 956.28s |  additional police officers paid Alice Askey a visit at home. They encouraged her to do
956.28s - 962.36s |  the right thing if she has nothing to hide. And as a result, they convinced her to provide
962.36s - 967.04s |  her laptop and cell phone to them for examination, along, of course, with the passwords to these
967.04s - 973.48s |  devices. So that evidence and the items collected at the scene were quickly turned over to the
973.48s - 986.97s |  forensic lab for imaging and processing. So when we do data gathering, because this is
986.97s - 993.29s |  the data gathering section, we may be gathering data that's not necessarily digital. And this
993.29s - 997.97s |  can be a real challenge because what happens sometimes, sometimes you go in the field doing
997.97s - 1001.75s |  this and you do it yourself. And sometimes somebody, a different team or other people
1001.75s - 1005.69s |  go into the field. So sometimes you're going to get different information from different
1005.69s - 1010.69s |  folks at different times. It can be really chaotic. But these are the kinds of things
1010.69s - 1016.49s |  that are examples of stuff we might collect. So, you know, we might have to take a forensic
1016.49s - 1021.73s |  image on scene. You know, maybe we need some log files. This all really depends on the
1021.73s - 1029.73s |  very specific case. What kind of tools do we use? Well, we use forensic tools like FTK
1029.73s - 1035.97s |  Imager, NCASE X-Ways, Axiom. You'll see a whole list here. We'll see some pictures.
1035.97s - 1040.05s |  Sometimes scripts are used. Cameras are handy. Sometimes it's best to take photographs. We
1040.05s - 1045.01s |  might see passwords on, I don't know, Post-it notes. Because no one's ever seen that under
1045.01s - 1052.53s |  a keyboard before, right? Nobody ever does that. So we might do video, but video is encouraged
1052.53s - 1056.77s |  to do with no sound. Sound can get you in hot water because people sometimes say things
1056.77s - 1062.57s |  on scene that maybe they shouldn't be saying. And of course, sometimes you just take notes.
1062.57s - 1067.77s |  Old-fashioned paper and pen are great for that. So I know this is a little fuzzy, but
1067.77s - 1074.77s |  this is Axiom GrayKey. It's only available to law enforcement. And it's used to gather
1074.89s - 1081.89s |  data off phones, typically. And it can do phone image extractions.
1083.25s - 1090.25s |  So this is with an FTK Imager. FTK Imager is often used for acquisitions and analysis
1090.93s - 1096.09s |  of files and file systems. And I know this is kind of tough to see. The only thing you
1096.09s - 1103.09s |  really need to pay attention to is the little tiny yellow thing that says EXFVE, that little
1103.17s - 1107.85s |  tip. And we'll see what that means later. And I'll have a blown-up so you can see that
1107.85s - 1114.37s |  better. This is NCASE Forensic. This is another really common tool that is used for acquisition
1114.37s - 1121.37s |  and analysis. And this is Autopsy. Autopsy is a free tool. So I'm showing you a mixture
1121.93s - 1128.33s |  like NCASE costs money, FTK Imager is free. This tool is also free and can do all kinds
1128.33s - 1134.89s |  of cool analysis, acquisition, that kind of thing. And again, we'll get into some examples
1134.89s - 1141.89s |  of that later. So these are some related questions. So often because you have limited time frames,
1143.77s - 1147.81s |  you have to know what you have to prioritize. Because if you only have so much time to do
1147.81s - 1153.81s |  an investigation or to analyze a particular piece of evidence, then it's problematic if
1153.97s - 1158.65s |  you have tons of data, right, and you have to, you know, get through it all. Maybe you're
1158.65s - 1163.17s |  not going to get through it all, so maybe you need to prioritize. You need to ask if
1163.17s - 1167.01s |  you're not the one on scene, or even if you are, you might ask the other folks who are
1167.01s - 1170.97s |  there, did you see anything interesting? And, you know, again, is there a restriction for
1170.97s - 1176.23s |  the timeline? Now, there are a lot of challenges. We've already talked about a couple of them.
1176.23s - 1180.53s |  You might acquire unnecessary data. So you might take a whole bunch of systems, take
1180.53s - 1184.05s |  images of things, or take systems with you that are not related at all, and you may not
1184.05s - 1191.05s |  know about that. You might really need a piece of data that is completely unavailable. So
1191.05s - 1195.09s |  the device is encrypted. You don't have the key. Maybe something's inaccessible. It's
1195.09s - 1200.13s |  behind a login. Because by default, even doing criminal case, you don't have the right to
1200.13s - 1206.61s |  necessarily log in and grab that data. You need permission for that. Again, time frames
1206.61s - 1213.89s |  are always an issue. Maybe there's regulations, ISO or other regulations, right? So which
1213.89s - 1219.17s |  could tell you either you have to or you can't collect certain kinds of data. Maybe the stuff
1219.17s - 1226.01s |  you brought to do the collection, wrong size, wrong dongles, wrong, you know, media, whatever,
1226.01s - 1231.85s |  and maybe you're doing a collection of a particular type of file system that you don't have tools
1231.85s - 1241.37s |  to collect. So this is the, that is the blown up screen of the FTK imager you saw earlier.
1241.37s - 1245.69s |  Now, I can tell you that the digital forensics team, when they were working on this, they
1245.69s - 1253.90s |  saw that. Does anybody recognize what that tells you? BitLocker, yeah. So the team was
1253.90s - 1260.14s |  like, oh, wow, this laptop's encrypted. So what they had to do is they had to take, they
1260.14s - 1266.62s |  could not take a full image, right, because they don't have the password. What happens if they
1266.62s - 1274.22s |  try to take a full image of this machine without a password? Yeah. You have an encrypted brick,
1274.22s - 1279.50s |  spot on, right? So instead, they take what's called a logical disk image, and the logical
1279.50s - 1284.46s |  disk image will capture basically whatever you can see sitting there working on it, but it's,
1284.46s - 1298.14s |  you're not going to see some of the underlying data systems. All right. The whirring of hard
1298.14s - 1302.54s |  drives mingled with the soft glow of computer screens in the brightly lit forensics lab.
1303.26s - 1309.90s |  Detective Hart stands at the helm, her eyes sharp and calculating. She scans the array of devices
1309.90s - 1316.06s |  laid out before her, two laptops, two cell phones, each holding secrets waiting to be unearthed.
1316.86s - 1322.22s |  Beside her, Maya Patel, the team's lead forensic expert, delicately examines the data retrieved
1322.22s - 1328.54s |  from Alice and Bob's laptops. Meanwhile, across the room, agent Mark Thompson meticulously dissects
1328.54s - 1334.54s |  the data from their cell phones, his brow furrowed in concentration. With each tap of his fingers,
1334.54s - 1340.94s |  he builds back layers of text messages and call logs, his determination unwavering as he hunts
1340.94s - 1352.56s |  for clues. All right. So the goals of data analysis, we're going to look for scoped indicators.
1352.56s - 1359.92s |  So remember that we had some goals in terms of what we were, our objectives were. So in terms
1359.92s - 1364.56s |  of being given that initial information, you know, we're looking for names, right? We might be looking
1364.56s - 1369.52s |  for user accounts, anything that was sort of point back to what we were told in the beginning.
1370.16s - 1375.68s |  And then from there, we might pivot because we might find something interesting. So, you know,
1375.68s - 1379.44s |  you might see a particular keyword that might take you to something else.
1380.56s - 1386.24s |  You need to document those findings. And timestamps are critical. If you take nothing
1386.24s - 1393.20s |  else away from this and you're interested in forensics, universal time, UTC is your friend.
1393.20s - 1398.08s |  I see some smiles out there. How many of you that do digital forensics are like, oh my God,
1398.08s - 1405.36s |  why won't they just give me everything in UTC? Yeah. So one of the most frustrating things is
1405.36s - 1409.92s |  that you sometimes get logs in all these different time zones and then you have to correlate
1409.92s - 1414.80s |  everything, which we'll talk about later. And that's a major pain in the drain. So make sure
1414.80s - 1421.44s |  that you're documenting not only the time, but what time zone, whether it's UTC or not, whatever.
1423.28s - 1428.72s |  You know, where'd you find it? You know, if there's code, you know, you want all of that
1428.72s - 1434.24s |  information. And document anything that's weird that maybe you don't see that you would expect
1434.24s - 1441.84s |  to see, because a lack of evidence is itself evidence. We use a bunch of different tools for
1441.84s - 1446.96s |  data analysis, very similar to what we saw for collection, because a lot of these tools do the
1446.96s - 1452.48s |  same thing. So we already saw a magnet gray key. They have another product called Axiom,
1452.48s - 1458.48s |  which is available to regular forensicators, not just law enforcement. We talked about autopsy.
1458.48s - 1463.84s |  Eric Zimmerman has some free tools. There's something called Obsidian Forensics Hindsight,
1463.84s - 1469.04s |  which I believe is free. We've already mentioned NCASE, X-Ways, FTK, and there's also a product
1469.04s - 1475.20s |  called NUIX. Celebrate Inspector, which is again phones, and Volatility, which is for memory
1475.20s - 1483.12s |  forensics. So this is Celebrate Physical Analyzer, which again can be used to recover an image and
1483.12s - 1489.60s |  do some analysis on phones. You know, and often you use more than one tool to get the best results,
1489.60s - 1494.00s |  because one tool may only give you a certain piece of what you're looking for, and sometimes
1494.00s - 1503.02s |  you need two. So this is Magnet Forensic Axiom. So this is the tool that is available to anybody
1503.02s - 1512.14s |  who purchases it. And again, it can be used for looking at mobile or cloud, computer, vehicle
1512.14s - 1517.18s |  sources. It can do all kinds of stuff. And the evidence you're going to see today was processed
1517.18s - 1524.70s |  with Axiom to provide some SMS logs. So let's take a look at that. So this is a snippet of what
1524.70s - 1532.30s |  that looks like. This is Axiom Forensics, and this is the overview screen. And this is
1532.30s - 1539.92s |  Hindsight Internet History Forensics, which is used for parsing internet history. Now let's talk
1539.92s - 1546.24s |  about the challenges, okay? So again, you need permissions. If something's behind a login, you
1546.24s - 1550.32s |  can't just go, you know, even if you're law enforcement, you can't just be like, I'm gonna go
1550.32s - 1556.16s |  looking at all the things. You might ignore relevant evidence. Perhaps you collect all kinds
1556.16s - 1561.04s |  of stuff and you're like, ah, this isn't relevant, doesn't matter, I don't care about this. And that's
1561.04s - 1565.68s |  really easy trap to fall into, especially if you have a ton of stuff and you're a short
1565.68s - 1570.64s |  timeline. It's easy to assume something is irrelevant and then find out later maybe it wasn't.
1571.60s - 1576.88s |  So maybe you don't have the right tools to analyze. Maybe you suddenly find there's malware
1576.88s - 1582.16s |  on something, but the issue is really somebody who's dead. Maybe the malware is just, you know,
1582.16s - 1588.08s |  they're involved in other extracurricular activities and they got malware from that.
1588.08s - 1592.96s |  So you've got to be very careful you don't go down the wrong rabbit holes. It's very easy to
1592.96s - 1597.60s |  get tunnel vision. I'm looking for this, I'm only looking for this, and then oops, and I'm seeing a
1597.60s - 1602.96s |  bunch of nods, because yeah, some of you have been there. And follow through is really important,
1602.96s - 1607.04s |  right? You got to follow the, once you start down that rabbit hole, you often have to follow it all
1607.04s - 1612.48s |  the way down. So here's where we're going to get into what I think is the interesting stuff,
1612.48s - 1617.28s |  right? The meat and potatoes. So this is an SMS conversation between Alice and Bob,
1617.84s - 1625.28s |  and this is, once you take something like Axiom, you can then export the log information into a
1625.28s - 1629.76s |  spreadsheet, and I know this is impossible to read. So instead, I'm going to give you the
1629.76s - 1635.68s |  conversation in a much easier place to read. So I'll give you just a minute or so. We're going to
1635.68s - 1642.48s |  see that, you know, Bob and Alice are having a conversation. Alice is like, Bob, we got to talk.
1643.60s - 1649.76s |  And ultimately, when we get to the end, because there's one more slide here,
1654.72s - 1661.44s |  so what's the tone here? What do we think? Hostile, right? How about on this one?
1667.50s - 1673.02s |  This is a continuation of the previous. There's one more. Yeah, it's threatening, right?
1674.62s - 1684.64s |  Yeah. How about how it ends? Yeah, not good, right? She's kind of digging a hole.
1686.67s - 1692.99s |  So we get some information from PD. They let us know that Alice's fingerprints were all over the
1692.99s - 1697.79s |  victim's house, including on a kitchen knife, that has a profile that's very similar to the
1697.79s - 1706.92s |  murder weapon. Interesting. There's also some evidence that is a conversation between Bob B,
1707.72s - 1715.64s |  we know Bob Byte, right, and some mystery person. So Agent Thompson shows this to you
1716.20s - 1721.56s |  and makes it much easier to read this way. This is a much shorter conversation.
1725.66s - 1734.57s |  So this seems, what, a little sketch, but, you know, okay. So, I mean, this is just some evidence
1734.57s - 1742.08s |  that's collected. So then the PD comes back. They've been, you know, talking to folks to find
1742.08s - 1747.92s |  out more information. And they find out they're really concerned about Bob, because Alice has
1747.92s - 1754.40s |  a temper. We don't know that at all from reading the evidence we saw, right? And they also noted
1754.40s - 1759.36s |  that Bob, the neighbors have said, gee, Bob seems to have folks that come all hours of the night.
1760.08s - 1764.40s |  And maybe drugs, maybe there's some drug smuggling, something going on there. Interesting.
1767.88s - 1773.80s |  So then they start looking at some email logs. And the tool that's used here is called Paraben
1773.80s - 1781.56s |  E3. This is a tool that's specifically used to investigate email. And Maya shows you this and
1781.56s - 1787.72s |  says, huh, this is a Lyft receipt she got from Alice's computer. And it indicates that Alice did,
1787.72s - 1793.08s |  in fact, travel to Bob's house on the day of the murder. And here is it blown up, so you can see
1793.08s - 1798.92s |  it a little better. So we can see the pickup at 123 Main Street, which we know is Alice's house,
1799.56s - 1806.36s |  and the drop off at 456 Central Avenue. And we see that this is, in fact, at least one of Alice's
1806.36s - 1820.08s |  emails. We'll get there. Good observation, though. As the hours stretched on, the team's
1820.08s - 1824.96s |  efforts began to yield results. Maya unearthed a number of potentially important emails from the
1824.96s - 1829.92s |  laptop, while Mark's fingers fly across the keyboard, cross-referencing timestamps and
1829.92s - 1837.12s |  GPS coordinates in a relentless pursuit of the truth. His analysis of metadata ultimately reveals
1837.12s - 1841.44s |  a pattern of communication that can be linked to the prime suspect in this case.
1842.16s - 1845.68s |  Through trial and error, they each piece together fragments and information,
1846.40s - 1851.12s |  every breakthrough bringing them one step closer to unlocking the answers they are seeking.
1855.36s - 1863.31s |  So once we have all of this data, we need to correlate it, right? Bring all of this stuff
1863.31s - 1868.75s |  together from all these different places that we pulled it, normalize the findings. Again,
1868.75s - 1875.31s |  timestamps are your friend, and they need to all be in one UTC time zone so that you get a much
1875.31s - 1881.39s |  better picture of what happened. And then we're going to look for some patterns, which will help
1881.39s - 1886.59s |  us build a picture of what actually happened. So how do we do that? Well, we use some tools,
1887.39s - 1892.43s |  things like mind mapping software, and I've given some examples, but good old pen and paper,
1892.43s - 1898.43s |  even a regular old spreadsheet can be good for that. In this case, so far, what do we have? Well,
1898.99s - 1904.91s |  we have SMS messages from Bob and Alice's phones. We saw the email. We got some information from
1904.91s - 1912.91s |  PD. We can run into challenges at this particular place, too. Not enough context might be provided.
1913.47s - 1918.43s |  We might dismiss something as irrelevant, again, back to timeframes. We might just not take the
1918.43s - 1929.28s |  time to correlate. So then we're going to build a timeline. In the hushed confines of the digital
1929.28s - 1934.16s |  forensic lab, the team gathered around a large whiteboard, their eyes fixed on the intricate
1934.16s - 1939.12s |  timeline taking shape before them. Detective Hart stands at the forefront, her gaze intent,
1939.12s - 1944.16s |  as she directs the assembly of evidence into a coherent narrative. Next to her, Maya and Mark
1944.16s - 1948.80s |  meticulously arranged timestamps and digital artifacts, weaving together threads of data to
1948.80s - 1954.16s |  reveal the chronological sequence of events they uncovered. Each piece of information begins to fit
1954.16s - 1961.60s |  into the puzzle that was the grand design of their investigation. Across the room, Dr. Maya Rodriguez,
1961.60s - 1965.76s |  the forensic psychologist, examines the psychological profiles of the individuals
1965.76s - 1972.24s |  involved, her insights providing a crucial layer of context to the timeline. With each revelation,
1972.24s - 1977.52s |  she uncovers the layers of motive and intent, shedding light on the human elements driving
1977.52s - 1985.90s |  the digital drama. Why is it important that we have someone like that involved? Any guesses?
1989.48s - 1995.24s |  Right. I mean, there's so much that we don't know, right? So understanding the people involved can be
1995.24s - 2000.20s |  crucial. And what did I say digital forensics itself is not good at? It's not good at people,
2000.20s - 2006.04s |  right? It can tell you that a human probably was at a keyboard doing a thing, but it can't
2006.04s - 2013.64s |  necessarily tell you who or why. All right. So the goals of timeline analysis, we're going to
2013.64s - 2020.36s |  be looking for timestamps with everything. Again, UTC. Make sure you understand the attributes that
2020.36s - 2025.56s |  you're collecting, and then we're going to create a timeline. So tools that can be used with that
2025.56s - 2033.48s |  for that purpose. Again, Axiom. There's also a free tool called Log2Timeline. Excel is great.
2033.48s - 2041.16s |  There's a free tool called Timeline Explorer. We can have challenges with this. Maybe the timestamps
2041.16s - 2047.24s |  are missing, and maybe we don't know the particular time zones. Maybe we just forget about timestamps
2047.88s - 2055.39s |  and we just overlook them. So this is the tiny timeline of what we've uncovered so far.
2056.03s - 2061.95s |  We know that Alice sends Bob threatening texts. We know when Bob is killed. And then Bob is
2061.95s - 2069.23s |  discovered deceased. So what is your initial hypothesis based on the evidence provided?
2077.02s - 2082.30s |  Well, yeah, I mean, it's an interesting question, but if you only had what I gave you so far,
2082.86s - 2093.40s |  what does it appear to be? That Alice did it, right? Okay. So initially, our hypothesis is Alice
2093.40s - 2100.04s |  killed Bob. Because this is scientific evidence-based forensics, we're always going to do
2100.84s - 2106.04s |  a hypothesis and then see if we can prove the hypothesis or disprove the hypothesis.
2106.04s - 2113.00s |  Who here has seen the movie Clue? A bunch of you. Okay. So that's how it could have happened.
2115.45s - 2119.29s |  And Detective Hart looks at you when you come up with that hypothesis and says,
2119.85s - 2125.85s |  hmm, there's evidence that suggests that could in fact be the case. But have you exhausted your
2125.85s - 2130.33s |  search of all the evidence? Because I hear PD still has some information for all of you.
2131.29s - 2138.89s |  And they might have more information for us soon. So how about this? And look, we're back to data
2138.89s - 2144.49s |  analysis again, because we're going to look at some more data. So I know one of you caught this,
2145.29s - 2155.79s |  right? What did we not focus on when we looked at this the first time? The timestamp, right?
2155.79s - 2163.71s |  The timestamp was an hour after Bob was dead. So Alice went there, but a little too late to
2163.71s - 2174.27s |  kill him if he's already dead. A little weird. And then Maya discovers on Bob's machine that
2174.27s - 2179.07s |  there was some web activity. And if you look carefully at some of this web activity,
2180.27s - 2187.95s |  again, the timestamps are showing you after his time of death. Very strange. And if you look at
2187.95s - 2195.07s |  some of the descriptions here, we see some phishing things and some relationship counseling,
2195.07s - 2202.40s |  because we know there was a relationship going on there. Kind of interesting. So then we look
2202.40s - 2209.84s |  further. Maya continues to look for evidence on Alice's email. She finds another email address.
2209.84s - 2218.60s |  And she finds this very peculiar thing in Alice's email. What do you see here?
2220.88s - 2228.32s |  Bob's password and username, right? Huh. Interesting. So PD comes back to you and says,
2229.28s - 2236.08s |  I interviewed Alice Askey, and she found when she got there, Alice admitted she found him deceased
2236.72s - 2242.48s |  and knew she would be somebody they would look at. And she was so freaked out that she thought,
2242.48s - 2247.84s |  I know, I'll log into Bob's machine, I'll pretend to be Bob, and it'll be fine, because then they'll
2247.84s - 2255.04s |  know it wasn't, you know, it was somebody else. So she admits to this. So uh-oh, it's not Alice.
2255.28s - 2265.58s |  So here's what really happened. Just as they thought they were closing in on their target,
2265.58s - 2271.10s |  a new challenge presents itself. A strange file containing a bunch of random characters
2271.10s - 2276.06s |  buried deep within the directory of Bob's computer. Determined not to be thwarted,
2276.06s - 2280.70s |  the team pooled their expertise, each member contributing their unique skills to uncover
2280.70s - 2286.30s |  this latest mystery, which turned out to be an encrypted file. And finally, as the first light
2286.62s - 2290.14s |  And finally, as the first light of dawn filtered through the windows of the lab,
2290.78s - 2296.06s |  they triumphed. The encrypted file yielding its secrets and providing the missing piece
2296.06s - 2303.50s |  of the puzzle they needed to solve the case. The team sat down to just, oh, I'm sorry,
2303.50s - 2314.51s |  that's the next bit. So PD comes back to you. Remember that thread we saw, that conversation
2314.51s - 2320.59s |  between Bob and some mystery person? Well, it turns out that was somebody named Charlie C.
2321.39s - 2327.82s |  We're back to data analysis again, because now we need some stuff about Charlie C.
2328.38s - 2335.98s |  But as we're looking, this is where Maya discovers this very strange encrypted file.
2337.10s - 2345.50s |  It's a strange size. It's certainly nothing obvious. It's kind of hard to see, but it's a
2346.38s - 2352.94s |  file that, well, let me go back a slide here. You can see that it's Microsoft. It looks like
2352.94s - 2360.78s |  Minesweeper, but it's a weird name and a very strange size. And the gobbledygook that you see
2360.78s - 2366.38s |  in this what's called a hex editor, for those of you unfamiliar, this tells us this file is
2366.38s - 2372.94s |  encrypted. And because it's encrypted, Maya starts looking for other things having to do with
2372.94s - 2380.94s |  encryption. And she finds something called VeriCrypt installed on Bob's laptop. She knows
2380.94s - 2388.78s |  that that software can create an encrypted file. And she also has a tool called TC Detective.
2389.50s - 2396.14s |  She runs that tool against this weird file and, in fact, confirms this is the tool that was used
2396.14s - 2405.58s |  to encrypt that file. Hmm. It's just a piece of Python code. So this is something called
2405.58s - 2412.14s |  Shell Bag Explorer that Maya runs. And, again, I'll show you this blown up so you can see it
2412.14s - 2418.14s |  better. But Shell Bag Explorer is a free tool that you can use to explore something called a shell
2418.14s - 2425.02s |  bag. What is a shell bag? It is a registry entry that shows you information about user preferences
2425.02s - 2432.70s |  and some of their activities. In this particular case, it shows you a really weird mount point
2432.70s - 2440.30s |  called secret stuff. Because that doesn't sound sketch at all. So it can show you this tool,
2440.30s - 2444.62s |  things like right clicks and mount points. And it's part of, for those of you familiar,
2445.26s - 2453.02s |  registry keys called end user dot dat and user class dot dat. So what we see here is this,
2453.66s - 2459.58s |  you know, again, this path. Very interesting. And then PD comes back and they say, hey,
2459.58s - 2467.34s |  check it out. We found this post it note with some passwords. And Maya says, I wonder what I
2467.34s - 2476.70s |  can do with those. So she gets a copy of Veracrypt on her forensic machine and she loads it up and
2476.70s - 2482.70s |  she gets a copy of this file and she mounts it with Veracrypt and it is successful and she opens
2482.70s - 2494.75s |  it. And in this, she finds five files. Four weird pictures of money and a text file. Hmm. These are
2494.75s - 2500.35s |  the, or five weird pictures of money. So here's some pictures of money. Anybody see anything
2500.35s - 2507.23s |  common about this, these pictures of money? Yes. The serial numbers, right? Don't say too much.
2507.23s - 2513.87s |  Who here knows exactly what this is when you looked at it? A couple of you, right? Typically
2513.87s - 2519.63s |  it's folks who either work with law enforcement or know law enforcement folks, but we'll get there.
2522.08s - 2528.88s |  She initially doesn't think they're relevant at all. But, hmm. So then you have a further
2528.88s - 2535.36s |  conversation with Detective Hart and you find out Charlie C is known for dealings in his drug world
2535.36s - 2544.32s |  and he is, in fact, Charlie Cyber. You look at that text file and you realize this is some kind
2544.32s - 2552.88s |  of ledger file and we see some names that we recognize, right? Alice, Bob, and now Charlie.
2554.24s - 2563.92s |  So that's interesting. Then PD says, ooh, there's a ring camera. We just discovered it. It has a view
2563.92s - 2570.56s |  toward the victim's back door. And camera footage obtained from it shows Charlie Cyber entering Bob's
2570.56s - 2578.24s |  house via the back door moments before Bob's death and exiting shortly thereafter. So now we
2578.24s - 2584.24s |  have more data we have to correlate. These are all the pieces we have to correlate, right? So back to
2584.24s - 2590.40s |  the beginning, all the SMS messages, the emails, the encrypted space with the hidden file, the reports
2590.40s - 2600.97s |  from PD, the ring camera. PD comes back to you, the forensicators, and says, oh, oh, those pictures
2600.97s - 2609.85s |  of money. So those are actually used by drug dealers. Drug dealers, so when you're a drug dealer
2609.85s - 2613.45s |  and you're dealing with other drug dealers and they don't necessarily know who each other are,
2614.81s - 2619.53s |  funny this, they don't go, look, this is my ID. See, this is me. It's who you thought it was, right?
2620.09s - 2626.09s |  So the way they do identity matching is that they will give you part of a serial number and when you
2626.09s - 2631.45s |  meet, you show them the whole serial number and that's how they know that it's the same person
2632.09s - 2635.45s |  that they've been communicating with and the person they're supposed to do the deal with.
2636.09s - 2639.85s |  And this is something that law enforcement actually sees on a fairly regular basis.
2642.32s - 2650.64s |  So based on all that evidence, what we ultimately determine is that Charlie killed Bob. And if we
2650.64s - 2657.28s |  think back about that conversation between now we know Bob and Charlie, right,
2658.96s - 2667.76s |  who was trying to get out of working with him? What did Bob want to do? Yeah, Bob wanted out.
2667.76s - 2673.28s |  He was like, I'm going on my own. I'm going to do my thing. And Charlie didn't seem real happy
2673.28s - 2678.00s |  about that. But that didn't necessarily seem relevant until we had the rest of these pieces
2678.08s - 2681.28s |  and found out there were drug dealings and that's actually what was going on.
2683.48s - 2693.52s |  All right. The team sat down to discuss the case they had just concluded.
2693.52s - 2700.32s |  Each one took their place at the table. Their expressions, a mix of exhaustion and satisfaction,
2700.32s - 2706.16s |  a testament to the arduous journey they had undertaken to solve this mystery. Detective
2706.16s - 2710.88s |  Hart opened the meeting with a solemn nod, signaling the start of their post-incident
2710.88s - 2716.40s |  analysis. Her guys swept across the room before settling on the whiteboard in front of them,
2716.40s - 2721.44s |  where a timeline of events was displayed in meticulous detail. All right, everyone,
2721.44s - 2726.00s |  let's begin, she said in her voice, steady and authoritative.
2727.60s - 2732.08s |  So just because we've solved the case effectively and all the pieces have come together,
2732.64s - 2739.12s |  that does not mean we're done. We've got goals, what are called post-incident goals.
2739.76s - 2746.00s |  And these are critical as well. We need to discuss what went well and what did not go well. Maybe we
2746.00s - 2751.44s |  didn't have the right tools. Maybe we did things in the wrong order. Maybe we didn't look carefully
2751.44s - 2758.32s |  at all of our evidence as we saw here, right? What outcomes were achieved, positive and negative,
2758.32s - 2763.04s |  because again, we kind of want to look at this whole big picture. We need feedback from all the
2763.04s - 2767.84s |  different teams that are involved because nobody does this stuff in a vacuum. And one of the
2767.84s - 2772.16s |  challenges in many cases is that forensicators and the detectives, while they work together,
2772.16s - 2779.76s |  they're often separated significantly. Technical challenges that maybe can be handled later on.
2780.56s - 2786.24s |  And you want to document everything that happened and didn't happen. So if you attempted something
2786.24s - 2792.64s |  and it didn't work, that all has to be documented as well. What do we use to document that? Well,
2792.72s - 2798.32s |  you know, paper, pen, computer, you know, whatever it takes, right? It can be, theoretically, it
2798.32s - 2802.08s |  continued to be photographs and all the kinds of things we've talked about for documentation.
2803.68s - 2810.56s |  The challenges involved in all of this, lots of folks forget to document. They just are in too
2810.56s - 2813.84s |  much of a hurry and they don't write up a report. And then by the time they actually need that
2813.84s - 2819.76s |  information, it's way too late and they forget things. You could forget to document specific
2819.76s - 2824.08s |  things. You might document something that didn't happen because you started down a rabbit hole and
2824.08s - 2827.76s |  you knew that's what was going to happen and so you started writing it down and then you find out,
2827.76s - 2834.48s |  oops, and you forget to delete that. Or you go down that path and instead of deleting, you say,
2834.48s - 2838.72s |  well, we thought it was this, but we, you know, we got to a point and it wasn't that.
2840.48s - 2844.08s |  Another problem is the full story could not be told through documentation.
2844.96s - 2848.72s |  It requires the reader to make assumptions and that's not a good thing either.
2849.52s - 2857.84s |  And an after-action report should always be held. So that is ultimately the story of Alice and Bob.
2859.60s - 2864.00s |  I have to do a little tiny bit of shameless self-promotion here. I have a book here called
2864.00s - 2870.32s |  The Act of Defender. For those of you who are new to the Defender space, what this book does is it
2870.32s - 2876.96s |  looks at defense from an offensive perspective because I discovered when I started my journey
2876.96s - 2883.68s |  down this path that ultimately defense is only half the story. If you don't understand what your
2883.68s - 2888.32s |  offensive counterparts are doing, you don't have to know all the fiddly technical details, but if
2888.32s - 2893.68s |  you don't understand what they do, you will never understand how attackers work and you will not be
2893.68s - 2899.52s |  an effective defender. So I wrote this book basically to give back to a community that has
2899.52s - 2908.27s |  given me a ton because I started in the music industry. I did not start in technology. And so I
2908.27s - 2912.35s |  like to close with this quote and then we'll open it up. I think we still have a couple minutes for
2912.35s - 2919.39s |  questions. So I may not have gone where I intended to go, bachelor's degree in music industry, but I
2919.39s - 2926.19s |  think ultimately I wound up exactly where I need to be. And with that, do I have any questions? Yes.
2957.71s - 2961.55s |  So the two things that were mentioned had to do with exculpatory evidence and I purposely
2961.55s - 2965.95s |  didn't go too far into that because, you know, knowing that a lot of the folks in the audience,
2965.95s - 2971.15s |  this is all very new to them, I wanted to keep it fairly high level. The question in particular was
2971.15s - 2977.87s |  what do I use for documentation? Whatever tool works. So paper, pen, Word documents, Excel
2977.87s - 2983.55s |  spreadsheets. I have some, in some cases I have forms that I use regularly for certain kinds of
2983.55s - 2989.87s |  cases. Sometimes you have to go outside the box because the case is weird. But there's nothing
2989.87s - 2997.31s |  magical or special about any of that. It really depends on your use case. So if a Word form works
2997.31s - 3010.08s |  well for you or a spreadsheet works well for you, then that's perfectly fine. Does that help? Is
3010.08s - 3014.08s |  there any tool that I've run into problems with if I've asked for to use my notes? No, the biggest
3014.08s - 3019.68s |  problem is either having notes on like the back of a napkin and then you literally have to turn in
3019.68s - 3024.88s |  the napkin. So that's one of the big, I mean, I haven't personally run into that, but it's something
3024.88s - 3030.80s |  they warn you about. You know, pretty much as long as you can show your documentation and you're
3030.80s - 3044.72s |  not missing anything, I've never had an issue. I saw another question, hand in the back. Well, I
3044.72s - 3051.12s |  missed the last bit, what? Yeah, so he's saying he does instant response and they just do WordDoc. So
3051.12s - 3056.40s |  yeah, DFIR is my specialty and I do all kinds of different things in that space and WordDoc
3056.40s - 3060.32s |  are your friend and having templates for different kinds of things can be really helpful.
3060.88s - 3074.01s |  Other question? Yes. So the question is, I started in music industry, could I talk about the steps to
3074.01s - 3078.57s |  make the switch? I'm going to give you the like two second abbreviated version and then I'm happy
3078.57s - 3085.45s |  to discuss it further offline. And I just gave a talk, I did a closing keynote for Trimark where I
3085.45s - 3089.69s |  actually tell the really long version of that story and that was recorded and you're happy to,
3089.69s - 3095.53s |  you're welcome to check that out. So the really short answer is my father worked at the computing
3095.53s - 3099.85s |  center at the local college in the town where I grew up and I was actually around all of this
3099.85s - 3105.85s |  stuff forever and when I suddenly became unemployed because I was working for a record store after I'd
3105.85s - 3110.49s |  worked for a couple different record companies and the owner of that store and that small chain
3110.49s - 3114.09s |  decided that paying taxes was optional and New York State said otherwise and they,
3115.29s - 3120.57s |  I had to find another career option and a good friend of mine that I was talking to said, why
3120.57s - 3125.61s |  don't you go into tech? Because this was, you know, in the mid-90s when lots of places were
3125.61s - 3132.41s |  hiring for support roles on the phone and I started down that path that way. How I wound
3132.41s - 3140.49s |  up doing investigation work, I had a good friend at a later job who started to look at worms and
3140.49s - 3145.93s |  other infections and I was fascinated by what he was learning. He shared some stuff from SANS with
3145.93s - 3151.21s |  me and that's kind of the direction I wound up taking. The university where I work ultimately
3151.21s - 3156.89s |  needed somebody to do a forensics for compliance and I built that program for them. So that's the
3156.89s - 3175.77s |  super duper short answer. We might have time for one more, yes. So the question has to do with the
3175.77s - 3179.93s |  fact that I work with law enforcement but I'm not in law enforcement and why do they come to me for
3179.93s - 3184.89s |  stuff? So because I work for university, I have access to all of our data points, right? I have
3184.89s - 3191.37s |  access to all of our logs. I know the people who can get stuff for us if I can't and so they come
3191.37s - 3197.45s |  to me in part because they want that data and in some cases they want to understand that data
3197.45s - 3203.21s |  better. If it is a case that is actually going to go to a criminal court, then we collect the system
3203.21s - 3209.53s |  and that goes down to our regional forensics lab. I don't work those cases because that really needs
3209.53s - 3214.73s |  to be specially handled but when we have employee relations issues, I will do full forensic cases
3214.73s - 3219.85s |  for employee relations that's not law enforcement and do those kinds of things and I think folks
3219.85s - 3224.33s |  were just about out of time. I'll hang out for a minute or two here as long as I'm allowed and then
3224.33s - 3231.37s |  I will be out there if you need me. Thank you so much for having me. Thank you DEF CON for bringing me in.