{
  "webpage_url": "https://www.youtube.com/watch?v=glTCi9SaJbM",
  "title": "DEF CON 32 - Exploiting Voice Cloning in Adversarial Simulation - Mark Foudy",
  "description": "We live in an era where voice verification is increasingly adopted in security protocols. The potential for abuse through voice cloning technology presents a significant and growing threat to cybersecurity. This talk dives into the alarming capabilities of deep learning to create highly convincing voice clones. Using my own voice as a case study, I will demonstrate a recorded simulation where the cloned voice successfully bypasses several major institutions\u2019 voice verification systems. This presentation will outline the tools and techniques leveraged for voice cloning, discuss the pressing risks involved, and explore strategic countermeasures for red teams. The aim is to equip offensive security researchers with a nuanced understanding of voice cloning technology, emphasizing its implications for threat emulation and defensive strategy formulation. Attendees will gain insight into adversary tactics using publicly available voice samples for simulating voice-based attacks, providing a clear perspective on preparing defenses against such AI-driven threats.",
  "channel_url": "https://www.youtube.com/channel/UC6Om9kAkl32dWlDSNlDS9Iw",
  "duration": 1535,
  "channel": "DEFCONConference",
  "uploader": "DEFCONConference",
  "upload_date": "20241016"
}

0.00s - 7.00s | This text was transcribed using whisper model: large-v2

 Hello, my name is Mark Foody, and my presentation is called exploiting voice cloning and adversarial simulation.
7.00s - 16.00s |  I'd first like to thank Adversary Village for giving me the opportunity to present my research, the DEF CON 32, and it's an honor to be here among so many talented individuals.
16.00s - 19.00s |  Okay, so let's dive in. Who am I?
19.00s - 28.00s |  As I mentioned, my name is Mark. I wear many hats. I'm an offensive security researcher, a father, a husband, a proud cat dad.
28.00s - 39.00s |  In addition to my work in AI and security, I founded Neurodiverse Hackers, which is a community dedicated to highlighting and addressing the unique needs of neurodiverse individuals in the hacking community.
39.00s - 45.00s |  Now let's get to the heart of today's presentation. We're going to explore the fascinating and unsettling world of voice cloning.
45.00s - 58.00s |  So, initially I had planned on demonstrating how easy voice verification systems could be bypassed, but due to the legal gray areas concerning using a real-time voice clone to access my own bank account,
58.00s - 65.00s |  I decided to focus on showing how clone speech can be made undetectable by two anti-spoofing mechanisms.
65.00s - 74.00s |  While many commercial products can create realistic voice clones, they cannot defeat the voice verification services used by financial institutions, which detect anomalies.
75.00s - 76.00s |  Through mouse spectrograms.
76.00s - 81.00s |  To bypass anti-spoofing components, it's crucial to refine a voice model through the steps I'll present.
83.00s - 91.31s |  So, voice verification services are provided by companies like Nuance, Variant, Fortress Identity.
91.31s - 98.31s |  They're used by financial institutions such as Fidelity Bank, Wells Fargo, Citibank for secure authentication.
99.31s - 104.31s |  Although these services enhance security through voice biometrics, they remain vulnerable to exploitation.
104.31s - 114.31s |  Today I'll discuss the methods used to bypass these technologies and focus on adversarial training required to enable a voice clone model to bypass anti-spoofing verification systems.
116.31s - 126.31s |  The purpose of this talk is not to delve into the voice cloning process itself, but to explore how adversarial training can create a voice clone indistinguishable from natural human speech.
126.31s - 132.31s |  So, I'll walk through the eight key elements that can make a synthetic voice practically imperceptible from a real one.
133.31s - 147.48s |  The thematically organized various approaches for defeating voice verification, I developed the acoustic standards for modifying spoof speech.
148.48s - 155.48s |  This is like a set of standards focused on key aspects of audio manipulation, making spoof speech indistinguishable to voice verification.
156.48s - 167.48s |  Each step in acoustics provides a structured approach to bypass the rigorous verification and streamlining the process used by other researchers into accessible steps that anyone can follow.
168.48s - 173.48s |  Implementing these techniques requires combining signal processing and machine learning algorithms.
174.48s - 182.48s |  So, after DEF CON, I will provide code examples and slides on GitHub to demonstrate how these adjustments can be made and automated and used to train a voice clone model.
183.48s - 184.48s |  Let's delve in.
185.48s - 187.48s |  Alright, so slide one. Acoustics.
188.48s - 194.48s |  In audio spoofing, adjusting silence intervals is crucial for creating speech that convincingly mimics genuine human interaction.
195.48s - 200.48s |  Natural communication includes pauses and starts at the end of speech.
201.48s - 208.48s |  These are known as leading and trailing silences, which can carry acoustic signatures like microphone static, breathing sounds, and other ambient noise.
209.48s - 211.48s |  These nuances are vital for making speech sound authentic.
212.48s - 219.48s |  So, the first task in adjusting silence intervals involves replacing the leading and trailing silence with natural silences extracted from genuine recordings.
220.48s - 228.48s |  This requires selecting silences that match the context of the spoofed speech and ensuring they exhibit natural variability and align with the intended environment.
229.48s - 234.48s |  Along with replacing leading and trailing silence, it's also essential to eliminate interword redundant silence.
235.48s - 242.48s |  Spoofed speech often has longer synthetic pauses due to its segmented nature of the speech synthesis process.
243.48s - 254.48s |  The goal is to reduce these gaps by inserting human-like silences that maintain the rhythm and flow of authentic speech, using advanced algorithms to model natural silence patterns.
256.89s - 259.89s |  So, then center spectrum boosting.
260.89s - 268.89s |  Center spectrum boosting is also a critical technique for enhancing spoofed speech because it manipulates frequency components to increase perceived authenticity.
269.89s - 279.89s |  Human speech has an energy concentration in the low to mid-frequency range, particularly between 1 and 4 kHz, which is vital for intelligibility and contains the most phonetic information.
280.89s - 290.89s |  Boosting these central frequencies makes synthetic speech sound more natural and less mechanical, helping it blend seamlessly into real-world audio environments.
291.89s - 297.89s |  Natural speech's mid-range frequencies contribute to clarity and distinguish human voices from synthetic ones.
298.89s - 305.89s |  Many audio classifiers and voice verification systems detect subtle clues within this range to differentiate genuine from spoofed speech.
306.89s - 312.89s |  So, making center spectrum manipulation essential for overcoming synthetic speech limitations.
313.89s - 322.89s |  Digital signal processing techniques amplify critical frequencies while suppressing higher frequencies and enhancing the signal's intensity within a targeted range.
322.89s - 329.89s |  Careful calibration ensures that the amplification maintains authenticity and avoids distortions.
330.89s - 336.33s |  Optimizing echo simulation.
337.33s - 341.33s |  Optimizing echo simulation is crucial for making synthetic speech more convincing and realistic.
342.33s - 347.33s |  Echoes naturally occur when a speech is recorded, adding depth and context by reflecting off surfaces.
347.33s - 354.33s |  These reflections help listeners perceive space and authenticity, often missing in synthetic voice generated by spoofing algorithms.
355.33s - 365.33s |  And the genuine recording echoes are subtle clues that aid in interpreting the recording's space, size, and nature, and they vary in amplitude and delay based upon the surface distance and characteristics.
366.33s - 375.33s |  To enhance the realism of spoofed speech, simulating natural echo patterns involves introducing slight time delay with copies of the original audio with progressively lower amplitudes.
375.33s - 387.33s |  This mimics how sound waves will bounce and decay in real world environments, and it's enhancing the audio's spatial qualities and challenging voice verification systems to detect the absence of natural reflections.
388.33s - 394.62s |  Upgrade frequency pre-emphasis.
395.62s - 406.62s |  While center spectrum boosting focused on enhancing the naturalness of synthetic speech by amplifying mid-ranges, frequency pre-emphasis targets the higher frequency ranges to improve speech quality and reduce noise.
406.62s - 417.62s |  Pre-emphasis involves boosting the amplitude of higher frequencies, typically between 1 and 6 kHz, which are less prominent in natural speech but critical for enhancing clarity and intelligibility.
418.62s - 426.62s |  The primary goal of frequency pre-emphasis is to adjust the frequency profile of synthetic speech so that it aligns more closely with natural human speech.
427.62s - 434.62s |  By applying pre-emphasis filters, we can emphasize higher frequencies to match synthetic characteristics and maintain a natural spectral balance.
434.62s - 440.62s |  This process reduces noise impact and makes the speech sound more realistic and robust.
441.62s - 453.62s |  So through careful calibration, pre-emphasis ensures speech retains its tonal quality without a distortion, making it more challenging for a voice verification system to detect any anomalies.
454.62s - 458.64s |  S is spectral noise reduction.
459.64s - 467.64s |  Spectral noise reduction is crucial for enhancing spoofed speech by removing unwanted noise artifacts that reveal its synthetic quality.
468.64s - 477.64s |  While natural speech includes subtle random background noise, spoofed speech often contains distinct machine noise due to the synthesis limitations.
478.64s - 485.64s |  Managing noise in the audio signal improves the perceived authenticity, making it more challenging for a detection system to identify.
486.64s - 493.64s |  The goal is to eliminate or minimize machine-generated noise that can serve as a cue for voice verification systems to reject the speech as cloned.
494.64s - 499.64s |  To align the noise profile of spoofed speech with natural human speech, we use a three-step strategy.
499.64s - 507.64s |  First, we use spectral gain filtering, which filters out the noise by analyzing frequency components and removing those below a set threshold.
508.64s - 517.64s |  Then we use dynamic noise filtering, which uses adaptive algorithms to adjust in real-time to the audio environment, ensuring continuous noise reduction.
518.64s - 529.64s |  Finally, through context-appropriate additive noise, such as ambient office or outdoor sounds, which is incorporated, it will often be used to mask synthetic artifacts and create more natural-sounding speech.
538.06s - 540.06s |  Tuning adversarial speaker regularization.
541.06s - 550.06s |  Tuning adversarial speaker regularization is a sophisticated technique used to make synthetic speech sound as if it was produced by a real speaker.
551.06s - 555.06s |  Masking any artifacts that could reveal its artificial origins.
556.06s - 565.06s |  This is achieved by using adversarial methods, often with machine learning models, to refine speech signals so that it closely matches the vocal characteristics of a targeted speaker.
566.06s - 576.06s |  By employing adversarial techniques, we can adjust the speech signal to align with the natural variability and dynamism of human speech, reducing the likelihood for it being flagged as synthetic.
577.06s - 581.06s |  To enhance speech authenticity, our strategy involves three steps.
582.06s - 594.06s |  First, we use adversarial training with generative adversarial networks to iteratively refine audio quality, allowing the generator to produce realistic samples while the discriminator evaluates their authenticity.
595.06s - 608.06s |  Second, we engrave the unique voice print of the targeted speaker onto the spoofed audio by adjusting prosodity, pitch, and timbre, which matches the genuine speaker's vocal characteristics.
609.06s - 615.06s |  Finally, regularization techniques smooth irregularities in speech signal, ensuring consistent tone and clarity through the audio.
621.10s - 622.10s |  Integrating additive noise.
623.10s - 626.10s |  Integrating additive noise is crucial for enhancing authenticity of spoofed speech.
627.10s - 633.10s |  Natural speech often includes background noises, added depth and context, while spoofed speech typically sounds too clean and artificial.
634.10s - 640.10s |  By strategically adding noise, synthetic speech can blend seamlessly into real-world environments, increasing its believability.
641.10s - 646.10s |  Additive noise makes synthetic qualities by introducing natural variations and imperfections present in real recordings.
647.10s - 655.10s |  It also helps disguise any artifacts or inconsistencies from the synthesis process, making spoofed speech sound more realistic.
656.10s - 661.10s |  To create a realistic audio environment, we can do three steps to do that.
662.10s - 669.10s |  First, we select noise sources that are contextually appropriate, such as typing sounds for an office setting or wind or traffic noise.
670.10s - 678.10s |  Second, we use algorithms to dynamically adjust the level and type of the noise that we're using, ensuring that it complements the speech without overwhelming it.
679.10s - 684.10s |  Finally, we maintain temporal and spatial consistency by aligning the noise with the speech's rhythm and flow,
685.10s - 690.10s |  carefully timing its introduction and adjusting spatial characteristics to match the perceived environment.
691.10s - 696.85s |  And C, we create model-agnostic approach.
697.85s - 700.85s |  Creating a model-agnostic approach is essential for enhancing spoofed speech,
701.85s - 708.85s |  ensuring that the techniques that use to generate or modify speech are not tied to any specific voice verification system or machine learning model.
708.85s - 713.85s |  This approach provides flexibility and adaptability, allowing for the development of spoofed methods
714.85s - 720.85s |  that can effectively bypass a wide range of detection systems, regardless of their underlying algorithms or architecture.
722.85s - 725.85s |  By focusing on techniques that are universally applicable,
726.85s - 732.85s |  a model-agnostic strategy exploits general weaknesses in speech processing to create a more convincing spoofed audio,
732.85s - 736.85s |  which is crucial as voice verification systems continue to evolve.
737.85s - 744.85s |  To enhance audio manipulation, we develop generalizable techniques that address common vulnerabilities across systems.
745.85s - 749.85s |  We focus on manipulating silence intervals, frequency emphasis, and noise integration,
750.85s - 753.85s |  based on fundamental speech processing principles.
754.85s - 758.85s |  Then, second, we create a flexible framework that allows easy adaptability
758.85s - 765.85s |  and testing on various techniques using modular design principles for component and algorithm intercompatibility.
766.85s - 770.85s |  Finally, we implement machine learning models that learn from diverse verification systems,
771.85s - 776.85s |  training on generalized features and patterns to ensure adaptability and effectiveness across different platforms.
777.85s - 778.85s |  All right.
779.85s - 783.22s |  As we conclude our exploration of acoustic standards,
786.78s - 789.78s |  it's evident that each element is crucial in refining the authenticity of spoofed speech.
789.78s - 793.78s |  These techniques provide insight into the weaknesses that can be exploited in voice verification systems
794.78s - 796.78s |  and highlight the areas where these systems need to evolve.
797.78s - 804.78s |  For cybersecurity professionals, understanding these enhancements lays the foundation for developing more robust defenses against audio spoofing.
806.78s - 808.78s |  By dissecting the methods used to create convincing spoofed speech,
809.78s - 813.78s |  cybersecurity experts gain a deeper understanding of the intricacies of audio manipulation.
813.78s - 816.78s |  This knowledge enables them to anticipate and counteract emerging threats,
817.78s - 819.78s |  strengthening the security posture of voice verification systems.
820.78s - 825.78s |  The acoustic standards offer a comprehensive framework for enhancing the realism of spoofed speech.
826.78s - 827.78s |  By applying these insights,
828.78s - 832.78s |  professionals can devise innovative strategies that detect and thwart sophisticated spoofing attempts
833.78s - 836.78s |  and build more resilient systems that withstand these challenges.
837.78s - 839.78s |  As we continue to innovate in this field,
840.78s - 842.78s |  it's essential to prioritize security, ethics, and responsibility
843.78s - 845.78s |  in the development and application of these technologies.
846.78s - 847.78s |  Thank you for your attention,
848.78s - 850.78s |  and I welcome any questions or discussions you may have.
851.78s - 852.78s |  Any questions?
862.26s - 863.26s |  I'm sorry.
884.81s - 906.68s |  I think the goal is text-to-speech,
907.68s - 908.68s |  especially from an adversary's perspective.
909.68s - 911.68s |  It's to get a clone replica of someone's speech
912.68s - 915.68s |  and to be able to bypass any verification systems
915.68s - 919.68s |  that would prevent access to banking records or what have you.
920.68s - 922.68s |  I think both in the sense that,
923.68s - 924.68s |  I think what you're saying is,
925.68s - 926.68s |  is the goal text-to-speech,
927.68s - 931.68s |  or is it mining speech samples from an actual speaker?
932.68s - 935.68s |  You have to mine speech samples from a speaker.
936.68s - 938.68s |  You have to start with your clone model
939.68s - 943.68s |  and then adding it in samples from your target.
944.68s - 951.68s |  The amount of samples you need to introduce varies
952.68s - 953.68s |  depending on the context,
954.68s - 955.68s |  but you have to start that way.
956.68s - 961.68s |  Implementing these techniques will allow you to expand that.
962.68s - 964.68s |  Taking a little bit of sample from a target
965.68s - 967.68s |  and being able to create a realistic voice clone
968.68s - 969.68s |  is possible using these techniques.
970.68s - 988.10s |  Does that answer your question?
988.10s - 989.10s |  I think it's a temporary thing.
990.10s - 991.10s |  I think it's a temporary thing.
992.10s - 993.10s |  Any other questions?
1011.41s - 1012.41s |  Absolutely.
1013.41s - 1014.41s |  The question was,
1015.41s - 1017.41s |  there are AI models in the works to create spoof speech,
1018.41s - 1021.41s |  but are there models also being used to defeat voice cloning?
1022.41s - 1023.41s |  Absolutely.
1024.41s - 1026.41s |  It's sort of a cat and mouse game in the sense that,
1027.41s - 1031.41s |  in fact, the models that exist to detect spoof speech
1032.41s - 1033.41s |  are probably better in some sense
1033.41s - 1034.41s |  than the models that make clone speech.
1035.41s - 1036.41s |  As I was saying,
1037.41s - 1038.41s |  when you look on the internet,
1039.41s - 1041.41s |  there's people selling voice clone technology.
1042.41s - 1044.41s |  None of that stuff is advertised
1045.41s - 1047.41s |  or is expected to defeat the voice biometrics
1048.41s - 1051.41s |  that are necessary for a career criminal or a cyber threat.
1052.41s - 1054.41s |  The technology is on that side,
1055.41s - 1058.41s |  but these steps that I've outlined
1059.41s - 1062.41s |  are ways that focus and attack
1063.41s - 1067.41s |  and ways that those AI speech models view spoof speech
1068.41s - 1070.41s |  and determine it and distinguish it from real speech.
1071.41s - 1072.41s |  We're going after the same places
1073.41s - 1074.41s |  that these models were looking at,
1075.41s - 1078.41s |  such as ambient noise and echo and pre-emphasis
1079.41s - 1080.41s |  and spectral boosting.
1081.41s - 1082.41s |  By addressing those,
1083.41s - 1086.41s |  we make spoof speech much harder to detect from real speech.
1087.41s - 1088.41s |  You know what I mean?
1089.41s - 1090.41s |  Any other questions?
1091.41s - 1093.78s |  Yeah, yeah, yeah.
1096.06s - 1097.06s |  Okay, just speak to me and I'll follow.
1098.06s - 1099.06s |  Yeah, yeah, yeah.
1100.06s - 1101.06s |  So I've heard from a lot of CEOs that are like,
1102.06s - 1103.06s |  I want you to put AI on it.
1104.06s - 1105.06s |  It needs to be AI. Put AI on my company.
1106.06s - 1107.06s |  And voice is obviously one of the options.
1108.06s - 1109.06s |  So given where the technology is now,
1110.06s - 1111.06s |  is that a bad recommendation?
1112.06s - 1113.06s |  Do you think that we shouldn't be using voice cloning?
1114.06s - 1115.06s |  Is it a...
1116.06s - 1119.06s |  Is voice verification a failed technology
1120.06s - 1121.06s |  looking for a problem?
1122.06s - 1124.06s |  Well, I'm a little biased, but I would say so.
1124.06s - 1125.06s |  I mean, I would...
1126.06s - 1127.06s |  You know, my own bank uses voice verification.
1128.06s - 1129.06s |  I mean, I don't know.
1130.06s - 1131.06s |  I'm not a CEO of a company,
1132.06s - 1133.06s |  but I would...
1134.06s - 1135.06s |  Voice verification is...
1136.06s - 1137.06s |  I mean, so like,
1138.06s - 1140.38s |  using these techniques I talked about,
1141.38s - 1143.38s |  you have almost like a 95% effective rate, right?
1144.38s - 1146.38s |  So I mean, the voice verification systems will advance,
1147.38s - 1149.38s |  but at the current state they're at now,
1150.38s - 1151.38s |  they are able to be defeated.
1151.38s - 1152.38s |  It just requires a voice clone model
1153.38s - 1154.38s |  that has been trained appropriately
1155.38s - 1156.38s |  to defeat them, right?
1157.38s - 1158.38s |  And that is something that any adversary
1159.38s - 1160.38s |  could figure out, could do, right?
1161.38s - 1162.38s |  I mean, with enough resources,
1163.38s - 1164.38s |  I mean, I can do it.
1165.38s - 1166.38s |  So if they can do it.
1167.38s - 1168.38s |  So yeah, I mean, if I was a CEO,
1169.38s - 1170.38s |  I would find other ways to like, you know,
1171.38s - 1173.38s |  like to secure myself in voice.
1174.38s - 1175.38s |  Because I mean, we've already seen in the news
1176.38s - 1177.38s |  other...
1178.38s - 1179.38s |  Like a bunch of different situations
1179.38s - 1180.38s |  where this has happened, you know?
1181.38s - 1182.38s |  And it'll, yeah.
1183.38s - 1184.38s |  Does that answer your question?
1185.38s - 1186.38s |  Okay.
1186.38s - 1189.55s |  Anybody else, please?
1190.55s - 1191.55s |  Anybody?
1192.55s - 1193.55s |  Are you scared?
1194.55s - 1195.55s |  It's going on GitHub.
1196.55s - 1197.55s |  I'll add the code.
1198.55s - 1199.55s |  I was going to put the code up,
1200.55s - 1201.55s |  but then I thought, you know,
1202.55s - 1203.55s |  I hate it when people just like throw code
1204.55s - 1205.55s |  and then I'll have more like code
1206.55s - 1207.55s |  and more like explanations
1208.55s - 1209.55s |  of how to implement each of these techniques,
1209.55s - 1210.55s |  but this was a talk that was like,
1211.55s - 1212.55s |  could have been a workshop
1213.55s - 1214.55s |  and I just had to pare it down.
1215.55s - 1216.55s |  So there's a lot of cutting,
1217.55s - 1218.55s |  like a lot of cutting.
1219.55s - 1220.55s |  But I promise to release that.
1221.55s - 1224.60s |  Okay.
1225.60s - 1226.60s |  Anybody else?
1227.60s - 1228.60s |  What's up?
1229.60s - 1230.60s |  It's all right.
1231.60s - 1232.60s |  No, please do.
1233.60s - 1234.60s |  Come on.
1235.60s - 1236.60s |  Yep.
1237.60s - 1238.60s |  It's a great question.
1238.60s - 1239.60s |  It's a great question.
1240.60s - 1241.60s |  It's a great question.
1242.60s - 1243.60s |  So that's an awesome question.
1244.60s - 1245.60s |  The question is,
1246.60s - 1247.60s |  is like a clone speech indistinguishable
1248.60s - 1249.60s |  to the verification system
1250.60s - 1251.60s |  or to a human listener?
1252.60s - 1253.60s |  So that's a really great question.
1254.60s - 1255.60s |  So like I would say this,
1256.60s - 1257.60s |  like if someone clones my voice
1258.60s - 1259.60s |  and calls my wife,
1260.60s - 1261.60s |  she's probably going to figure out it's not me
1262.60s - 1263.60s |  because not just my voice,
1264.60s - 1265.60s |  but just sort of the speaking patterns
1266.60s - 1267.60s |  might not be the same.
1268.60s - 1269.60s |  Right.
1269.60s - 1270.60s |  And there's situations like
1271.60s - 1272.60s |  some woman had like,
1273.60s - 1274.60s |  somebody had done the same thing with their daughter
1275.60s - 1276.60s |  and they were like,
1277.60s - 1278.60s |  it didn't sound right,
1279.60s - 1280.60s |  but it sounded like her but not like her.
1281.60s - 1282.60s |  So it depends who we're talking about.
1283.60s - 1284.60s |  Like this person works at the bank
1285.60s - 1286.60s |  who relies on the voice verification system
1287.60s - 1288.60s |  to say, yeah, this sounds authentic.
1289.60s - 1290.60s |  That's probably going to be able to be bypassed.
1291.60s - 1292.60s |  My wife, I mean,
1293.60s - 1294.60s |  gosh, I hope not.
1295.60s - 1296.60s |  So yeah, I mean,
1296.60s - 1297.60s |  so when I call my bank,
1298.60s - 1299.60s |  I call it, like I try to like,
1300.60s - 1301.60s |  I just, you know,
1302.60s - 1303.60s |  and it's like to try to, you know,
1304.60s - 1305.60s |  voice changes, like, you know,
1306.60s - 1307.60s |  like your voice can change.
1308.60s - 1309.60s |  So it's really like,
1310.60s - 1311.60s |  it's not like a fingerprint
1312.60s - 1313.60s |  that it's like it's harder to modify.
1314.60s - 1315.60s |  I mean, people's voice changes with age.
1316.60s - 1317.60s |  So yeah, does that make sense?
1318.60s - 1319.60s |  Yeah, yeah, yes and no.
1320.60s - 1321.60s |  The context depends.
1322.60s - 1323.60s |  But yeah, yeah.
1324.60s - 1329.38s |  Anybody else?
1330.38s - 1333.17s |  Yeah, so there's,
1334.17s - 1335.17s |  that's a great question.
1336.17s - 1337.17s |  So there is like open source data sets
1338.17s - 1339.17s |  out there that are used
1340.17s - 1341.17s |  by voice verification systems
1342.17s - 1343.17s |  to sort of refine,
1344.17s - 1345.17s |  train their models on.
1346.17s - 1347.17s |  And they're available like, you know,
1348.17s - 1349.17s |  there's ASD spoof data sets.
1350.17s - 1351.17s |  There's other ones out there
1352.17s - 1353.17s |  and you can use them.
1354.17s - 1355.17s |  And just like the voice verification
1356.17s - 1357.17s |  companies use them,
1358.17s - 1359.17s |  adversaries can use them also
1360.17s - 1361.17s |  to sort of train on
1362.17s - 1363.17s |  Is that, so that, you know,
1364.17s - 1365.17s |  that's what, is that your question?
1366.17s - 1367.17s |  Like, and so,
1368.17s - 1369.17s |  if I was going to train,
1370.17s - 1371.17s |  well, so I would start off by,
1372.17s - 1373.17s |  well I did, I mean I trained,
1374.17s - 1375.17s |  I started off by a generalized voice data set.
1376.17s - 1377.17s |  Like there's one,
1378.17s - 1379.17s |  it's like a Lynda Johnson,
1380.17s - 1381.17s |  Lynda Johnson speech.
1382.17s - 1383.17s |  It's like 30,000 voice samples.
1384.17s - 1385.17s |  And I'd feed that into like my model,
1386.17s - 1387.17s |  right, to start off with.
1388.17s - 1389.17s |  And let it train on that.
1390.17s - 1391.17s |  It took about a week
1392.17s - 1393.17s |  and then what I did
1394.17s - 1395.17s |  was I take voice samples of myself,
1396.17s - 1397.17s |  like which are like maybe 100, right,
1398.17s - 1399.17s |  which are similar to what you could get,
1400.17s - 1401.17s |  let's say on this YouTube video
1402.17s - 1403.17s |  if someone was to cut my voice
1404.17s - 1405.17s |  into segments, right.
1406.17s - 1407.17s |  And I trained it on that
1408.17s - 1409.17s |  and it gets pretty close
1410.17s - 1411.17s |  but it's not going to defeat
1412.17s - 1413.17s |  verification unless I address ambient noise.
1414.17s - 1415.17s |  I mean, because the way
1416.17s - 1417.17s |  voice verification works
1418.17s - 1419.17s |  is it takes the digital,
1420.17s - 1421.17s |  it takes the digital signal
1422.17s - 1423.17s |  in a much different way than we are
1424.17s - 1425.17s |  and it's looking for
1426.17s - 1427.17s |  like differences in frequency
1428.17s - 1429.17s |  and like pitch
1430.17s - 1431.17s |  and it knows which things are
1432.17s - 1433.17s |  common with smooth speech
1434.17s - 1435.17s |  and so it picks it up.
1436.17s - 1437.17s |  So as long as you can like manipulate
1438.17s - 1439.17s |  the synthetic speech
1440.17s - 1441.17s |  in order to sort of bypass
1442.17s - 1443.17s |  those like, you know,
1444.17s - 1445.17s |  target areas,
1446.17s - 1447.17s |  then yeah, I mean,
1448.17s - 1449.17s |  and it's doable.
1450.17s - 1451.17s |  I mean, you know, other people have done it.
1452.17s - 1453.17s |  Everyone can do it, you know, I mean.
1454.17s - 1455.17s |  So, what's that?
1462.28s - 1492.75s |  In a sense, that's what,
1495.32s - 1496.32s |  what's that?
1497.32s - 1498.32s |  Okay, I'm being told
1499.32s - 1500.32s |  I have to answer this offline.
1501.32s - 1502.32s |  Yes, that's, yeah,
1503.32s - 1504.32s |  I guess we're done for time
1505.32s - 1506.32s |  but do we test it against,
1507.32s - 1509.76s |  sorry,
1511.76s - 1512.76s |  can I answer that afterwards
1513.76s - 1514.76s |  because I'm being told we got to stop
1515.76s - 1516.76s |  and it's like, it's a little more deeper question.
1517.76s - 1518.76s |  It's a little more complicated to explain
1518.76s - 1519.76s |  but the short answer is yes.
1520.76s - 1521.76s |  Okay, we'll just come see me
1522.76s - 1523.76s |  and we'll talk.
1524.76s - 1525.76s |  I'll talk, I'll be here afterwards.
1526.76s - 1527.76s |  I'm not going anywhere.
1528.76s - 1529.76s |  So, anybody's got questions,
1530.76s - 1531.76s |  want to hang out, chat, talk.
1532.76s - 1533.76s |  I'm cool with it.
1534.76s - 1535.76s |  All right, man.
1535.76s - 1536.76s |  Thank you for coming to my talk, man.