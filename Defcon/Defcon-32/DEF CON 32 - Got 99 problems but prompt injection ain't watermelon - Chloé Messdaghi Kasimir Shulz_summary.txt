**Event Information**
- **Title**: DEF CON 32 - Got 99 problems but prompt injection ain't watermelon
- **Speakers**: Chlo√© Messdaghi, Casimir Shulz
- **Channel**: DEFCONConference
- **Upload Date**: October 16, 2024
- **Duration**: 1843 seconds

**AI Vulnerabilities**
- **Public Perception**: Misinformation and disinformation on AI security; misconceptions about AI vulnerabilities.
- **AI Model vs. AI System**: 
  - **AI Model**: Handles data processing and decision-making.
  - **AI System**: Ensures model use in real-world applications, includes data management and user interfaces.
- **Types of Attacks**: 
  - **Data Poisoning**: Manipulates data to bias model behavior.
  - **Model Evasion**: Uses slight input changes to trick models.
  - **Model Theft**: Involves intellectual property theft through model replication or data extraction.
  - **Prompt Injection**: Tricks AI into performing unauthorized actions.
  - **Supply Chain Attacks**: Compromises trusted vendors to spread malicious components.

**AI Infrastructure Vulnerabilities**
- **Hugging Face**: Platform for sharing AI models; potential for malicious uploads due to trust.
- **AI Development Frameworks**: Often lack security; common issues include serialization vulnerabilities.
- **Model Format Vulnerabilities**: Use of insecure serialization methods like **pickle** can lead to exploitation.
- **ML Ops Solutions**: Involves model deployment, vector databases, and project hosting; large attack surface.

**Open Source AI Challenges**
- **Verification Difficulties**: Inconsistent code quality, hidden vulnerabilities, and complex licensing.
- **Open Source Risks**: Frequent updates and dependency issues can introduce security flaws.

**Vulnerability Management**
- **Disclosure Challenges**: Lack of clear ownership, technical complexity, and legal concerns hinder reporting.
- **Call to Action**: Enhance AI security disclosure processes and strengthen partnerships for better protection.