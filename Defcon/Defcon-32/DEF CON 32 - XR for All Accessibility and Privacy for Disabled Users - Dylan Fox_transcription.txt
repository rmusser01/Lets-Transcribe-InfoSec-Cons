{
  "webpage_url": "https://www.youtube.com/watch?v=LysMyDrOGn4",
  "title": "DEF CON 32 - XR for All:  Accessibility and Privacy for Disabled Users - Dylan Fox",
  "description": "Extended Reality (XR) technologies offer tremendous new possibilities for socializing, entertainment, training, and more. Unfortunately, many disabled users find themselves excluded from XR entirely or exposed to severe privacy risks for using it. In this talk, Dylan Fox, Director of Operations for the XR Access Initiative at Cornell Tech, will discuss the core challenges disabled people face in using XR, the tensions between privacy and assistive capabilities, and the open-source efforts happening now to ensure XR is accessible to everyone.",
  "channel_url": "https://www.youtube.com/channel/UC6Om9kAkl32dWlDSNlDS9Iw",
  "duration": 1375,
  "channel": "DEFCONConference",
  "uploader": "DEFCONConference",
  "upload_date": "20241016"
}

0.00s - 5.52s | This text was transcribed using whisper model: large-v2

 Hello everybody, uh, love to get started for you today. As I just mentioned, uh, I didn't bring my
5.52s - 12.48s |  laptop because, uh, I had been given many fear-mongering tales, excuse me, uh, of DEF CON
12.48s - 18.48s |  and the vicious hackers within, as this is my first time at DEF CON. Um, now, ideally we're
18.48s - 24.96s |  gonna have a laptop from the, uh, XR Village host for me to present on, but unfortunately I haven't
24.96s - 30.72s |  been able to get in contact with her, so I'm gonna do, uh, what is called a pro-gamer move
30.72s - 36.64s |  and ask if anybody in the audience has a laptop they would be willing to let me present my slides
36.64s - 44.48s |  from. This is a great look for me, I know. Uh, if not, that's okay, we will, I'll, I'll bring
44.48s - 48.80s |  out my phone for you and you all can just, um, look at the, look at the slides from here. That'll
48.80s - 60.88s |  work, right? Um, uh, well, that's all right. Uh, we'll do this theater of the mind. So, hello everybody,
60.88s - 67.04s |  uh, my name is Dylan Fox, uh, and I'm here to talk to you today about XR for All, accessibility and
67.04s - 74.24s |  privacy for disabled users. Uh, I am the Director of Operations for XR Access, which I'll be talking
74.24s - 81.68s |  to you about in just a moment, uh, and you can reach me at dylan at xraccess.org. Uh, our agenda
81.68s - 86.00s |  today is I'm going to tell you a little bit about the XR Access Initiative that I represent.
86.00s - 92.64s |  Uh, we're going to talk about the benefits that accessibility-focused XR can provide to people
92.64s - 97.84s |  with disabilities. Uh, we're talking about the privacy risks that those benefits come along with,
97.84s - 102.24s |  uh, and then best practices for mitigating those risks, or how we can have the, the best of both
102.24s - 109.36s |  worlds. Uh, and hopefully at the end, we'll have some time for Q and A. Uh, so to start with, uh,
109.36s - 118.48s |  the XR Access Initiative, uh, is a community dedicated to connecting people in order to make
118.48s - 125.04s |  virtual augmented and mixed reality accessible for people with disabilities. Uh, we were originally
125.04s - 130.56s |  founded in 2019 as just kind of a community of people coming together to wanted to make this
130.56s - 136.32s |  new tech accessible. Uh, and now we are a proud research initiative of Cornell Tech in New York.
137.12s - 143.92s |  Uh, we do a lot in terms of researching the fundamentals of accessibility. You know, how do
143.92s - 150.80s |  we make these technologies accessible, especially to blind and low vision people? Uh, we also make a
150.80s - 156.88s |  lot of resources that we provide to designers and developers on how to make their apps accessible.
156.88s - 163.76s |  Uh, we con- connects different communities in terms of the, uh, big, you know, the big technical
163.76s - 170.64s |  platforms, the content creators, uh, researchers, government people, uh, and of course, people who
170.64s - 175.52s |  are disabled and advocates, uh, in order to come together to solve some of these really thorny
175.52s - 182.16s |  problems, uh, on how to make these things accessible. Uh, and we advocate and educate for XR
182.16s - 188.96s |  accessibility, just like I'm doing right here. Uh, we also hold every year our XR Access Symposium.
188.96s - 195.52s |  Uh, you just missed the one June 6th and 7th, but, uh, we have our, all of our videos up on YouTube. So
195.52s - 200.16s |  if you're interested in learning more about kind of the hot topics in XR accessibility,
200.16s - 204.88s |  uh, I'd encourage you to check that out. Uh, our website is xraccess.org.
205.76s - 213.28s |  So let's talk about accessibility-focused XR. Now, XR, for those of you who aren't aware,
213.28s - 220.56s |  is, uh, an umbrella term, uh, referring to extended reality. Uh, and that covers virtual reality,
220.56s - 226.96s |  where you are immersed in this virtual space, augmented reality, where you augment reality
226.96s - 231.76s |  with data, uh, and mixed reality, which is a little column A and a little column B.
231.76s - 237.28s |  Uh, and all of these come together to form a technology that has really grown in popularity
237.28s - 243.44s |  over the last five or ten years, uh, and is really poised to make a big change in people's lives if
243.44s - 250.48s |  we use it correctly. So that's XR. What about the accessibility half of XR accessibility?
251.76s - 258.72s |  Now, the first thing, the notion that I want to dispel for you all, is that accessibility
259.36s - 267.20s |  is a checklist that you run down in order to support a few people who are in wheelchairs
267.20s - 270.88s |  or what have you out of the goodness of your heart. Because that's a lie.
272.24s - 280.72s |  Uh, accessibility affects all of us. Accessibility is defined as basically being able to use
280.72s - 287.44s |  something no matter what your ability is, because we all have abilities to see, to hear, to touch,
288.40s - 295.60s |  um, and sometimes those abilities can become hampered, right? Uh, now that can be permanently,
295.60s - 300.80s |  right? If you are, you know, have a genetic condition that makes you born without ears,
301.52s - 306.72s |  you're probably deaf, right? And that would be a permanent condition. But you might also be deaf
306.72s - 313.04s |  because you have an ear infection, or you might be deaf because you're at a really loud bar,
313.04s - 316.08s |  like, you know, the middle of the arcade party last night. That thing was deafening.
317.04s - 325.44s |  Um, and accessibility will help everybody no matter what that source of disability is from.
326.08s - 334.24s |  Because disability isn't really just about your hampered ability. Disability is when your
334.24s - 341.44s |  abilities don't match up with the expectations or the assumptions of the technology that you use,
341.44s - 348.40s |  or the spaces around you. So somebody in a wheelchair is not disabled inherently.
348.40s - 352.96s |  They are disabled when they come to a place that the only way to get in is stairs,
352.96s - 357.68s |  right? You know, never use the term wheelchair bound, because a lot of the people that use
357.68s - 361.44s |  wheelchairs will tell you, I'm not bound to this wheelchair. The wheelchair is what
362.32s - 366.64s |  gives me mobility. It's what lets me move around and be where I want to be.
367.60s - 374.48s |  So when we talk about accessibility, accessibility is about technology that adapts to your needs.
374.48s - 379.92s |  It's about technology that no matter what your abilities are, you'll still be able to use.
381.60s - 388.16s |  There's a woman, Cindy Lee, who wrote the book on CSS and was also an accomplished accessibility
388.16s - 396.24s |  advocate, and she had this idea that we're all just temporarily abled, right? All of us,
397.12s - 402.56s |  at some time or another where we're just in a loud room or we get old and our bodies start to
402.56s - 407.76s |  fail us, all of us will be disabled at some point in our lives. So when we're talking about
407.76s - 412.08s |  accessibility, don't make the mistake of thinking, oh, accessibility, that's for those people over
412.08s - 416.08s |  there. Oh, accessibility, that's the thing that fricking bureaucrats make me want to check off
416.08s - 421.68s |  a list so we don't get sued. It's not the case. Accessibility is for all of us. Quick show of
421.68s - 428.24s |  hand, who here in the audience has either personally experienced accessibility or rather
428.24s - 433.20s |  personally experienced disability or has a relative who has disabilities? Show of hands.
433.20s - 438.08s |  I know I have. That's a good portion of you, and I think 100% of the people that are actually
438.08s - 445.44s |  paying attention and thinking about it. So where does that leave us on accessibility and XR?
446.56s - 452.88s |  Well, there's two perspectives when it comes to XR accessibility. The first is this idea of core
452.88s - 460.64s |  platform accessibility, and that is the idea that every single XR app from, you know, Beat Saber to
460.64s - 466.24s |  Vacation Simulator to, you know, all the stuff you see in the XR Village upstairs of working on labs
466.24s - 472.72s |  and simulating national disasters, all of those should be accessible to anybody that wants to use
472.72s - 481.12s |  them. The second way of thinking about XR accessibility is about XR as assistive technology,
481.12s - 485.52s |  and so this would be tools that are aimed specifically at people with disabilities to
485.52s - 492.24s |  support them and their use in everyday life. Now, normally I would focus this talk on core
492.24s - 497.20s |  platform accessibility. You know, that's things like the curb cut effect, right? Everybody knows
497.20s - 501.28s |  curb cuts, the little things that go from the sidewalk down to the street. They didn't have
501.28s - 506.16s |  those back before, like, the 1960s. There was a whole disability civil rights movement where
506.16s - 510.96s |  people were sneaking out at night to take sledgehammers to sidewalks and then put in, you know,
510.96s - 517.28s |  wooden ramps, and once, you know, they people had to fight tooth and nail to get these in for
517.28s - 523.04s |  wheelchair users so that wheelchair users didn't have to, you know, wheel through the streets and
523.04s - 531.44s |  be hit by cars, and once they did that, they realized, oh, hold on a sec, guys. I think, I think
531.44s - 537.52s |  these are useful for everybody. They found that these curb cuts weren't just useful for people in
537.52s - 542.24s |  wheelchairs, people who, you know, had no mobility. Uh, they were useful for people on bicycles and
542.24s - 550.24s |  people with baby strollers and people with heavy dollies full of crap. So, these types of things,
550.24s - 553.84s |  you know, when we make, uh, when we make things accessible for people with disabilities,
553.84s - 558.72s |  we make them better for everybody. So, that's usually what I would do a whole 30-minute talk
558.72s - 564.16s |  about, right? We talk about things like, uh, captions in VR, we talk about magnification,
564.16s - 568.80s |  we talk about co-piloting, uh, all the features that if you are designing or developing
568.80s - 576.08s |  a VR, AR, XR app, you would put in to make it more usable. But today, we're talking about
576.08s - 584.16s |  something else, because I know you all here, uh, at DEF CON, uh, care about a little thing called
584.16s - 594.88s |  privacy, right? And there is a very interesting tension between accessibility and privacy when it
594.88s - 604.24s |  comes to XR, because there are some tools like, for example, facial recognition, that if you are
604.24s - 608.96s |  blind or you have, uh, you know, prosopagnosia, which is like face blindness, the inability to
608.96s - 615.52s |  remember faces, uh, or if you just have memory problems, facial recognition could be a very
615.52s - 620.88s |  helpful tool, right? Being able to have a little reminder of, oh, your brother just walked into the
620.88s - 629.28s |  room, oh, here comes your friend Sam, right? That's really useful. But if that comes at the cost of
629.28s - 636.00s |  every single person's face you see ending up in some meta or NSA database, that cost might not
636.00s - 641.68s |  really be worth it, right? So, we have to figure out how to balance these. So, I'm going to start
641.68s - 646.64s |  with the good news, uh, which is that there are some really powerful uses of this assistive
646.64s - 654.88s |  technology. Um, if I had my slides, which I would, uh, I would show you that, uh, you know, there's
654.88s - 662.64s |  technologies like ORCam, which is a, uh, a camera that you stick onto your glasses that helps to,
662.64s - 668.96s |  uh, provide things like facial recognition, um, what types of, you know, what denominations of
668.96s - 674.80s |  currency do I have? What color is my shirt? What's this text in front of me? Uh, applications that are
674.80s - 682.00s |  really helpful if you are blind so that you don't have to, you know, just hope that there's a braille
682.00s - 688.96s |  pattern or a, uh, audio version or somebody nearby who can read it out loud to you. Uh, these types
688.96s - 697.44s |  of technologies offer huge levels of independence, uh, to people that, that have disabilities. Um,
697.44s - 702.72s |  there's tools like Be My AIs as well coming out recently that, you know, even more questions
702.72s - 706.96s |  arise from this type of thing. These are tools that let you take a photo of something and then
706.96s - 711.20s |  have a conversation with a chat bot about what's in it. Uh, and if you look at YouTube, there's
711.20s - 715.76s |  examples of people saying, okay, you know, what's here? Oh, well, there's a microwave on a shelf.
715.76s - 721.52s |  There's a knife next to it. Okay. Where's the button for popcorn on my microwave? Oh, it's the
721.52s - 728.08s |  second button down on the left, right? That is incredible. That is game changing for blind
728.08s - 733.92s |  people. But again, we run into these challenges of, well, it's fantastic that the blind person
733.92s - 741.44s |  has access to this data. Who else gets access to that data? Uh, other examples I have here are
741.44s - 746.16s |  things like captioning glasses, right? Um, for people who are deaf or hard of hearing, uh, or
746.16s - 750.24s |  for people who don't have English as a first language, there are captioning glasses by
750.24s - 756.80s |  companies like, uh, Xander and XRAI that will listen to what's going on and present a little
756.80s - 762.08s |  transcripts, uh, for you to read. Uh, and this is again, something, if you are deaf, that makes you
762.08s - 768.16s |  much more independent, much more able to partake in your kind of social life, uh, talk to people.
769.36s - 774.00s |  And yet who else can now read all of the conversations you're having?
775.44s - 780.80s |  Um, so there are many more examples of this, right? There's, there's many more things I could
780.80s - 786.72s |  describe to you about, uh, how XR can enable all of these assistive technologies, but let's take a
786.72s - 795.36s |  moment to talk about the risks. So the risks here are that in order for these things to function,
796.08s - 803.36s |  they basically act as little data vacuums, just sucking up, uh, either discreetly or continuously
803.36s - 808.64s |  data about you in terms of your gaze, your motion, uh, your biometric data, your location,
809.44s - 816.48s |  or data about your surroundings, you know, visual, auditory, temporal, spatial, uh, and those,
817.28s - 821.28s |  as you might expect, comes with a lot of risks. Um, three of them that I'd highlight for you.
822.00s - 831.60s |  First is non-consensual recording. So let's say you have a Billy who's blind, right? And he wants
831.60s - 836.64s |  to be able to recognize when his friend walks in the room. So he has a facial recognition app.
837.20s - 843.28s |  Now that is going to have to look at the face of everybody that walks into the room to function.
843.92s - 851.76s |  Uh, now how do we stop that from now reporting about all of the different bystanders that Billy
851.76s - 856.80s |  doesn't care about that did not give consent for that? How do we keep their identities safe, but
856.80s - 862.88s |  still make this tool useful? Uh, you can also think about the challenges of 3D mapping, right?
862.88s - 869.12s |  You know, if you are at a public university, a library or an airport, uh, it's fantastic to have
869.12s - 874.08s |  a 3D map of that for your navigation applications to be able to guide you to your gate, guide you
874.08s - 879.20s |  to the classroom you're going to. But let's say I, you know, I wearing my headset cause I, I did
879.20s - 884.16s |  my master's thesis on this of augmented reality for visually impaired people where we're using
884.16s - 889.04s |  the hollow lenses ability to map out the environment, uh, and then communicate useful
889.04s - 894.16s |  things about that. Now, let's say I'm wearing this as I walk around, it's mapping the space
894.16s - 900.08s |  around me. You know, if I go into my home and I map out my home, I now have a digital twin of my
900.08s - 907.36s |  home. Who has access to that twin, right? Same. If I go into a private facility or a government
907.36s - 911.76s |  office that they don't really take kindly to there being a bunch of 3D maps floating around
911.76s - 917.28s |  on the internet. Uh, how do we keep those safe? And all of these challenges with recording are
917.28s - 923.20s |  doubled or tripled in things like educational settings and healthcare settings, uh, where there
923.20s - 930.40s |  are major rules and laws covering what you can and can't record. Another big risk is data
930.40s - 935.36s |  retention, right? Let's say I need to pass some data up to the cloud to get processed.
936.32s - 942.48s |  Is it there and then gone? Is it just held in the moment or is it parked in some big server
942.48s - 947.36s |  farm somewhere? That means the organization that I've sent it to now can use it in perpetuity
947.92s - 952.48s |  or, you know, until they get a data breach and now everybody has that information.
953.04s - 957.76s |  Uh, wanting to make sure that when we do pass information to the cloud, that it's only held
957.76s - 962.56s |  for just as long as it needs to be is really important to keeping all our privacy safe.
964.08s - 967.76s |  Finally, I'm going to dip into science fiction a little bit for this one because
967.76s - 974.72s |  I'm a guess, I'm guessing that many of you like me are giant freaking nerds. Um, you can look at
974.72s - 980.48s |  things like a ghost in the shell standalone complex, for examples of perception hacking.
980.48s - 986.48s |  You know, if somebody is able to hack your headset, not only are they getting a record of
986.48s - 991.44s |  everything that you see in here, they could potentially be changing what you see in here.
992.00s - 998.08s |  Uh, you know, in ghost in the shell, there is the laughing man who is able to block himself out of
998.08s - 1003.12s |  everybody's cybernetic eyes. So nobody actually knows what he looks like. Uh, you can also look
1003.12s - 1008.40s |  at black mirror, because of course there's a black mirror episode about this, uh, for there's
1008.40s - 1014.24s |  an episode called men against fire, where soldiers are told they're going off to fight monsters,
1014.24s - 1021.44s |  mutants, these terrible monstrous creatures. Uh, and then a little flaunt, you know, a bug in the
1021.44s - 1027.12s |  software reveals to one of the soldiers, no, these are innocent civilians that you've been hunting
1027.12s - 1032.24s |  down and killing. Right. And now you may say, okay, this is all well and good. If you have
1032.24s - 1036.80s |  cybernetic eyes, we're a little ways away from that, but there are a lot of subtle ways that
1036.80s - 1041.84s |  this could be done. You know, for example, thinking about, um, advertisers who could
1042.40s - 1048.72s |  swap out billboards for their ads without you knowing, uh, thinking about political operatives
1048.72s - 1054.96s |  who could maybe every time you see a politician, make them a little bit uglier or something like
1054.96s - 1062.00s |  that. Right. To, to just subtly influence your perceptions. We need to be careful with who has
1062.00s - 1066.56s |  access to this data, both in and out, because these are the types of possibilities they're
1066.56s - 1071.52s |  going to come when more and more people start to wear these augmented reality glasses and headsets.
1073.52s - 1079.36s |  So we've talked about the good, you know, how XR technology can make life better for a lot of
1079.36s - 1084.16s |  people. We've talked about the bad, some of the risks that come with it. So how do we have the
1084.16s - 1090.24s |  best of both worlds? Well, again, I'm going to start with three because I only got half an hour
1090.24s - 1097.92s |  here. Um, the first one is on device processing. So doing as much as you can on the device and not
1097.92s - 1103.44s |  in the cloud. Uh, the vision pro actually has a pretty good policy about this for now, at least,
1103.44s - 1110.24s |  uh, where the pro acts as a gatekeeper between the data that is coming in from your sensors
1110.80s - 1116.64s |  and the apps that might want to use that data. Right. So it's not just like every single app
1116.64s - 1121.84s |  has full access to all your cameras and everything. It only get access to what it
1121.84s - 1127.52s |  needs in order to function. There's all those things like, uh, the, the optic ID it uses for
1127.52s - 1133.68s |  authentication is stored on device because as we know, uh, once your biometric data gets into the
1133.68s - 1138.88s |  cloud, it's a little harder to change than a password. Uh, there's a really great paper on
1138.88s - 1147.76s |  this called bystand AR, uh, by Corbett and his team, um, that talks about this idea of, uh,
1147.76s - 1155.20s |  basically automatically filtering out all bystanders from a scene. You know, you have the
1155.20s - 1161.20s |  camera, the camera input coming through, uh, it identifies all the faces and blurs all of them out
1161.20s - 1166.32s |  before it gets to a third party, except for the person you're talking to, right? There's a certain
1166.32s - 1172.80s |  threshold, uh, where between eye contact, voice communication, and other clues that tell you this
1172.80s - 1179.04s |  is the single person I'm interacting with. That one person gets their face and other information
1179.04s - 1186.32s |  sent off in order to get info about everybody else. It's kept private. Uh, data transparency
1186.32s - 1191.20s |  and control is another big one. We're talking about your right to know what is being collected
1191.20s - 1197.84s |  and for what purpose, you know, are AIs being trained on my gaze information, uh, control access
1197.84s - 1202.08s |  to your data and revoke it when necessary, and to make sure that your data gets deleted when it's
1202.08s - 1207.12s |  no longer needed. Now, if you're from Europe, congratulations, you have the GDPR and that
1207.12s - 1214.58s |  protects you from a lot of this stuff. If you're in the US, anyway, there's a great, uh, great paper
1214.58s - 1220.66s |  by, uh, Elise Dick of the Information Technology and Innovation Foundation a few years ago, uh,
1220.66s - 1225.46s |  that lays out some of the things that ought to be done on this, uh, for kind of policymakers,
1225.46s - 1229.54s |  lawmakers. So if you're interested, uh, I have that reference, I will happily send it to you.
1230.82s - 1236.26s |  Uh, and finally, because I think I just have a few minutes left here, consent. You know, consent is
1236.26s - 1242.18s |  the oldest and best way of protecting privacy, right? You consent to be recorded, you consent
1242.18s - 1248.90s |  to having your data used in order to help disabled people navigate the world. Um, there's a lot of
1248.90s - 1253.14s |  conversation about how to get consent in a feasible manner, right? Because, you know, if I
1253.14s - 1256.74s |  had a headset on right now, I couldn't just walk around and ask every single one of you, hey, can I
1256.74s - 1263.86s |  use this? Um, but you could imagine a scenario where, for example, uh, somebody's in a hospital
1263.86s - 1269.30s |  and all of the doctors and nurses have some type of token, you know, like a QR code they wear on
1269.30s - 1276.50s |  their shirt or something else that a headset could recognize and say, ah, these people have opted in
1276.50s - 1282.58s |  to facial recognition. It's okay to tell them, you know, tell the person using the headset their
1282.58s - 1287.22s |  name and their info and all of that. Um, there's a lot of interesting models around that. We don't
1287.22s - 1293.06s |  have time to get into them now, but, uh, again, making sure that we have systems in place that
1293.06s - 1300.50s |  know who has and who hasn't consented to having their information recorded, uh, is going to be
1300.50s - 1309.14s |  vital as we go forward. So, that is, uh, XR accessibility and privacy in a nutshell. Um, I
1309.14s - 1312.34s |  really want to thank you all for coming. I want to thank, uh, you all for having me. This is my
1312.34s - 1319.46s |  first time at DEF CON. Uh, it is a weird and wonderful place. Um, and I would love to take
1319.46s - 1328.75s |  a few questions in the time we have left. I see you all just came here to get comfy.
1329.39s - 1333.79s |  All right. Well, if anybody has any, uh, feel free to come talk to me. Uh, you can reach us
1333.79s - 1344.43s |  at xraccess.org. That's X-R-A-C-C-E-S-S dot O-R-G. Um, we have, uh, some really great resources. We
1344.43s - 1350.03s |  have a research network. If you're doing research into these related topics, definitely reach out
1350.03s - 1355.87s |  to us because we want to shine a spotlight on you. Um, because it takes all of us coming together
1356.11s - 1362.11s |  to solve these problems. We need the tech companies. We need the legislators. We need
1362.11s - 1367.55s |  the watchdogs. We need the disabled people and we need all of you with your expertise.
1367.55s - 1370.67s |  Uh, so I think we'll end it there and thanks so much.