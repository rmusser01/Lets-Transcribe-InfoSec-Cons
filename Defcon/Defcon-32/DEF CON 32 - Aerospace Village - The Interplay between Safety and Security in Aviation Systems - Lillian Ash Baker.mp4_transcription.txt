{
  "webpage_url": "local:1731743171:17ec8593:DEF CON 32 - Aerospace Village - The Interplay between Safety and Security in Aviation Systems - Lillian Ash Baker.mp4",
  "title": "DEF CON 32 - Aerospace Village - The Interplay between Safety and Security in Aviation Systems - Lillian Ash Baker.mp4",
  "description": "Local file",
  "channel_url": null,
  "duration": null,
  "channel": null,
  "uploader": null,
  "upload_date": null
}

0.00s - 1.88s | This text was transcribed using whisper model: large-v2

 All right, good afternoon, everyone.
1.88s - 3.28s |  I am Lillian Ashbaker.
3.28s - 4.80s |  I'm product security engineer
4.80s - 7.20s |  at the Boeing company in Whisk Aero.
7.20s - 9.44s |  Today, I'll be discussing the most important part
9.44s - 11.62s |  of aviation systems development,
11.62s - 13.84s |  standards and certification.
13.84s - 16.28s |  But what I hope you get out of this
16.28s - 18.20s |  is an understanding of how the industry
18.20s - 20.20s |  has developed safe systems
20.20s - 24.56s |  and considers security in those designs.
24.56s - 28.96s |  First, we need to discuss the safety of these systems
28.96s - 32.24s |  and I'll make you all aware of what safe actually means
32.24s - 33.96s |  in the aerospace industry.
33.96s - 36.84s |  I hope you find this as interesting as I have.
36.84s - 39.40s |  I still can't shut up about it 15 years later.
40.62s - 42.28s |  So the first principles of safety
42.28s - 43.36s |  that we have to talk about
43.36s - 46.52s |  are failure conditions and probabilities, right?
46.52s - 48.40s |  All of this information comes out
48.40s - 51.64s |  of Advisory Circular 25 or 23,
51.64s - 54.44s |  if you go read for the pilots in the crowd,
54.44s - 56.60s |  that's part of the CFRs out there
56.60s - 60.40s |  that you're legally supposed to know.
60.40s - 64.84s |  So Advisory Circular 25-1309-1A,
64.84s - 66.88s |  this is all public information,
66.88s - 69.16s |  actually lays out all these probabilities
69.16s - 72.64s |  and kind of puts together this really nice graph
72.64s - 74.90s |  of probability versus consequence, right?
74.90s - 78.86s |  So you have probable, improbable and extremely improbable,
78.86s - 83.40s |  as well as an acceptability of those failures and faults.
83.40s - 85.36s |  And there's a line that runs right between it
85.36s - 87.80s |  that says acceptable and unacceptable, right?
87.80s - 89.64s |  So you have to develop the system
89.64s - 91.86s |  in order to understand
91.86s - 94.12s |  what the system effects are gonna be of that.
95.40s - 98.08s |  So as we move forward, those probabilities,
98.08s - 99.94s |  those failure classifications
99.94s - 102.28s |  actually have probabilities behind them
102.28s - 106.18s |  as defined in the Advisory Circulars, right?
106.18s - 109.08s |  So when we talk about safety,
109.08s - 111.50s |  we talk about the probabilities of failure.
111.50s - 113.78s |  So for a minor classification,
113.78s - 115.66s |  that's a probable failure condition
115.66s - 117.88s |  on the order of 10 to the minus fifth.
117.88s - 119.62s |  Major is 10 to the minus ninth,
119.62s - 121.78s |  that got reclassified as 10 to the seventh.
122.70s - 125.74s |  Hazardous is now 10 to the seventh.
125.74s - 129.58s |  Catastrophic is 10 to the ninth or less.
129.58s - 132.46s |  So that means that like probabilities of 10 to the ninth.
132.46s - 136.02s |  So think about the systems that you currently see in like IT
136.02s - 139.32s |  and how often they have to stay up and operate.
140.18s - 142.58s |  Our stuff has to operate and not fail.
143.78s - 149.61s |  So the design assurance levels are a major component
149.61s - 151.81s |  of how we develop these systems, right?
151.81s - 156.81s |  So what you have are a nice trace of failure conditions
157.47s - 159.25s |  with the severities,
159.25s - 162.01s |  with the actual definitions of what that is,
162.01s - 164.37s |  extremely probable, extremely remote,
164.37s - 166.05s |  and the probabilities themselves
166.05s - 169.49s |  that tie off to the functional DAL assignments.
169.49s - 171.47s |  So whenever you're talking about aviation systems,
171.47s - 175.11s |  if you see something that says that it is a DAL-C system,
175.11s - 176.85s |  this is what it means.
176.85s - 180.79s |  It means that that system has a major effect
180.79s - 184.31s |  on the system operation of the aircraft,
184.31s - 187.07s |  has a remote possibility of failure,
187.07s - 192.07s |  and has a failure probability of somewhere between
193.23s - 196.73s |  10 to the fifth to 10 to the seventh probability.
197.73s - 201.57s |  So with all these probabilities,
201.57s - 204.21s |  the way that the industry works through that
204.21s - 207.17s |  is that we have a bunch of functional hazard assessments,
207.17s - 212.17s |  which takes a functional look at the individual functions
212.77s - 214.45s |  that trace down throughout the system
214.45s - 215.61s |  and look at all the points
215.61s - 219.09s |  in which that function can be impacted.
219.09s - 223.17s |  So if it moves through three or four systems,
223.17s - 226.09s |  all the systems in the chain have to have some sort of way
226.13s - 231.71s |  of preventing failure conditions from occurring.
231.71s - 234.15s |  So once we do that,
234.15s - 239.15s |  these probabilities go into the functional DAL assignments.
239.29s - 240.63s |  If you go take a look,
240.63s - 242.99s |  here's where the standards start to come in.
242.99s - 247.99s |  DO-178, DO-254, and DO-278 for ground systems operations,
250.19s - 254.67s |  as well as ARP-4754 for systems development.
254.67s - 256.75s |  What those standards actually define
256.75s - 260.71s |  is not how you develop a system.
261.59s - 264.59s |  It is, a very important piece here,
264.59s - 267.83s |  the development objectives that you have to meet.
267.83s - 271.35s |  So that means that you can't just go write code.
271.35s - 273.63s |  You have to have requirements for the code.
273.63s - 276.35s |  You have to have traceability down to the code itself.
276.35s - 280.03s |  You have to have traceability to the actual compiled code.
280.03s - 282.07s |  And then you actually have to test all that code.
282.07s - 284.03s |  And it's defined in tables
284.03s - 289.03s |  and design objectives throughout these different documents.
292.31s - 295.51s |  Those design objectives that you work through
295.51s - 298.67s |  are the deliverables that go to a regulatory body.
298.67s - 300.55s |  In the US, that would be the FAA.
300.55s - 302.23s |  Over in Europe, that'd be EASA.
302.23s - 304.79s |  If you have dual use between the two of them,
304.79s - 306.91s |  it will be shared between the two of them.
306.91s - 310.27s |  Those documents are the proof that you did the work.
310.27s - 313.07s |  You have to prove that you did the operations
313.11s - 314.79s |  and did the work.
314.79s - 317.15s |  So as you have a higher DAO level,
317.15s - 319.87s |  so DAO A would have the most stringent.
319.87s - 321.79s |  What's unique about DAO A
321.79s - 325.51s |  is that there is a required independence in the testing,
325.51s - 329.51s |  which means the person who had developed the system
329.51s - 332.11s |  cannot be the one who has tested the system.
332.11s - 334.51s |  It has to be a completely independent body
334.51s - 337.39s |  that does the verification of your code
337.39s - 339.75s |  or of your system, of your hardware
339.75s - 341.27s |  to ensure that there is independence
341.31s - 344.03s |  between the developers and the test teams.
346.60s - 349.12s |  All right, so now you all are experts on safety.
350.04s - 351.32s |  So now as we move forward,
351.32s - 355.36s |  we start to talk about what DO-356A is.
355.36s - 360.36s |  So DO-356A defines the cybersecurity development objectives
360.36s - 362.76s |  for aircraft systems.
362.76s - 365.92s |  One of the most important concepts in that
365.92s - 367.96s |  is this concept of IUEI,
367.96s - 372.96s |  which is intentional unauthorized electronic interactions.
373.56s - 374.44s |  What it means is that
374.44s - 378.60s |  someone has to be doing an attack intentionally.
378.60s - 381.60s |  They did not have authorization for the system
381.60s - 383.84s |  and it has to be electronic interactions.
383.84s - 387.44s |  So no, birds flying, we know that they're not real.
387.44s - 392.00s |  Birds flying into engines do not count, right?
392.00s - 394.98s |  That's not intentional by the bird to do that.
395.98s - 400.98s |  So this is what makes security threats
401.58s - 406.30s |  different from safety threats in our system development.
406.30s - 409.70s |  But how we develop our systems around the two of them
409.70s - 411.34s |  kind of start to touch.
411.34s - 415.54s |  So safety is more of a kind of a what and why questions
415.54s - 418.90s |  of how all these unintended adverse effects happen
418.90s - 421.90s |  within systems operation.
421.90s - 425.94s |  Security looks at more of the who and where questions,
425.94s - 426.78s |  right?
426.78s - 428.34s |  We care more about who's doing it
428.34s - 431.58s |  and what systems they're touching
431.58s - 434.14s |  because they should not have access to certain systems
434.14s - 438.24s |  within security boundaries and other places.
438.24s - 441.94s |  Where the safety and security meet is in the how.
441.94s - 443.50s |  How these events can happen
443.50s - 446.82s |  so that we can mitigate the effects of those faults
446.82s - 450.71s |  and the manipulation, all right?
450.71s - 455.19s |  So 356 brings in a new concept of SAL.
455.19s - 459.83s |  SAL is not directly tied to DAL
459.83s - 463.17s |  despite what a lot of people like to talk about with this.
463.17s - 465.79s |  But what it is, is if you look at that table at the top,
465.79s - 470.25s |  table 4-4, which is taken directly out of DO-356-A,
471.15s - 473.99s |  it gives you a threat condition effect severity,
473.99s - 478.31s |  which kind of looks a lot like the advisory circulars
478.35s - 479.79s |  with the definitions
479.79s - 483.71s |  and gives you SAL levels for that mitigation.
483.71s - 485.43s |  But what's unique here is that something
485.43s - 489.25s |  that has an effect condition of catastrophic,
490.15s - 494.07s |  all of a sudden it has these two SAL levels, right?
494.07s - 494.95s |  That's kind of weird.
494.95s - 496.89s |  Why would you do two SAL levels?
497.99s - 500.99s |  The big part about security development
500.99s - 503.63s |  is that we look at individual threat vectors
503.63s - 505.39s |  as it moves through a system
505.39s - 507.15s |  because we have to look at every point
507.15s - 509.07s |  in which it could touch a system
509.07s - 511.87s |  and have a final effect that may or may not
511.87s - 515.55s |  have a safety effect on the entire aircraft.
515.55s - 518.51s |  So if we do have an effect on the entire aircraft,
518.51s - 521.51s |  we have to go back through our safety analyses
521.51s - 524.07s |  and we have to place mitigations,
524.07s - 527.67s |  two of them in this case, of SAL-3 and SAL-2
527.67s - 532.19s |  in our system to prevent a catastrophic threat condition.
532.19s - 537.19s |  So those mitigations have to be developed
538.03s - 541.35s |  with security objectives, the design objectives
542.55s - 544.31s |  for SAL-3 and SAL-2.
544.31s - 546.99s |  So if you're developing a system
546.99s - 549.19s |  and if you look at the actual
551.35s - 554.39s |  security assurance level objectives,
554.39s - 557.59s |  they look very, very, very, very similar
557.59s - 561.07s |  to exactly what DO-178 and DO-254
561.11s - 564.55s |  because all these documents are in concert with one another.
564.55s - 565.95s |  They all feed from one another.
565.95s - 569.07s |  They all use a lot of same concepts from one another.
569.07s - 573.11s |  They all try to use the same structures.
573.11s - 574.91s |  So that makes it really easy for us
574.91s - 578.11s |  to take our cybersecurity mitigations
578.11s - 581.31s |  and place them into software or hardware
581.31s - 586.31s |  and have the process look the same for development.
588.58s - 589.42s |  All right?
589.42s - 593.50s |  So we're gonna do a little bit of a safety analysis
593.50s - 594.34s |  on a system, right?
594.34s - 597.14s |  So we have system A, we have system B, we have system C,
597.14s - 598.62s |  and then we have a user display, right?
598.62s - 601.32s |  It could be any sort of function here.
601.32s - 603.86s |  So we do our functional hazardous assessment
603.86s - 608.86s |  and it says that this system has a function that is DAL-B.
609.02s - 609.86s |  Okay?
609.86s - 613.62s |  So we're looking at a path of DAL-B,
613.62s - 616.76s |  hazardously misleading data to display.
617.78s - 619.06s |  And what we're gonna do is we're gonna apply
619.06s - 621.02s |  safety requirements onto this system.
621.02s - 623.86s |  So we add in some monitors for failures
623.86s - 625.98s |  and then we'll enunciate those.
625.98s - 627.70s |  We check the validity of the inputs.
627.70s - 630.78s |  We check the system B and system C, right?
630.78s - 633.10s |  System B is just gonna do a really simple operation
633.10s - 634.62s |  of adding something on there.
634.62s - 638.86s |  It could be either changing data or manipulating data
638.86s - 642.86s |  or merging data at some points.
644.02s - 645.02s |  And now what we're gonna do
645.02s - 646.94s |  is we're gonna look at a threat.
646.94s - 649.58s |  We have an attack that modifies code or memory
649.58s - 651.22s |  and changes that two to a four.
652.56s - 653.46s |  That's pretty bad.
655.14s - 657.22s |  Don't know how they managed to do that.
657.22s - 659.28s |  But when we look at this system,
659.28s - 660.22s |  there's erroneous data
660.22s - 661.58s |  that's now flowing through the system, right?
661.58s - 665.42s |  This is the hazard effect that we're looking at.
665.42s - 669.10s |  We're looking at how we can cause
669.10s - 673.18s |  hazardously misleading data DAL-B impacts to the system.
674.06s - 675.90s |  So fine, guess what?
676.82s - 678.22s |  We're gonna hash the memory spaces
678.22s - 679.74s |  so that none of that changes, right?
679.74s - 681.62s |  We're gonna put hashes in place
681.62s - 683.38s |  so that the values that we're adding
683.38s - 686.46s |  or subtracting or changing around
686.46s - 688.94s |  the whole memory spaces are then hashed, right?
690.18s - 692.98s |  And we'll get back to why I picked hashing
692.98s - 694.04s |  in the first place.
694.04s - 695.20s |  Safety analysis also said
695.20s - 697.18s |  that there has to be a system B prime,
697.18s - 699.94s |  which is a secondary thread to the system
699.94s - 703.62s |  so that system C merges data
703.62s - 705.78s |  from both system B and system B prime.
707.10s - 709.02s |  Kind of looks a lot like what we do
709.02s - 711.86s |  for pilot side, co-pilot side in aircraft.
712.94s - 714.90s |  Oh, there was another attack
714.90s - 717.44s |  that our pen testing team came up with.
719.62s - 720.76s |  They flooded the interface,
720.76s - 722.78s |  they did a DDoS attack on our system C
722.78s - 724.90s |  and it prevented data from going through
724.90s - 728.06s |  to the user display, crashed the system.
728.06s - 730.82s |  Well, I guess we need to go through
730.82s - 733.12s |  and put together another mitigation.
733.12s - 735.86s |  So now we're gonna need some sort of DDoS protection,
735.86s - 738.12s |  some sort of rate limiting in there.
740.12s - 744.30s |  It's a pretty secure system so far,
744.30s - 746.94s |  except they found a third attack,
746.94s - 748.34s |  which is actually a mode command
748.34s - 751.58s |  that's sent into systems, injected at system C,
751.58s - 753.76s |  which then back propagates through the system
753.76s - 756.34s |  to system A, which changes a mode,
756.34s - 759.22s |  which then forces data to come out incorrectly
759.22s - 761.90s |  without a pilot commanding a mode change.
762.90s - 766.46s |  So you see how there's kind of a non-linearity
766.46s - 767.70s |  through these systems
767.70s - 769.74s |  where you could get these system effects
769.74s - 773.18s |  without having exactly changed or manipulated
773.18s - 777.62s |  or without having commands be sent
777.62s - 780.38s |  and get unintentional data
780.38s - 781.82s |  that was not supposed to be there
781.82s - 784.10s |  without some sort of other checks, right?
784.10s - 786.10s |  So a lot of aircraft systems,
786.10s - 787.94s |  it's not just that we press a button
787.94s - 788.90s |  and the mode comes through.
788.90s - 791.20s |  You press a button, it goes through,
791.20s - 792.68s |  it sends back bits that says,
792.68s - 795.88s |  yes, I saw that you changed the mode.
795.88s - 797.60s |  Here's the new mode information.
798.60s - 799.68s |  But what's unique about this
799.68s - 803.74s |  is that that mode command may have also propagated back
803.74s - 806.52s |  through the B prime and A prime systems
806.52s - 808.02s |  through the secondary thread,
808.96s - 812.80s |  and has also changed those modes,
812.80s - 817.20s |  which gets around our cross-checking in system C.
817.20s - 818.72s |  So now a system,
818.72s - 822.12s |  so the primary thread and the secondary threads
822.12s - 826.60s |  are now sending the same data, valid data across,
826.60s - 831.14s |  and it's not being picked up by system C.
831.14s - 833.90s |  So what's interesting about this whole development here
833.90s - 837.74s |  is that where safety and security really touch
837.74s - 841.22s |  is some of the implementations that we actually have here.
841.22s - 844.30s |  So you take a look at system B
845.34s - 849.66s |  and we applied hashing memory.
849.66s - 851.42s |  Our safety analysis also came back
851.42s - 853.44s |  and said that B prime needed to be added
853.44s - 855.88s |  as a safety mitigation on the system.
857.06s - 858.86s |  But what does that do for the safe
858.86s - 862.34s |  or security of the system, right?
862.34s - 864.02s |  Now I have a secondary thread
864.02s - 866.34s |  that I can cross-check data against,
866.34s - 871.24s |  an independent thread that somebody may not have access to
871.24s - 875.86s |  that I can ensure that is part of the whole security posture
875.86s - 877.50s |  of this whole entire system.
878.50s - 881.86s |  So hashing memory is a great one, right?
881.86s - 884.14s |  We use it in cybersecurity
884.14s - 886.90s |  in order to prevent manipulation,
886.90s - 889.74s |  intentional manipulation of memory spaces.
889.74s - 893.30s |  Well, over on the aerospace or on the safety side,
893.30s - 894.34s |  they do that sort of stuff
894.34s - 897.66s |  to prevent accidental manipulations from like,
897.66s - 901.70s |  I don't know, single event upsets from the sun, right?
901.70s - 903.76s |  Neutron events on memory spaces.
904.76s - 907.78s |  Other areas would be like duplicating
907.78s - 911.60s |  or triplicating data stored across the system
911.60s - 913.82s |  so that if you have manipulation in one place,
913.82s - 915.52s |  you can go pick it up in another place.
915.52s - 917.28s |  And if that one's still manipulated,
917.28s - 919.38s |  you can go and pick it up somewhere else
919.38s - 923.24s |  and cross-check those three different memory spaces.
923.24s - 928.24s |  So safety and security have to kind of be developed together
930.24s - 931.88s |  in these systems
931.92s - 937.92s |  because you have these concepts in here
937.92s - 940.04s |  of inherited security principles
940.04s - 941.74s |  or properties of the system.
944.88s - 947.96s |  Security is not the only developer of the system.
947.96s - 949.44s |  Safety is doing it.
949.44s - 951.44s |  Implementers of code are doing this.
951.44s - 953.24s |  They're developing their own requirements
953.24s - 955.88s |  with how they either think the system should work
955.88s - 960.04s |  or how the system has been developed in the past
960.04s - 964.32s |  and how other systems have been developed.
964.32s - 966.68s |  And so we have to take a look
966.68s - 970.08s |  at not just security requirements.
970.08s - 973.56s |  We have to look at the entire system requirements pool
973.56s - 975.60s |  to see which items might be part
975.60s - 979.00s |  of the security posture of the system.
979.00s - 980.36s |  The reason why we want to do that
980.36s - 982.00s |  is because we're gonna take credit for those
982.00s - 984.46s |  in our threat models at some point.
985.88s - 988.64s |  And if you take credit for them in your threat models,
988.64s - 990.72s |  you have to provide the documentation
990.72s - 992.56s |  as part of the design objectives.
992.56s - 993.88s |  And if you have to provide data
993.88s - 995.48s |  as part of your design objectives,
995.48s - 997.24s |  it's part of your certification baseline
997.24s - 999.28s |  and you want to take that credit for it.
999.28s - 1001.78s |  It all comes back down to the standards
1001.78s - 1006.56s |  and the certification of these systems.
1006.56s - 1009.06s |  Another important piece in here
1009.06s - 1012.28s |  is that you can also have system effects
1012.28s - 1017.28s |  where safety and security may interact
1017.48s - 1019.92s |  with each other in a negative manner.
1019.92s - 1021.60s |  Where one may trigger,
1021.60s - 1024.96s |  you might want to trigger a safety event
1024.96s - 1028.94s |  or you have an event that triggers some safety safeguards
1028.94s - 1030.30s |  that have been in place
1031.20s - 1033.00s |  and the security of the system is reduced
1033.00s - 1036.00s |  because systems have now been reset and they lost state.
1037.00s - 1041.02s |  You might have security implementations in there
1041.02s - 1043.44s |  where it prevents data from cross flowing
1043.44s - 1045.20s |  from one side to another,
1045.20s - 1049.68s |  or you may have other pieces where data's unavailable
1049.68s - 1051.36s |  because it's been encrypted
1051.36s - 1053.92s |  that affects the safety of the system.
1053.92s - 1057.84s |  So it's very important to look at how safety
1057.84s - 1060.22s |  and security interplay in the requirements
1060.22s - 1062.18s |  and determine like, is this a positive
1062.18s - 1065.02s |  or a negative part of our system?
1066.72s - 1071.72s |  So in summary, aircraft cybersecurity is very young.
1072.72s - 1077.72s |  DO-356 was first released in about in 2014.
1081.72s - 1083.96s |  In comparison to the advisory circular
1083.96s - 1088.96s |  that I showed you at first, AC-25-1307,
1089.92s - 1092.24s |  that was released in 88.
1092.24s - 1095.56s |  We've had these definitions around
1095.56s - 1100.56s |  in aviation for almost 40 years.
1102.71s - 1104.67s |  40 years of development time
1104.67s - 1107.35s |  to learn how to do all these development principles
1107.35s - 1111.55s |  with how to develop safe code,
1111.55s - 1114.67s |  how to develop safe hardware
1114.67s - 1117.75s |  has been going on for a very long time.
1117.75s - 1119.23s |  But the security of these systems,
1119.23s - 1121.91s |  because they're becoming more and more connected
1121.91s - 1126.91s |  and even more highly connected in real time in the future,
1128.27s - 1131.31s |  these systems need better security principles
1131.31s - 1134.07s |  that work with how the systems are developed
1134.07s - 1136.75s |  in order to provide certification boundaries.
1141.41s - 1143.89s |  To touch upon the technological limitations,
1143.89s - 1147.01s |  prior systems in the past used to have federated systems
1147.01s - 1151.49s |  where you had multiple single purpose systems onboard,
1151.49s - 1154.89s |  which then moved into more highly integrated systems,
1154.89s - 1157.61s |  which then moved into more highly integrated
1157.61s - 1159.33s |  networking systems as well.
1159.33s - 1162.45s |  So those boundaries of data
1162.45s - 1166.73s |  that you couldn't get security issues across
1166.73s - 1170.05s |  because of the highly federated nature of these systems
1170.05s - 1173.33s |  is now being whittled away at as part of the development
1173.33s - 1175.57s |  because of the demands of higher speed buses.
1175.57s - 1180.57s |  Airing 429 is not fast at all, but Ethernet is,
1180.65s - 1182.49s |  and we can do that deterministically.
1184.05s - 1187.21s |  The way that security brings those direct impacts
1187.21s - 1190.73s |  has to be developed as part of the architecture,
1190.73s - 1194.05s |  because in the end, you can't have a safe system
1194.05s - 1197.73s |  with also having a cyber secure system.
1197.73s - 1198.57s |  Thank you.