{
  "webpage_url": "https://www.youtube.com/watch?v=Qua92jLf2fE",
  "title": "DEF CON 32 - National Labs Use of XR - Martin Pratt",
  "description": "The DOE National Lab mission space includes exploring the use of disruptive technology to enable increasing efficiency and abilities of operations critical to national security, infrastructure, communication, and many other fields. The XR field has become a new area of active research and implementation at many national labs across the US, integrating with cutting edge hardware and software to enable users with increased capabilities. At the Pacific Northwest National Lab (PNNL), we have been using immersive XR platforms to enable a variety of government and external sponsors with novel approaches to their field. These include creating new 3D virtual twins to enable remote engagements as if remote users had access to one-of-a-kind lab equipment, creating simulation environments of hazardous environments or dangerous situations that can\u2019t be recreated in the real world, and outreach and communication projects to engage both sponsors and the public with critical information about current security threats. During this presentation I will touch on a few case studies of projects taken on at PNNL to make the best use of XR platforms, and where we see future development with this capability.",
  "channel_url": "https://www.youtube.com/channel/UC6Om9kAkl32dWlDSNlDS9Iw",
  "duration": 1435,
  "channel": "DEFCONConference",
  "uploader": "DEFCONConference",
  "upload_date": "20241016"
}

0.18s - 1.86s | This text was transcribed using whisper model: large-v2

 Hello, hello.
1.86s - 2.78s |  Checking this is on.
2.78s - 3.46s |  All right.
3.46s - 4.34s |  Sorry for the delay.
4.34s - 9.06s |  But I think we're good to get going now.
9.06s - 10.42s |  Nice to meet everyone.
10.42s - 11.58s |  My name is Martin Pratt.
11.58s - 14.90s |  I'm a software engineer at the Pacific Northwest National Lab
14.90s - 16.38s |  up in Washington state.
16.38s - 19.58s |  And today I'm going to talk to you a little bit about some
19.58s - 21.30s |  of the work that we do up there with immersive
21.30s - 25.06s |  technologies, with virtual and augmented realities, and a
25.06s - 27.54s |  variety of different situations, as well as one of
27.54s - 29.34s |  the things that we're actually demoing over in the XR
29.38s - 30.22s |  Village this week.
30.22s - 32.66s |  So please stop by if you want to actually try
32.66s - 35.69s |  some of this stuff out.
35.69s - 37.79s |  So to start with, I'm just going to go over a little bit
37.79s - 40.65s |  about what we do in immersive computing at PNNL.
43.53s - 45.93s |  This includes quite a few different things.
45.93s - 49.05s |  We are not just specific to one particular project, but we
49.05s - 51.53s |  do actually cover the entire gamut of what
51.53s - 54.17s |  we do at the lab.
54.17s - 57.09s |  I'll go into a little bit more detail about what we're doing
57.09s - 61.17s |  with the project that we're demoing over here this week.
61.17s - 64.21s |  And then I'll also go into some of the other XR
64.21s - 67.49s |  applications that we've used at the lab that we've found as
67.49s - 71.69s |  effective, able to communicate well to sponsors and partners
71.69s - 74.25s |  and the public as well, and just
74.25s - 78.67s |  maybe some lessons learned.
78.67s - 82.63s |  So a little bit about immersive computing at PNNL.
82.63s - 85.35s |  We've been around for around about eight years now.
85.35s - 88.91s |  We started on the first sort of the big push into VR back in
89.11s - 92.27s |  2016, 2015 time.
92.27s - 94.71s |  Since that time, we've had to adapt considerably as the
94.71s - 96.31s |  technology has changed.
96.31s - 101.11s |  We've had to sort of adapt as well to the changing face of
101.11s - 104.11s |  what the lab is doing and what their priorities are.
104.11s - 106.35s |  So the lab, if anyone's unfamiliar with the National
106.35s - 109.63s |  Lab System, is we're looking at trying to increase
109.63s - 112.71s |  efficiency in the economy for the US government, as well as
112.71s - 116.03s |  the people in the public around the country as well.
116.03s - 119.99s |  And then we also, the lab itself actually exists
119.99s - 123.47s |  primarily in association with the Hanford site out in
123.47s - 124.19s |  eastern Washington.
124.19s - 125.95s |  So we do a lot of work with nuclear
125.95s - 128.27s |  remediation, nuclear energy.
128.27s - 129.43s |  But that doesn't stop there.
129.43s - 132.91s |  We also go into more renewable energies as well, looking at
132.91s - 135.75s |  geothermal, looking at wind and tidal power.
135.75s - 139.23s |  We have a whole marine sciences campus out in western
139.23s - 139.91s |  Washington.
139.91s - 143.19s |  So we look at marine energy and the impacts that that has
143.19s - 144.43s |  on our systems as well.
146.95s - 150.99s |  Each of those areas that I mentioned can benefit from
150.99s - 153.43s |  XR technologies in some form or another.
153.43s - 157.31s |  So we're on hand to try and make sure that they can
157.31s - 159.91s |  envision what they're doing and get something out there
159.91s - 163.41s |  that's impactful.
163.41s - 164.85s |  What we do, we do a lot of design.
164.85s - 168.49s |  We work with sponsors directly to try and actually envision
168.49s - 170.57s |  what they're trying to produce.
170.57s - 173.41s |  There's a lot of interaction at the early stages trying to
173.41s - 175.21s |  make sure that we are actually getting
175.21s - 176.85s |  what the sponsor wants.
176.85s - 180.69s |  And that can boil right down to actually the platform that
180.69s - 182.01s |  we're trying to use.
182.01s - 187.33s |  So in certain cases, certain immersive platforms may not be
187.33s - 191.13s |  the right tool to use.
191.13s - 192.45s |  People want to create environments and
192.45s - 192.93s |  things like that.
192.93s - 195.45s |  That sort of favors a more virtual reality aspect.
195.45s - 198.13s |  Some people want to bring in digital twins or bring things
198.13s - 199.77s |  into their environment themselves.
199.77s - 203.97s |  So we have to make sure that we're adaptable and we can
203.97s - 207.77s |  change with what those different sponsors may need
207.77s - 209.21s |  when those things arise.
211.81s - 215.13s |  We do actually create a lot of content ourselves.
215.13s - 217.73s |  We do a lot of 3D asset development, because a lot of
217.73s - 221.17s |  the systems and things that we're trying to recreate and
221.17s - 224.37s |  envision are very specific.
224.37s - 226.29s |  And they may not exist out there in the world in general.
226.29s - 231.45s |  So we have to be able to create what we can at as high
231.45s - 233.69s |  level as possible.
233.69s - 235.97s |  And then the last thing is actually to implement those
235.97s - 239.49s |  3D assets into a virtual or augmented or some sort of 3D
239.49s - 244.21s |  environment, so that we can then explore and go and show
244.21s - 248.42s |  this to the world.
248.42s - 251.22s |  So the different applications that we end up going towards,
251.22s - 253.18s |  they can be quite varied.
253.18s - 255.30s |  We do a lot of training platforms, so taking people
255.30s - 258.02s |  into environments that they may not normally go into and be
258.02s - 260.50s |  able to do it repeatedly over and over again, so they'd be
260.50s - 262.86s |  able to build up those skills before they actually encounter
262.86s - 266.10s |  the situation in real life.
266.10s - 268.74s |  We also work with scientists as well to try and do
268.74s - 271.94s |  scientific visualizations, as well as situational awareness
271.94s - 274.34s |  to visualize data.
274.34s - 277.26s |  So data that's inherently three dimensional lends itself
277.26s - 280.38s |  very well to both virtual and augmented reality systems.
280.38s - 283.14s |  We create environments that are able to envision that data
283.14s - 288.18s |  and ideally give them new insights into what that data's
288.18s - 289.18s |  trying to show.
289.18s - 294.34s |  And that has happened quite a few times during this.
294.34s - 295.50s |  We're not just sponsor facing.
295.50s - 297.02s |  We are public facing as well.
297.02s - 300.06s |  We do a lot of communication, not just to the general
300.06s - 306.18s |  public, but to academia, to industry, to third parties.
306.18s - 309.06s |  And that communication can work really well when you're
309.06s - 311.94s |  doing something with something new and exciting.
311.94s - 313.90s |  So taking people to an environment that they may not
313.90s - 317.42s |  normally go into, this can be quite a novel approach and
317.42s - 324.41s |  quite engaging for those folks.
324.41s - 327.77s |  We are using the very latest hardware we
327.77s - 330.45s |  can get our hands on.
330.45s - 334.49s |  As I said, we started at the very early stages of VR and AR
334.49s - 338.21s |  as that sort of became more mainstream.
338.21s - 342.69s |  So we started with things like HoloLens 1 with Oculus Rift.
342.69s - 345.45s |  HTC Vive, when the first one of those came out,
345.45s - 346.61s |  we had one too.
346.61s - 351.33s |  But now we're starting to progress into much more modern
351.33s - 356.61s |  systems, more latest technology that's out there.
356.61s - 359.05s |  Working with things like VR Passthrough, we do quite a
359.05s - 361.69s |  lot these days.
361.69s - 364.49s |  And we have up here also, not up here because the
364.49s - 369.33s |  presentation's over here, we also have a Vario XR3, which
369.33s - 371.21s |  we're going to demo today.
371.21s - 373.25s |  But we also have it over in our booth over in the XR
373.25s - 374.29s |  Village as well.
374.29s - 377.37s |  And that equipment is sort of latest tech that we can get
377.37s - 378.97s |  our hands on.
378.97s - 381.09s |  The XR4 came out just after we bought this one.
381.09s - 386.21s |  But this is certainly a step up in rendering capability
386.21s - 388.85s |  they're actually able to achieve, which does have a
388.85s - 393.65s |  significant impact with what the sponsors actually want.
393.65s - 396.41s |  So that takes us through a little bit about some of the
396.41s - 397.73s |  immersive capability background.
397.73s - 400.53s |  But I also want to talk about why we're here this week.
400.53s - 403.29s |  And that is primarily to demonstrate one of the
403.29s - 405.57s |  projects that we've been working on, which is the
405.57s - 406.97s |  CELOR XR project.
406.97s - 411.41s |  So CELOR stands for the Control Environment Laboratory
411.41s - 414.69s |  Resource and is run in partnership with the Cyber
414.69s - 418.17s |  Security and Infrastructure Security Agency, or CISA,
418.21s - 421.41s |  which is a DHS agency.
421.41s - 424.53s |  And what we're trying to do with this project is actually
424.53s - 429.85s |  create test platforms that are realistic, that use the same
429.85s - 433.33s |  hardware, that use the same software, as real systems that
433.33s - 435.17s |  exist out in the real world.
435.17s - 440.33s |  So we can actually test different methods of finding
440.33s - 444.21s |  threats, to do red-blue teaming or things like that,
444.21s - 447.93s |  and do it in a safe and reliable environment.
447.93s - 451.61s |  And what the team actually has done is not only created the
451.61s - 457.93s |  software on the interfaces that we use, but also we've
457.93s - 462.41s |  created physical models and scaled-down models of these
462.41s - 465.65s |  systems that we call skids.
465.65s - 468.33s |  And those skids are about the size of a tabletop.
468.33s - 471.21s |  They contain a good representation of what
471.21s - 474.73s |  actually happens in the real world, and they're completely
474.73s - 482.08s |  three-dimensional physical models.
482.08s - 485.72s |  In partnership with INL, the Idaho National Lab, as well,
485.72s - 487.60s |  we've created a number of these skids in a number of
487.60s - 488.88s |  different systems.
488.88s - 491.28s |  The ones that we have at P&L include things like the rail
491.28s - 496.32s |  yard system, the seaport, the hydropower plant, and the
496.32s - 499.32s |  water systems, as well.
499.32s - 501.12s |  So these are quite diverse systems.
501.12s - 505.24s |  They have quite diverse visualizations associated with
505.24s - 505.72s |  them, as well.
505.72s - 508.12s |  So we have to make sure we build our systems that are
508.12s - 514.56s |  able to pull between each of those skids as they go.
514.56s - 516.28s |  So I'm just going to show a quick video.
516.28s - 518.28s |  I apologize for folks at the back if it's a
518.28s - 519.20s |  little bit small.
519.20s - 524.28s |  But you can see some of these skids that we have at P&L. We
524.28s - 529.00s |  have the rail yard skid that scales down an actual system
529.00s - 530.80s |  that exists in the real world.
530.80s - 534.28s |  We invite people, industry partners, academia, sponsors,
534.28s - 538.12s |  into P&L to actually interact with these skids and try and
538.12s - 541.24s |  hack those skids to see how they do.
541.24s - 544.40s |  But what we can do with the XR system is
544.40s - 545.44s |  take it a step further.
545.44s - 548.84s |  We can scale this system so we can take it on the road, as we
548.84s - 551.32s |  have done this week.
551.32s - 555.40s |  And in doing so, we can create essentially a virtual twin of
555.40s - 556.12s |  these skids.
556.12s - 558.92s |  So we have the same sort of interactions that we're doing
558.92s - 561.16s |  with the real skids, but now we're just doing it all with a
561.16s - 564.56s |  virtual representation of it, as well.
564.56s - 571.44s |  So our envisioning for the future is actually to create
571.44s - 575.40s |  environments as well that immerse people in the systems
575.40s - 576.76s |  that we're trying to show them.
576.76s - 579.28s |  So not only do we see the scale version of those skids,
579.28s - 581.64s |  but we can actually take people into, for example, the
581.64s - 583.00s |  train cab.
583.00s - 585.32s |  So we're scanning essentially people down into the skid
585.32s - 589.80s |  itself to actually interact and play with the train as it
589.80s - 591.04s |  exists on the skid itself.
592.04s - 595.52s |  In order to capture the skid, we do a couple of different
595.52s - 595.76s |  ways.
595.76s - 598.58s |  We create a virtual model, but we also record in three
598.58s - 599.96s |  dimensions as well.
599.96s - 601.92s |  So we use a software called DepthKit, and I'll go into
601.92s - 605.80s |  this in a sec, to be able to recreate that 3D
605.80s - 609.32s |  representation of the skid in a virtual environment.
609.32s - 611.68s |  We can do lots of different things, like create trains to
611.68s - 615.40s |  derail, and water systems to break, and overflow, and all
615.40s - 622.46s |  that fun stuff that we can't really do in the real world.
622.46s - 626.30s |  So as I said, why CellarXR?
626.30s - 628.02s |  Why are we actually building this platform?
628.02s - 629.34s |  Well, we kind of want to scale this.
629.34s - 632.74s |  We want to take this on the road.
632.74s - 634.50s |  And we're using a bunch of different softwares.
634.50s - 637.38s |  We're building most things in Unity so we can port to
637.38s - 641.34s |  different platforms, but we're also making use of this 3D
641.34s - 643.38s |  capture software called DepthKit.
643.38s - 646.22s |  And this is actually a third party software created by a
646.22s - 649.54s |  company called Evercoast, and they're able to do real time
649.54s - 653.54s |  3D capture using up to, at the moment, up to 10 different
653.54s - 655.26s |  sensors, but I think we're going to get a bit higher than
655.26s - 659.26s |  that in the future, to recreate a 3D model of the
659.26s - 660.94s |  scale of what we're actually trying to do.
660.94s - 664.34s |  So that's the tabletop scale, which is kind of nice.
664.34s - 666.78s |  So at the moment, we've actually created this demo to
666.78s - 669.94s |  use on the HoloLens, and also on the VarioXR3.
669.94s - 672.00s |  In the future, we'll probably take this to the Quest 3, and
672.00s - 674.58s |  then any other further headsets that we see being
674.58s - 680.47s |  useful in the future, we can definitely do that.
680.47s - 683.43s |  So for the DepthKit setup itself, we are actually using
683.43s - 686.39s |  10 Femto bolts at the moment.
686.39s - 689.27s |  These 10 Femto bolts are calibrated and organized in a
689.27s - 692.39s |  certain geometry around each of these skids, and is able to
692.39s - 696.63s |  capture to pretty good resolution on most of the
696.63s - 699.03s |  surfaces that we're actually using.
699.03s - 701.27s |  We're actually able to capture in real time, so we can get up
701.27s - 703.67s |  to 30 to 60 frames per second.
703.67s - 705.51s |  And in certain cases, we're actually able
705.51s - 707.23s |  to live stream this.
707.23s - 709.03s |  Unfortunately, we were hoping to be able to live stream
709.03s - 713.43s |  today, the bandwidth that we were able to get to today
713.43s - 715.25s |  unfortunately wasn't high enough to get a good
715.25s - 717.39s |  representation of what we can actually show.
717.39s - 720.27s |  But generally speaking, we can get up to 30 frames per second
720.27s - 726.89s |  at 4K with this stream, which is really kind of nice.
726.89s - 731.65s |  A little bit more about the app development is that one of
731.65s - 733.57s |  the problems that we interacted with is the fact
733.57s - 735.85s |  that a lot of these surfaces are reflective or shiny on the
735.85s - 737.21s |  skids themselves.
737.21s - 742.29s |  So we had to try and find a way to interact, try and work
742.29s - 747.09s |  with DepthKit and Evercoast to create a way to represent
747.09s - 749.49s |  those shiny and reflective surfaces.
749.49s - 753.41s |  They were able to create a shader to be able to project
753.41s - 756.73s |  the camera systems onto a surface that we could use the
756.73s - 759.25s |  CAD designs for the skids themselves for.
759.25s - 762.97s |  And in doing so, we were actually able to give a pretty
762.97s - 765.61s |  good representation of those skids, and we'll show you that
765.61s - 768.21s |  in a second, so long as all the technology works.
768.21s - 770.97s |  We've been having a few issues this morning.
770.97s - 773.57s |  These skids that we're going to show are scale models of
773.57s - 776.13s |  the actual skids themselves, but we're actually also able
776.13s - 778.65s |  to show more full-scale assets
778.65s - 780.91s |  associated with that model.
780.91s - 784.61s |  So with that, I'm going to hand over to, I'm just going
784.61s - 787.61s |  to switch over the HDMI port, and hopefully this works.
787.61s - 789.89s |  My lovely assistant, Brandon DeGear, is
789.89s - 791.29s |  going to be demoing.
791.29s - 793.21s |  He's been helping working on this software
793.21s - 809.70s |  quite considerably.
814.58s - 817.38s |  All right, so Brandon, if you wouldn't mind taking us
817.38s - 819.06s |  through a little bit of what you're seeing.
819.06s - 821.78s |  So we have the rail skid up here.
821.78s - 825.30s |  This is in what we call exploration mode.
825.30s - 827.58s |  So we can actually have a demonstration of these skids
827.58s - 830.98s |  in action completely virtually, and show off
830.98s - 833.50s |  different features of that skid as we go through.
833.50s - 835.34s |  So we have a bunch of different
835.34s - 837.18s |  interactable objects on there.
837.18s - 838.62s |  We're using everything with hand tracking on
838.62s - 840.46s |  this value as well.
840.46s - 843.14s |  So we can bring up things like the train cab and actually go,
843.58s - 845.98s |  if we had space to step into it, we could actually go and
845.98s - 849.06s |  step into the train cab as well.
849.06s - 851.34s |  There are interactable elements within this, too.
851.34s - 853.82s |  So you can actually change the speed of the trains within the
853.82s - 855.78s |  app itself.
855.78s - 859.38s |  And in certain cases, we run scenarios as well that allow
859.38s - 862.50s |  us to do things like train derailments and turning
862.50s - 866.26s |  critical systems on and off as we go.
866.26s - 871.58s |  So that's a quick overview of the rail skid.
871.58s - 874.38s |  But if we go into the wastewater skid now, which is
874.38s - 875.50s |  one of the other things that we developed.
875.50s - 878.26s |  And we're going to actually be able to see what we did with
878.26s - 881.90s |  Depth Kit to actually project some of the more challenging
881.90s - 888.22s |  aspects of doing water systems using this technology.
888.22s - 891.38s |  So here we have a representation of the water
891.38s - 892.30s |  skid.
892.30s - 894.50s |  So it has essentially three different sections on here.
894.50s - 896.70s |  We have the digester on the right-hand side.
896.70s - 898.58s |  We have the membrane in the middle.
898.58s - 900.90s |  And then on the left-hand side, we have a bar screen.
900.94s - 902.78s |  So three different systems that we can go into and
902.78s - 904.58s |  explore in more details.
904.58s - 907.50s |  There's some virtual assets associated with this as well.
907.50s - 908.54s |  But we can actually run through.
908.54s - 911.50s |  This is actually a recording that we did on the real skid.
911.50s - 914.14s |  And we're actually showing this in three dimensions in VR
914.14s - 916.10s |  right now, so we can run through scenarios
916.10s - 917.90s |  over and over again.
917.90s - 921.06s |  In the future, we will be able to live stream this directly
921.06s - 924.14s |  from the skid in Richland.
924.14s - 929.34s |  But right now, we can show you this demo as to the sort of
929.34s - 931.46s |  qualities and the resolutions that we can actually get out
931.46s - 936.51s |  of it right now.
936.51s - 938.79s |  So thanks, Brandon.
938.79s - 940.07s |  Appreciate it.
940.07s - 965.94s |  Good work.
965.94s - 966.94s |  Sweet.
966.94s - 967.46s |  All right.
967.46s - 971.68s |  So a few of the next steps.
971.68s - 973.48s |  Obviously, we've got more platforms to go.
973.48s - 974.96s |  We've shown you the wastewater and the
974.96s - 975.72s |  rail skid right here.
975.72s - 978.84s |  We have the seaport skid in progress right now.
978.84s - 983.92s |  We have a couple of others that we have at PNNL that we
983.92s - 985.68s |  want to take forward, things like the
985.68s - 988.16s |  hydropower skid as well.
988.16s - 992.52s |  So lots of things to play with, lots of things to do.
992.52s - 996.36s |  Point to the latest technology, things like Quest 3.
996.36s - 999.80s |  And any future technology headsets that come out soon,
999.80s - 1002.00s |  we'll be right there trying to make use of
1002.00s - 1005.36s |  them as best we can.
1005.36s - 1007.96s |  And then also maybe thinking about ways to integrate more
1007.96s - 1010.28s |  systems into the apps themselves, whether that be
1010.28s - 1013.08s |  through digital twins or virtual desktops.
1013.08s - 1017.52s |  We can take and view a lot of this stuff within the VR app
1017.52s - 1018.56s |  that we're creating.
1018.56s - 1020.56s |  And we just want to be able to extend that and go further
1020.56s - 1026.42s |  and further and further.
1026.42s - 1028.70s |  So a little bit more about some of the other things that
1028.70s - 1033.22s |  we do in Immersive, just to finish off with.
1033.22s - 1036.06s |  So the way that Immersive Community is set up at PNNL is
1036.06s - 1039.02s |  that we are based within the AI and
1039.02s - 1040.74s |  data analytics division.
1040.74s - 1043.30s |  So we have a lot of very close partners that work within the
1043.30s - 1047.78s |  AI industries and actually developing new software and
1047.78s - 1050.14s |  new capabilities all the time.
1051.06s - 1053.94s |  We're right there with them to make sure we can best use any
1053.94s - 1056.38s |  of their models, any of their technologies in
1056.38s - 1057.82s |  the XR environment.
1057.82s - 1058.90s |  And we've been doing this for a while.
1058.90s - 1061.78s |  So this is actually a video from a project that I did a
1061.78s - 1062.90s |  couple of years ago that was actually
1062.90s - 1063.82s |  doing color detection.
1063.82s - 1066.54s |  We've been thinking about being able to try and port
1066.54s - 1070.66s |  these AI models onto mobile devices for a long time now.
1070.66s - 1072.14s |  So this is actually doing things like chemical
1072.14s - 1074.70s |  detection.
1074.70s - 1078.50s |  And so we can actually see very small color changes that
1078.50s - 1080.54s |  you may not be able to see in the field.
1080.54s - 1082.82s |  But we'll actually be able to do that using essentially the
1082.82s - 1084.34s |  webcam on the HoloLens.
1084.34s - 1086.90s |  So that gives you a sense of the technologies that we were
1086.90s - 1090.70s |  trying to make best use of at the time.
1090.70s - 1093.98s |  AI, we see, has been incredibly useful for our
1093.98s - 1096.06s |  workflow going forward.
1096.06s - 1097.98s |  That can be in a variety of different ways, whether it be
1097.98s - 1100.98s |  in the development space, so actually creating assets,
1100.98s - 1105.14s |  creating systems faster, creating more prototypes out
1105.14s - 1107.18s |  there that sponsors can give us feedback on to make sure
1107.18s - 1110.10s |  that we're actually doing what we're doing correctly.
1110.10s - 1112.58s |  But also within the applications that we're
1112.58s - 1114.66s |  developing ourselves, we kind of want to make sure we can
1114.66s - 1120.86s |  tune the apps correctly to see what the trainer's actually
1120.86s - 1121.82s |  doing at that time.
1121.82s - 1124.58s |  So trying to make sure we're iterating on the fly as well,
1124.58s - 1125.82s |  which would be really kind of cool.
1128.30s - 1129.54s |  These headsets are actually creating a
1129.54s - 1131.46s |  lot of data as well.
1131.46s - 1133.38s |  So as we're walking around, it's not just positional data
1133.38s - 1136.46s |  but eye tracking data, hand tracking data, how we're
1136.70s - 1139.70s |  performing within these apps can be analyzed and be
1139.70s - 1143.26s |  understood as to whether or not we're actually getting good
1143.26s - 1147.62s |  results from these apps, getting the training scenarios
1147.62s - 1149.06s |  working really well.
1149.06s - 1152.06s |  And we can only improve by trying to explore these
1152.06s - 1155.34s |  technologies and these developments going forward.
1155.34s - 1159.46s |  So that's pretty exciting.
1159.46s - 1162.46s |  The sort of environments that we've used include really
1162.46s - 1163.50s |  dangerous places too.
1163.50s - 1166.18s |  So we can expose people to things like active
1166.18s - 1167.46s |  shooter scenarios.
1167.46s - 1171.06s |  So we can actually start getting people understood as
1171.06s - 1174.66s |  how they would react in these sort of situations.
1174.66s - 1182.50s |  And that can be quite an intense scenario that you
1182.50s - 1185.22s |  don't really know until you put the headset on someone as
1185.22s - 1186.10s |  to how that works out.
1186.10s - 1192.18s |  So with this situation, we took people in there and had
1192.18s - 1194.82s |  to deal with an active shooter situation.
1194.82s - 1197.22s |  So they had to either sort of hide behind a desk or
1197.22s - 1199.10s |  barricade a door.
1199.10s - 1201.58s |  Or in some cases, you could actually run up behind them
1201.58s - 1204.66s |  and try and fight, essentially.
1204.66s - 1207.14s |  So we could actually go in there and actually try and do
1207.14s - 1211.30s |  the sort of situations and trainings that we want people
1211.30s - 1212.54s |  to understand.
1214.38s - 1217.74s |  We've also taken people into creative environments that
1217.74s - 1221.30s |  train people on best practices, getting people that
1221.30s - 1223.54s |  muscle memory before they actually go into the field,
1223.54s - 1227.02s |  whether that be through proper PPE in a chemical
1227.02s - 1228.82s |  situation such as this.
1228.82s - 1232.06s |  So we actually create the environments as flexible as
1232.06s - 1234.42s |  possible and as creatively as possible.
1234.42s - 1236.14s |  So in this case, we actually create our
1236.14s - 1237.82s |  own maps within VR.
1237.82s - 1240.06s |  We could actually also do this on desktop too and transmit
1240.06s - 1244.34s |  the actual maps to the headset after the fact.
1244.34s - 1248.34s |  So with this situation, we actually create a lot of
1248.34s - 1250.94s |  things at the same time, as well as exposing people to
1250.94s - 1252.30s |  realistic environments.
1252.30s - 1254.14s |  Realistic health effects that happen.
1254.14s - 1258.38s |  So we can use certain situations with VR that reduce
1258.38s - 1260.94s |  field of view or blurriness or things like that and actually
1260.94s - 1265.92s |  create something that's disorientating for the user.
1265.92s - 1269.00s |  And as I said, we do a lot of things with nuclear waste up
1269.00s - 1270.60s |  around the Hanford site.
1270.60s - 1272.96s |  So we can actually take people into the tanks themselves and
1272.96s - 1279.80s |  show them what they would hope to see if they could actually
1279.80s - 1283.24s |  go into the tanks and be able to operate technology and
1283.24s - 1285.16s |  systems down there.
1285.16s - 1288.32s |  We actually found with this demonstration that we used for
1288.32s - 1291.76s |  another conference that we actually hooked this up to an
1291.76s - 1294.80s |  Xbox controller, and they actually control this arm
1294.80s - 1298.08s |  within both VR and on a TV screen.
1298.08s - 1301.60s |  We actually found that people used the VR with the Xbox
1301.60s - 1303.64s |  controller a lot better than the TV screen.
1303.64s - 1306.56s |  So actually being able to be in the environment, be able to
1306.56s - 1308.60s |  see the arm from lots of different angles.
1308.60s - 1310.76s |  This is an incredibly 3D structure that we're trying to
1310.76s - 1312.12s |  take people into.
1312.12s - 1314.52s |  We could actually operate systems a lot better if we had
1314.52s - 1317.52s |  this point of view, had this understanding of what they're
1317.52s - 1320.44s |  trying to do in a three-dimensional way.
1320.44s - 1328.44s |  So just to finish up, a little bit about, so we are
1328.44s - 1330.20s |  expanding across the P&L mission space.
1330.20s - 1333.48s |  It's not just in security or cyber security, but we are
1333.48s - 1335.28s |  across the lab.
1335.28s - 1338.08s |  Although, please come by the booth as well.
1338.08s - 1339.24s |  We're over in the XR Village.
1339.24s - 1340.76s |  Come try out the demo.
1340.76s - 1343.52s |  We have a couple of different applications, both on HoloLens
1343.52s - 1347.80s |  and on Vario, so do try out both if you can.
1347.80s - 1349.48s |  We're going to be working with AI going on in the future.
1349.48s - 1352.76s |  I think everybody can see that happening, and we just need to
1352.76s - 1356.20s |  make sure that we use it the best way we possibly can and
1356.20s - 1358.36s |  the most useful ways.
1358.36s - 1360.76s |  And we're definitely going to be using game engine
1360.76s - 1363.68s |  technology in various different ways.
1363.68s - 1367.64s |  We're trying to push those systems as much as they can in
1367.64s - 1370.08s |  lots of different ways that we maybe haven't thought of yet.
1370.08s - 1372.20s |  So with that, I just want to finish up there.
1372.20s - 1375.44s |  And do we have any time for questions, or are we?
1375.44s - 1377.48s |  One minute for questions, so if anybody's got any questions,
1377.48s - 1393.44s |  then I'll try and answer them.
1393.44s - 1395.96s |  OK, so the question is about whether or not we've seen any
1395.96s - 1399.84s |  data about improving situational awareness using
1399.84s - 1402.40s |  these technologies.
1402.40s - 1408.92s |  So I'd say anecdotally, yes, but not anything physically,
1408.92s - 1412.40s |  mostly because a lot of what we do is actually trying to
1412.40s - 1413.56s |  create prototypes to show that this
1413.56s - 1415.00s |  sort of thing is possible.
1415.00s - 1417.20s |  We're trying to get it out there as quickly as possible
1417.20s - 1418.12s |  in a variety of different ways.
1418.12s - 1424.44s |  So I'd say, yeah, we've seen improvements, but obviously,
1424.44s - 1431.26s |  you just need to do more of this stuff in the future.
1431.26s - 1433.14s |  OK, thank you very much for your time.
1433.14s - 1434.38s |  Have a good rest of your week.