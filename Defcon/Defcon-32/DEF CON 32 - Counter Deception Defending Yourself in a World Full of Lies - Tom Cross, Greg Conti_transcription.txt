{
  "webpage_url": "https://www.youtube.com/watch?v=gHqDEMrqTjE",
  "title": "DEF CON 32 - Counter Deception: Defending Yourself in a World  Full of Lies - Tom Cross, Greg Conti",
  "description": "The Internet was supposed to give us access to the world's information, so that people, everywhere, would be able to know the truth. But that\u2019s not how things worked out. Instead, we have a digital deception engine of global proportions. Nothing that comes through the screen can be trusted, and even the things that are technically true have been selected, massaged, and amplified in support of someone\u2019s messaging strategy.\n\nDeception isn\u2019t just about narratives - we see deception at every layer of the network stack, from spoofed electromagnetic signatures, to false flags in malware, to phony personas used to access networks and spread influence. They hide in our blindspots, exploit our biases, and fill our egos while manipulating our perceptions.\n\nHow do we decide what is real? This talk examines time-tested maxims that teach the craft of effective deception, and then inverts those offensive principles to provide defensive strategies. We\u2019ll explore ways to counter biases, triangulate information sources, detect narratives, and how hackers can build tools that can change the game.\n\nAt their best, hackers lift their heads up above the masses to see how the world actually works, not how it purports to work, and then take action to make the world a better place. You\u2019ll leave this talk with practical skills to do just that.",
  "channel_url": "https://www.youtube.com/channel/UC6Om9kAkl32dWlDSNlDS9Iw",
  "duration": 2574,
  "channel": "DEFCONConference",
  "uploader": "DEFCONConference",
  "upload_date": "20241022"
}

0.14s - 5.62s | This text was transcribed using whisper model: large-v2

 Good morning DEF CON. Thanks for coming out. I appreciate it. Uh we have two speakers this
5.62s - 11.08s |  morning. Uh Tom Cross and Greg Conte and their talk is gonna be on deception and counter
11.08s - 13.46s |  deception. Please give them a good DEF CON welcome.
13.46s - 26.71s |  So uh good morning everyone. Thanks for uh making it out this morning. Um so we're uh
26.71s - 32.95s |  we're excited about this talk. Um I uh I I've been coming to DEF CON you know since it got
32.95s - 40.03s |  started and when uh you know early DEF CON uh you know at that time uh the internet was
40.03s - 45.99s |  just beginning to become publicly available um to consumers right? And we were thinking
45.99s - 49.63s |  about you know what what how is the internet gonna affect society? Like how what is gonna
49.63s - 55.35s |  happen right? Um and we were sort of imagining a world that we now live in today. And I think
55.35s - 60.35s |  it's interesting to look back at how what we thought would happen and question you know
60.35s - 65.55s |  sort of you know where we've ended up right? I think people in this community could see
65.55s - 71.75s |  both the like promise and peril of the internet. Um I remember going to lunch at DEF CON going
71.75s - 76.99s |  to a food court and everyone's paying with cash and we're thinking you know in the future
76.99s - 80.63s |  we're probably gonna pay electronically for everything and a little record will be kept
80.63s - 84.53s |  every time we buy something. And like it will create this model of our behavior and how
84.53s - 90.19s |  will that get used against us right? Um but at the same time I think people were genuinely
90.19s - 94.63s |  excited about the idea that everyone will have the world's knowledge at their fingertips
94.63s - 100.43s |  right? And maybe that will make people a little smarter. It might up level humanity. Um and
100.43s - 106.03s |  so as you know time has gone by and we've actually got all these capabilities and everyone's
106.03s - 113.11s |  using them um you know there's certain facets of human nature that have come roaring forth
113.11s - 119.91s |  uh and have a huge impact on how this stuff actually affects us. Uh I I think the part
119.91s - 124.19s |  of the problem is that people don't come to the internet because they want to get smarter.
124.19s - 128.71s |  They come to the internet because they want to be told that they're already smart. Um
128.71s - 132.95s |  they seek validation right? Um and there's a lot of people who recognize this and they're
132.95s - 139.51s |  in what I call the fun house mirror business. So they present you a world in which you're
139.51s - 144.59s |  a good person. In which you should get what you want. And in which the people that you
144.59s - 149.31s |  dislike we're gonna show you those people in the most negative light possible over and
149.31s - 156.15s |  over again. Um and this world of view that is centered around you and why you're special
156.15s - 164.03s |  um is highly compelling to people's egos. Um this is what we on some level mean by deception.
164.03s - 168.79s |  And we find deception not just in the like narratives that appear on social media but
168.79s - 174.11s |  also um at every level. Like in the phishing emails that people are getting. In the malware
174.11s - 180.95s |  that's running on their computers. Um ultimately the internet has become this massive deception
180.95s - 187.59s |  engine uh in which these uh false narratives are appearing at every level of abstraction
187.59s - 192.75s |  um and you can't trust anything that you see in the screen. Um it's I think people have
192.75s - 197.75s |  recognized this. They've recognized that the internet is not giving us what we wanted.
197.75s - 203.47s |  It's not making us smarter. Uh and in fact um the theme of this year's DEF CON is is
203.47s - 207.79s |  how do we engage with the the internet that isn't giving us what we want? How do we make
207.79s - 214.27s |  things better? Um so before I get into the overview of the talk um let me introduce us.
214.27s - 219.59s |  Uh so my name's Tom. Uh I've been coming to DEF CON for a long time. Uh I've done a few
219.59s - 224.99s |  social media projects over the years. My current uh project is called Feedseer. It's a news
224.99s - 229.35s |  reader app for Mastodon. So uh it shows you the top links that have been posted on your
229.35s - 233.79s |  feed in the past 24 hours and what people are saying about each link. Uh and um there's
233.79s - 238.47s |  lots of InfoSec folks on Mastodon. Um I've also uh you know generally had a career in
238.47s - 244.15s |  InfoSec and I've spoken at a lot of cons on information security uh topics. Often with
244.15s - 245.23s |  this gentleman, Greg.
245.23s - 253.83s |  Hi, I'm Greg Conte. Thank you for joining me here on Arrakis for DEF CON 32. Um my background
255.27s - 260.59s |  is uh I was long term faculty at West Point where I ran their cybersecurity research and
260.59s - 267.59s |  education programs. Also worked at NSA twice and US Cyber Command twice. Um and then I've
267.75s - 272.99s |  developed and taught the information operations course at Black Hat Training 7 years ago and
272.99s - 277.59s |  been running it uh since there and in private sessions and also run the military strategy
277.59s - 282.27s |  and tactics for cybersecurity course for 10 years. Same deal. Thanks Tom.
282.27s - 286.75s |  Oh and Greg and I are teaching a class on adversarial thinking at DEF CON training after
286.75s - 293.23s |  DEF CON is over. If you guys want more Vegas. Um so uh what are we gonna cover in this talk?
293.23s - 297.03s |  Um the first thing we're gonna do is we're gonna tap into some of Greg's deep expertise
297.03s - 301.51s |  with military doctrine and thinking. Militaries have been thinking about conflict for hundreds
301.51s - 307.71s |  of years um and deception in particular is an area where they have um identified maxims
307.71s - 313.67s |  that teach you how to craft effective deceptions. So we're gonna talk about how to uh to do
313.67s - 318.39s |  deception effectively. Um and then we're gonna flip the coin over and ask well if we
318.39s - 324.35s |  understand offense really well what does that teach us about defense? Um are there counter
324.35s - 331.15s |  deception principles that we can derive uh that uh tell us how to uh fight deception?
331.15s - 336.77s |  And um the the deception and counter deception principles we're gonna cover are they're useful
336.77s - 340.91s |  in any context where this could be occurring. It could be useful for malware attribution
340.95s - 346.75s |  or in a security operations context. Um but you know this year's DEF CON is about engaging
346.75s - 351.19s |  with the internet um and so we're gonna spend the third part of the talk um trying to apply
351.19s - 356.19s |  some of these counter deception maxims and ask what sort of capabilities um you know is the
356.19s - 362.73s |  internet lacking that might be useful or might help us defend ourselves against uh deception
362.73s - 369.21s |  that we're facing? So um why are we talking to you guys about this? Like why is this relevant?
369.21s - 376.31s |  I think you you know hackers have the ability to identify fuckery better than like a lot of you
376.31s - 382.09s |  know general people. So you guys have a unique talent at that. Uh and uh um you know I I
382.09s - 386.53s |  also you know I mean I I listened to Cory Doctorow's talk last year which inspired this
386.53s - 392.09s |  year's theme and his talk yesterday. Um it's he's engaged in a very important discussion
392.09s - 398.17s |  about like policy issues um and uh I I think you know what I do is I write code and I break
398.17s - 404.47s |  code um and I wanna talk about you know how I can apply those skills uh um to engage with
404.47s - 410.01s |  this problem as well. So um you know hopefully uh um you you know we we we add to the discussion
410.01s - 418.71s |  a a new dimension. Um so uh Greg let's talk about deception. So deception's been around
419.09s - 424.99s |  for millennia and the key idea is that it's the act of hiding the truth to get yourself
424.99s - 431.69s |  an advantage. And what you're trying to do is influence your target to make an incorrect
431.69s - 438.47s |  decision, right? Or to take an action that you want or fail to take an action all to your
438.47s - 445.23s |  advantage. And we've seen examples from our five legged Trojan horse AI uh generative AI
445.23s - 451.01s |  delivers when you need a five legged Trojan horse. Um to the civil war where people painted
451.03s - 456.03s |  logs black to create the to try and fake cannons. To the um Cuban missile crisis hiding
459.61s - 464.61s |  medium range ballistic missiles and concealing them in uh ships. To the uh Persian Gulf War
467.01s - 473.25s |  where the invading Iraqis were concerned about an attack by the sea by the marines and
473.25s - 479.29s |  instead were surprised by an attack by land from the opposite direction. We see it in the
479.51s - 484.51s |  Russia-Ukraine conflict. The Ghost of Kiev uh which was a mythical fighter pilot ace fighter
487.65s - 493.15s |  pilot fighting the Russian aggressors over the city which was later you know proved to be a
493.15s - 500.59s |  deception operation. So we've seen this uh for millennia. And when we think about the
500.59s - 506.23s |  targets of deception humans are the first come first to mind. And you uh you know in
506.75s - 511.75s |  information security users uh you know things like phishing, typosquatting, domain mimicry,
513.29s - 518.29s |  spoofed login pages. But also experts, think malware analysts, false flags, fileless
520.17s - 525.17s |  malware, deceptive metadata, um let's uh code injection, rotating command and control
527.61s - 533.27s |  infrastructure. So specialists can be targets for deception as well. But more than that
533.29s - 538.05s |  it's not just the humans it's our code. So our code think malware detect uh detection
538.05s - 543.83s |  systems. People try and deceive that through fileless malware, polymorphic malware,
543.83s - 548.83s |  rotating command and control infrastructure. And as we move into the era of AI, AI is also a
550.77s - 555.77s |  deception target. Think poisoning the training data of the AI or jailbreaking techniques to
555.81s - 560.81s |  overcome safeguards that people put in place. And deception can occur at all levels. It can
564.85s - 570.43s |  occur at all levels of the network stack. It can also occur in thinking more broadly at the
570.43s - 575.43s |  tactical operational and strategic level. Uh the tactical level you're actively deceiving
576.97s - 581.97s |  someone you're engaged in conflict with. All the way up to strategic level where you try to
582.91s - 587.91s |  hide your basic you know national objectives, your intentions, your strategies and your
587.91s - 592.61s |  capabilities or put forth uh maybe to put forth an alternate reality that's more
592.61s - 597.63s |  beneficial. So humans process data through this idea of the DIKW hierarchy. We begin with
601.63s - 606.63s |  data and with by adding uh context we can create information, by adding meaning we can create
606.83s - 611.83s |  knowledge and we can by adding insight we can create wisdom. Well deception can poison our
614.37s - 619.37s |  ability to you know by poisoning the data that we can have incorrect information, knowledge,
620.61s - 625.61s |  wisdom that we think is entirely accurate. So deception poisons our ability to think. And it's a
629.59s - 634.59s |  professional discipline uh deception. Uh what we have here, the orange document is a uh
636.69s - 641.69s |  declassified CIA document uh that includes the deception maxims that we're going to uh be
644.39s - 648.63s |  discussing. And also there are manuals like this is the Department of Defense joint
648.63s - 653.81s |  publication on military deception. It comes out every few years updated. So this the key
653.81s - 658.81s |  takeaway here is it's a professional discipline. And looking at some of the maxims, we're
661.25s - 664.61s |  just going to run through these pretty quick and then we're going to flip them and show how
664.63s - 669.71s |  you might counter. But one of the most important is it's easier to maintain a preexisting
669.71s - 675.31s |  belief um in in your target than to force a change. Right? So if someone believes the world is
675.31s - 681.35s |  flat you can help encourage them to continue thinking the world is flat. But if you want to have
681.35s - 689.90s |  them think the world is round well that's much harder. So yeah I really think Magruder's
689.90s - 695.60s |  principle is sort of the golden rule of deception. It speaks to this like fundamental aspect
695.62s - 699.96s |  of human nature. Um you know say there's a politician you hate. There might be different
699.96s - 704.40s |  answers in the room for who that person is but everyone hates some politician right? And if I
704.40s - 708.50s |  walk up to you and I say well you know that politician you hate? Did you hear about the
708.50s - 713.94s |  stupid thing they did this morning? Whatever I say next, whatever it is, you're going to
713.94s - 719.42s |  believe it. Because it's aligned with what you already think and it feels good to be right.
719.48s - 726.24s |  Um and so uh if if any of you have read um Asimov's Foundation series, he has a really
726.24s - 731.18s |  good um model um I think of deception that he presents in those books. There are these
731.18s - 737.92s |  robots that can manipulate people's emotions. Um and uh they they're constantly explaining
737.92s - 742.20s |  that they can't radically change people's worldview. And the way that they function is
742.20s - 746.84s |  by trying to understand what that person thinks and identify some specific belief that they
746.86s - 753.06s |  have that they can emphasize or reinforce just enough to get that person to take an action
753.06s - 757.80s |  that they might have otherwise not taken. And I I think that's a really good representation
757.80s - 768.58s |  of like effective deception in a nutshell. So one of my favorites is the idea of exploiting
768.58s - 774.22s |  the limits of human and machine sensing uh and information processing. So you think we
774.22s - 780.12s |  have as humans have senses right? And that are limited and like known parameters of what
780.12s - 785.72s |  we can uh sense. And we have limitations in our ability to process information. Machines
785.72s - 790.36s |  do the same. They have sensors and they have information processing. So if you can exploit
790.36s - 794.96s |  those limits for example uh think self-driving cars. There's been some really interesting
794.96s - 799.26s |  talks that you can exploit the sensing and processing of a self-driving car and make
799.26s - 804.92s |  it think see things that aren't there. Uh in a heist movie uh where there's usually
804.92s - 811.82s |  a motion sensor and someone moves really really slowly to slip past the motion sensor.
811.82s - 818.26s |  That kind of thing. And a variation of that is here's a picture of an inflatable tank
818.26s - 824.68s |  from Ghost Army uh in World War II. It was a group of creatives uh and they were a formal
824.68s - 830.54s |  deception unit. And it's their ability to create inflatable tanks and fake enemy or
830.54s - 836.84s |  fake troop uh emplacements uh was because the capabilities of the time to sense what
836.84s - 841.28s |  was you know sense the environment. These tanks looked real from a distance. Now they'd
841.28s - 848.28s |  be uh they'd obviously be not. Um then uh the third maxim is uh Jones's dilemma when
848.64s - 854.16s |  uh the idea is that in this competitive information environment of competing narratives that if
854.16s - 858.84s |  you're going to try and deceive someone and you're you have to ideally have more false
858.84s - 865.84s |  sources than real. So it's this battle of uh quantity and quality of of competing narratives.
867.50s - 873.38s |  Another strategy is the idea that you want to carefully uh create a story. That you don't
873.38s - 877.98s |  just have single data points but you're putting puzzle pieces out there for the deception
877.98s - 883.14s |  target to connect together that tell the story that you want that you're trying to uh to
883.20s - 890.20s |  portray. Uh another is the idea of carefully designed um planned placement of deceptive
890.84s - 897.68s |  material. The idea is you want to make your target work for it. If you if uh think if
897.68s - 903.66s |  you wanted to have a fake diary in in your room right? If you leave it on their desk
903.66s - 910.12s |  that that is an obvious place and that could be like your um that probably what you want
910.12s - 915.24s |  to do is make it hard. Have a lock on it. Have it hidden in a ventilation duct. Have
915.24s - 920.82s |  it written in code. By the time they find that and they've unpacked all that then they
920.82s - 926.04s |  think this has absolutely got to be the real diary. And we see that in malware as well
926.04s - 930.38s |  right? That's certainly a strategy. If you make them work for it people will be more
930.38s - 935.22s |  likely to believe it. The flip side of this is an orgy of evidence where things are you
935.22s - 942.96s |  know many incriminating things are obviously found. Well that should raise suspicions.
942.96s - 947.70s |  So yeah Olympic Destroyer is a really good example of the use of of some of these techniques
947.70s - 953.24s |  in order to fool malware analysts as to attribution. Doing attribution on IOCs is fraught with
953.24s - 959.40s |  risk as with respect to uh you know the manufacturing of those IOCs. Um in this case uh there was
959.40s - 963.88s |  a rich header in a binary uh that uh you know captures information about the developer's
963.88s - 968.24s |  environment and they they literally copied a rich header from a Lazarus sample and put
968.24s - 973.44s |  it in their their sample. Um and so someone who knows rich headers and like uh has a collection
973.44s - 978.68s |  of them and knows that they can be used to uh you know attribute malware might find this
978.68s - 982.72s |  and you know be excited that they connected the dots right? And so now they're emotionally
982.72s - 986.88s |  invested in the idea that this is true. Um and uh you know they they go out with this
986.88s - 990.16s |  narrative and it turns out that in fact in this case the rich header didn't match the
990.16s - 997.04s |  rest of the binary and uh the attribution was completely deceptive. Um so again uh uh
997.04s - 1001.68s |  you know avoid uh if you're trying to protect yourself against deception situations where
1001.68s - 1008.63s |  you're emotionally invested in the consequences of your work.
1008.63s - 1015.19s |  So I particularly like this one uh Maxim 6A, 6B. There are two sides of the same coin.
1015.19s - 1021.55s |  The first is ambiguity. So the idea is you want to increase doubt in the person's mind,
1021.55s - 1026.67s |  in your target's mind by providing many possible truths. Okay? Makes sense? They're they they're
1026.67s - 1031.67s |  uncertain. There's this cloud of uncertainty. The flip side of that is you want to decrease
1031.67s - 1038.39s |  doubt and focus the target on a particular um falsehood. So you want them instead of
1038.39s - 1045.31s |  being in a sea of doubt, you want them absolutely positively sure that they're right uh or that
1045.31s - 1050.31s |  they're sure about this falsehood. They think that they you know that it's true. Another
1050.31s - 1057.59s |  idea is that in in professionalized deception that there's the idea of husbanding deception
1057.59s - 1062.75s |  assets. That there are always limited resources. You need to save them for the time and at
1062.75s - 1068.43s |  the best time and the best place to be effective. You can see that in cyber in uh information
1068.43s - 1073.91s |  security capabilities O day. Right? Uh but imagine if you had the ability to place deceptive
1073.91s - 1080.67s |  material on a web server. You can't if you use it you're using that capability uh and
1080.67s - 1084.51s |  you might not be able to use it again. So you save these for the time and place you
1084.51s - 1090.39s |  think will be most effective. Uh maxim eight is the idea of feedback. In a professional
1090.39s - 1097.43s |  uh deception operation organization the attackers are monitoring their target audience looking
1097.43s - 1103.55s |  for feedback that the deception has been believed. And they are also so they want that feedback
1103.67s - 1108.51s |  loop. Uh and they're also monitoring their friendly organization to see if they are being
1108.51s - 1116.92s |  deceived. All right so now that we've talked a little bit about the principles of effective
1116.92s - 1121.96s |  deception let's flip the coin over and talk about how you practice counter deception.
1121.96s - 1129.24s |  Um so uh um at a high level I think there are four um general ways to counter deception.
1129.24s - 1133.72s |  One is through intelligence collection. So if you're actually monitoring your adversary
1133.72s - 1137.32s |  and just watching them create their deception then you know exactly what they're doing and
1137.32s - 1142.36s |  why they're doing it and what the truth is. Right? Um and the U.S. Cyber Command has this
1142.36s - 1148.20s |  defend forward uh um uh uh concept which has to do with like just going out and directly
1148.20s - 1151.72s |  spying on the people that are committing the acts so that you know exactly what they're up to.
1151.72s - 1156.84s |  Um another thing you could do not we don't always have intelligence capabilities um is
1156.84s - 1162.68s |  disruption. Um if uh so we talked about husbanding assets if uh you know someone has to go to a
1162.68s - 1168.92s |  certain effort to inject um deceptive narratives um you know in places and and you can take action
1168.92s - 1173.88s |  to to interfere with their capabilities um then that prevents them from being successful.
1173.88s - 1177.56s |  Um a simple example is like if they have to build a botnet in order to spread something
1177.56s - 1181.40s |  online and you're able to take the botnet down then you're interfering with their deceptive
1181.40s - 1188.04s |  capability. Um another thing you can do is is analytic. Sometimes that's your only option.
1188.04s - 1191.88s |  Um you're looking at the information you're collecting and you're critically analyzing it
1191.88s - 1196.04s |  in order to figure out whether or not it's deceptive. Um and a lot of our talk will focus
1196.04s - 1200.36s |  on that because that's often the only option that you've got. Um another thing you can do
1200.36s - 1206.92s |  is deterrent. So if you can if you can demonstrate uh that the deception will not be effective um
1206.92s - 1213.24s |  perhaps your adversary will not bother to do it. Um so uh in let's talk a little bit about
1213.24s - 1220.84s |  analytic processes. Um in InfoSec we're really good at devil's advocacy. Right? Um and so this is
1220.84s - 1225.56s |  the same thing. It's about playing devil's advocate with respect to things that you are
1225.56s - 1230.36s |  that you are deciding or that you believe. Um and uh you have to have the discipline to do that and
1230.36s - 1235.16s |  that's one of the hardest things about it. Um but uh you know if you have a belief or
1235.16s - 1241.16s |  intelligence related conclusion and there's a set of um facts that underpin that belief
1241.16s - 1246.04s |  you can look at each of those facts and ask yourself how hard would it be for my adversary
1246.04s - 1251.64s |  to simulate that fact? Am I am how many ways have I measured that? Um you know like is it
1251.64s - 1257.48s |  possible to fake that? Uh and um you know even in malware attribution you know a rich header is easy
1257.48s - 1262.52s |  to fake. Uh you know maybe uh you know could they get access to a particular source IP address or
1262.52s - 1269.00s |  how hard would that be uh for them to to simulate in order to fool me? Right? Um so let's talk about
1269.00s - 1273.88s |  some of the deception maxims and I'm gonna sort of flip them around and um and create counter
1273.88s - 1278.68s |  deception maxims based on them and I kind of organized them into categories. So the first
1278.68s - 1287.24s |  category uh is um maxims that suggest when deception may be present. So your human intuition
1287.24s - 1292.60s |  is both an asset and a liability when you're dealing with deception. This is the context where
1292.60s - 1299.16s |  it's an asset. You want to develop a kind of spidey sense that tells you things aren't quite right
1299.16s - 1306.28s |  here. It this looks fishy and that might prompt you to dig deeper um and explore the hypothesis
1306.28s - 1310.44s |  that what you're seeing might be a deception. Um so for example we've talked about carefully
1310.44s - 1317.48s |  sequencing um events to tell a story so it builds up in the target's mind. Um so flip that over,
1317.48s - 1321.24s |  what happens if there's all kinds of evidence that gets disclosed all at once? If you find
1321.24s - 1326.44s |  the diary sitting out on a table where it shouldn't be um you know that might be a sign to you
1326.44s - 1331.48s |  that like hey someone's trying to you know manipulate me that the this is this is possibly
1331.48s - 1337.96s |  deceptive right. Um so the the person operating the deception must either do ambiguity or
1337.96s - 1342.76s |  misdirection and in each case we can try to counter that right. So if they're engaged in
1342.76s - 1348.60s |  the ambiguity deception there's going to be a lot of narratives that are available right and if you
1348.60s - 1353.88s |  see multiple narratives then that might be a sign uh that deception is taking place. That some of
1353.88s - 1357.72s |  these narratives are simulated um that was certainly the case with Olympic Destroyer.
1357.72s - 1361.96s |  There were a bunch of organizations that had different attribution that they were publishing
1361.96s - 1367.16s |  um and and that's because the malware was intentionally sort of misleading analysts
1367.16s - 1373.16s |  into thinking that that that different narratives were correct. Um misdirection in a misdirection
1373.16s - 1377.48s |  deception the attacker is trying to get you to believe a particular thing which is false
1378.12s - 1383.08s |  and so um if you analyze it carefully perhaps you can discover that it's not true.
1384.20s - 1389.48s |  The the plus minus rule is this idea that nothing that is an imitation or a simulation can be
1389.48s - 1394.84s |  exactly the same as the real thing otherwise it is real and so identifying those characteristics
1394.84s - 1401.96s |  which are added or removed from the uh from the thing it helps you identify that it is deceptive
1401.96s - 1406.04s |  and again you have to have the discipline to say okay this isn't right it's incongruent and
1406.04s - 1414.63s |  therefore I must accept that it is not real. The place where your human intuition operates against
1414.63s - 1419.67s |  you has to do with mental discipline. Humans are really good at jumping to conclusions based on
1419.67s - 1423.67s |  not necessarily enough evidence. We kind of have to do that in order to function in the
1423.67s - 1430.07s |  complicated civilization that we have but um you know that's how uh deceptive deceptive operations
1430.07s - 1434.23s |  get you and so you kind of have to have the discipline to slow down and not listen to
1434.23s - 1439.83s |  sometimes to your intuition. Um so this is Magruder's principle is is the the biggest one
1439.83s - 1445.43s |  here. It's important to apply the same critical analysis to facts that support your assumptions
1445.43s - 1449.03s |  that you do to facts that challenge them and that's really hard for people to do.
1450.23s - 1454.55s |  You know also with respect to carefully designed placement of deceptive material don't assume the
1454.55s - 1459.27s |  fact is true just because you had to work hard to get it. Ask yourself could the adversary have
1459.27s - 1464.87s |  simulated that. I love this quote from a book on professional counter deception operations.
1465.83s - 1472.95s |  The vulnerable mind fits ambiguous information to its own preconceptions and expectations.
1472.95s - 1476.47s |  I think that's a really clear statement of vulnerability to deception.
1480.66s - 1486.98s |  So humans are not that complicated which part of the problem right. Psychologists have been studying
1486.98s - 1493.70s |  uh biases in humans for for hundreds of years and I have a list of examples here and if you're
1493.70s - 1499.70s |  wondering the prompt was humans swimming in a sea of piranha that was the prompt that gave us that.
1500.82s - 1507.30s |  But I wanted to highlight two. One is the idea of selection bias and just one instance of selection
1507.30s - 1515.38s |  bias is where you can choose from a variety of facts truths to paint a picture but you don't
1515.38s - 1519.70s |  share all the truths you're just selecting certain truths and I think we see that in many news
1519.70s - 1525.94s |  agencies today. A lot of what they say is true but which ones they choose paint a picture. So
1525.94s - 1532.26s |  that's selection bias. Confirmation bias sounds a lot like McGruder's principle. The idea that
1533.14s - 1539.46s |  we are biased toward things that already can reinforce our preconceived beliefs.
1543.20s - 1551.20s |  So the third set is maxims that suggest methods of preventing deception. So the two maxims that
1551.20s - 1556.00s |  have to do with the limits of human and machine sensing and information processing like speak to
1556.00s - 1562.32s |  the need to be able to measure reality from multiple perspectives. You know and think about
1562.32s - 1566.88s |  this on in a technical sense if you if you're in a security operations function and you have sensors
1566.88s - 1571.92s |  out there that like look at your network you know if there's only one kind of a particular sensor
1571.92s - 1577.12s |  then that sensor could be its data source could be manipulated it could be be presented with false
1577.12s - 1582.08s |  facts. If you've got multiple ways of looking at the situation then it gets harder and harder for
1582.08s - 1585.84s |  the person that's operating the deception to fool all of the sensors that you have.
1587.44s - 1592.56s |  With respect to husbanding deception assets again deception operations professional ones
1592.56s - 1598.48s |  involve effort and resources and if you can disrupt and target those capabilities then you
1598.48s - 1604.16s |  can undermine the ability for them to be successful. Feedback is also interesting. A professional
1604.16s - 1608.64s |  deception operation is going to be watching you to determine how you behave. You may choose to
1608.64s - 1612.48s |  behave as if the deception was effective because you don't want the deceiver to know that you were
1612.48s - 1619.60s |  not deceived. You may also choose to to show the adversary that you are debunked that you are
1620.16s - 1624.72s |  aware of their deception which is a deterrent method. One of the things that you know folks
1624.72s - 1629.76s |  in DHS and CISA are talking about is pre-bunking. So we think that this deceptive narrative is going
1629.76s - 1634.64s |  to be placed out there so in advance we're going to go ahead and explain to everyone that it's false
1634.64s - 1638.64s |  so that you know people just don't bother trying to push that narrative in the first place.
1640.48s - 1646.32s |  So in developing this set of trustworthy sources of data like when we're looking at things on the
1646.32s - 1652.56s |  internet it's really important for us to you know collect different places where we can get
1652.56s - 1659.52s |  different points of view that are credible and objective. And so like curating collections of
1659.52s - 1664.80s |  experts I think is really important and but also a weakness that we have is we have a tendency to
1664.80s - 1670.24s |  believe experts who you know are telling us what we already think and so we have to find objective
1670.24s - 1678.64s |  criteria for evaluating who we want to listen to. And so I think this is a real challenge like even
1679.20s - 1686.72s |  with respect to experts, experts sometimes deceive us right. So let's say there's a set of facts one
1686.72s - 1693.92s |  two three four and five and they add up to a conclusion which is 15 right. So what I can do
1693.92s - 1700.48s |  is I can present you some of those facts one two and three and a conclusion which is six. Each one
1700.48s - 1705.60s |  of the facts I've presented to you is absolutely true and the conclusion I'm presenting to you is
1705.60s - 1711.04s |  a natural consequence of the facts that I've presented right. So when you're listening to an
1711.04s - 1715.84s |  expert the challenge is that you depend upon them not just to tell you what the conclusions are but
1715.84s - 1721.20s |  also what the underlying facts are to educate you about the issue. And so you're vulnerable to the
1721.20s - 1725.92s |  fact that that without knowing more than they do about the subject that you can't see the other
1725.92s - 1732.00s |  facts that they're omitting that may lead you to a different conclusion. And so you know I
1732.56s - 1737.68s |  one of the things that people wring their hands about a little bit is journalistic objectivity.
1737.68s - 1741.60s |  There's this idea that like in the American civilization in particular where we have two
1741.60s - 1746.96s |  political parties that what should happen is that journalists should present both sides and we know
1746.96s - 1752.16s |  that like getting both of these perspectives does not get us closer to the truth right. And so
1752.16s - 1757.60s |  perhaps there's this role for journalism as a professional resource that goes out and finds
1757.60s - 1762.88s |  the other facts that are missing and adds them into the equation to get the complete truth right.
1763.68s - 1766.96s |  This is something that people have been talking about for a very long time. This is not an
1766.96s - 1772.80s |  internet problem. Walter Lippman was writing about this stuff in the 1920s and he had these
1772.80s - 1779.76s |  interesting ideas about what journalism could be but then he also you know he he was he was
1779.76s - 1785.12s |  concerned that it won't be that because the business model of newspapers doesn't support
1785.12s - 1790.48s |  this kind of work and and if if the news media isn't going to go out and find the additional
1790.48s - 1796.32s |  facts for me my question is can my computers do that? Can I can the internet give me the facts
1796.32s - 1801.52s |  that I need in order to objectively understand reality? And so that relates to the third part
1801.52s - 1807.92s |  of our talk and our call to arms. You know like hackers have an independent view of reality that's
1807.92s - 1812.96s |  somewhat outside of mainstream thinking and that enables you to see things with different eyes.
1813.92s - 1818.08s |  There are interesting capabilities and I'm going to talk about some examples of them
1818.64s - 1825.12s |  that might be useful to people to help combat deception and disinformation and I think also
1825.12s - 1831.44s |  we're we're tool makers and breakers and so you know I think we we're not entirely cynical about
1831.44s - 1840.00s |  the value that new tools can can bring. So I'm going to focus on four areas. One area it's just
1840.00s - 1844.00s |  something that I need to mention it's that model the adversary's capabilities and neutralize them.
1844.00s - 1849.04s |  I've mentioned that several times. There's been tremendous work over the years here at DefCon in
1849.04s - 1853.84s |  the misinformation village and there's also this thing called a disarm framework which is essentially
1853.84s - 1859.52s |  a kill chain for internet you know botnets and deception operations. This is fantastic work. We
1859.52s - 1863.76s |  love it and you know I want to endorse it here. There's lots of things that people can do in that
1863.76s - 1868.32s |  area. Because there's so much going on in that space we're not going to delve deeper into it.
1868.88s - 1874.08s |  We're going to focus on some other stuff. Particularly building tools for information
1874.08s - 1880.48s |  triangulation. You know knowing like when questions have been raised about what we're reading
1881.20s - 1885.60s |  and identifying and collecting those that network of experts that you can use to
1885.60s - 1892.08s |  determine whether or not something is real. So a really simple example I want to include because
1892.08s - 1896.48s |  it's a project that was the first one wiki scanner was a project that was done by somebody in this
1896.48s - 1901.28s |  community. It was a it was a small focused project and it had interesting consequences.
1901.28s - 1905.52s |  So it shows that like you can do some hacking over a few weekends and make something useful.
1906.40s - 1912.40s |  So wiki scanner looked for anonymous edits to Wikipedia and checked the you know like who is
1912.40s - 1916.64s |  information associated with the IP address and identified situations where people were editing
1916.64s - 1922.08s |  Wikipedia anonymously from the IP blocks assigned to large organizations. And so you could kind of
1922.08s - 1927.36s |  see what narratives were being pushed in Wikipedia by certain large orgs. There were certainly
1927.36s - 1932.96s |  interesting results that came out of that analysis. By the way it's mothballed. Somebody else made a
1932.96s - 1937.44s |  thing called wiki watchdog. The source code is available for that but it's also mothballed.
1937.44s - 1942.32s |  So like this is a thing anyone in this room could pick up and you know you know do something with
1942.32s - 1948.64s |  immediately and there are interesting results to be found. Sticking to the topic of Wikipedia
1948.64s - 1955.84s |  briefly the idea behind Wikipedia is that with enough eyes all bugs are shallow right. So you
1955.84s - 1960.56s |  know everyone's reading this article and they're removing fake things from it and so we get this
1960.56s - 1965.92s |  objective truth. The problem with it is that when you visit a page it might have been edited two
1965.92s - 1971.84s |  seconds ago by someone pushing an agenda and you can't really tell right. So I wrote a paper
1971.84s - 1978.32s |  in 2006 in which I suggested that we highlight passages that are new so that when you're reading
1978.32s - 1981.76s |  the article you can kind of tell which passages are less trustworthy because they haven't gone
1981.76s - 1986.24s |  through that editing process. There were some academics that built a thing called wiki trust
1986.88s - 1992.88s |  which like implemented a very similar set of ideas and with some added analytics underneath and
1992.88s - 1997.76s |  it was usable for a while. So this is kind of an interesting thing and this is also mothballed. I
1997.76s - 2003.92s |  believe in this set of ideas and there's work to be done in this area but I'm also I like the
2003.92s - 2008.32s |  high-level concept that maybe my computer should tell me when I should be careful about what I'm
2008.32s - 2015.12s |  reading because some objective objective criteria suggests that you know this information might not
2015.12s - 2023.36s |  be reliable right. So I want to return to some of the like core information resources that inspired
2023.36s - 2030.24s |  the creation of the web because there's a whole lot of ideas in here for things that we don't have
2030.24s - 2036.96s |  today and it's a way of seeing the negative space in the internet. So the first resource here is a
2036.96s - 2042.88s |  paper called As We May Think by Vannevar Bush. So Vannevar Bush was the guy that ran all defense
2042.88s - 2048.56s |  related research during World War II. So he was an incredibly important guy. He wrote a paper in
2048.56s - 2053.92s |  the 40s which might be the most important academic paper of the 20th century and it's
2053.92s - 2060.48s |  about using microfiche to create to link documents together and create knowledge management systems.
2060.48s - 2064.48s |  This guy's got a camera on his head because he imagined he wanted to take screenshots of books
2064.48s - 2069.60s |  he was reading and so he imagined having a camera in his head so he could screenshot documents right.
2069.60s - 2076.00s |  So it's it's weird tech but the ideas are super interesting and he you know had a lot of influence
2076.00s - 2081.12s |  over to other people who are incredibly important. One is Douglas Engelbart. Douglas Engelbart gave
2081.20s - 2085.04s |  the mother of all demos in which like he demonstrated things like mice and modems
2086.08s - 2092.64s |  at Stanford University in the 60s. He wrote a book about augmenting human intelligence and one of his
2092.64s - 2097.68s |  sort of precepts is that computers will always augment human intelligence better than they can
2097.68s - 2103.68s |  replace it and that is an idea that I think is it makes sense to remember these days given all
2103.68s - 2107.20s |  everything that's going on with AI and also I think social media companies sometimes forget
2107.20s - 2112.16s |  that the purpose of computers is to make us smarter. If you forget that you'll make the wrong
2112.16s - 2121.12s |  things. So Ted Nelson is the guy who coined the term hypertext. He did so it first appears in
2121.12s - 2125.76s |  print in this book which is called Computer Lib. It's an extra large book that's hand
2125.76s - 2131.92s |  written and illustrated in like a zine. It's a really interesting document and you can buy a
2131.92s - 2139.20s |  copy of it. They've got it printed again. A scholarly read through these three resources
2139.20s - 2144.56s |  will reveal a whole lot of ideas that these people had for things that the internet should do
2144.56s - 2150.48s |  that the internet does not yet do. Late in Engelbart's life he was sort of frustrated with
2150.48s - 2154.64s |  the web and like felt like it didn't achieve its potential and Ted Nelson is still ranting about
2154.64s - 2160.24s |  that on YouTube and you can find him doing so. So if we look at some of the stuff that these guys
2160.24s - 2165.84s |  did. So Xanadu is Nelson's project. Hyperscope is something that the Douglas Engelbart Institute
2165.84s - 2169.92s |  has been working on to try to implement some of his ideas. There's a bunch of things in there
2169.92s - 2174.24s |  that we don't have today and it's interesting to think or maybe we do but only in narrow
2174.24s - 2178.80s |  limited context right. So it's interesting to think about like what would it take to make this
2178.80s - 2184.72s |  a part of the internet. You know why don't we have it. In the context of deception and
2184.72s - 2189.68s |  counter deception I'm particularly interested in backlinks. All these guys wanted backlinks. So
2190.24s - 2195.52s |  web document can link out to another document from a phrase. In their systems also when you're
2195.52s - 2201.36s |  reading a document you can see which people link in and what phrases they link into. So you can
2201.36s - 2206.40s |  see if someone built upon the ideas that you're reading and you can also see if someone is
2206.40s - 2211.84s |  criticizing the thing that you're reading. Why don't we have that in the internet? Well the
2211.84s - 2218.08s |  answer is that it's a content moderation problem. If anybody could annotate a web page in any way
2218.08s - 2224.40s |  that they wanted then we'd have a bunch of spam and abuse right. And so we need to think about the
2224.40s - 2228.72s |  tools that we've built for managing content moderation and see if we can couple them to
2229.68s - 2233.60s |  backlinking in order to create something that's useful. There have been some interesting projects
2233.60s - 2238.64s |  over the years that played around with backlinking either in narrow context or you know to varying
2238.64s - 2244.00s |  degrees of success. You know I think a key thing here is that all opinions are not created equal.
2244.64s - 2249.44s |  There are certain opinions again I've curated my experts whose opinions that matter to me.
2249.44s - 2253.92s |  Those are the ones that I want to see. So when I choose to follow somebody on social media
2253.92s - 2259.20s |  I'm indicating that what they say is relevant to me even if I don't agree with it right. So I've
2259.20s - 2264.80s |  selected that group. It would be useful to me if I could see anytime I'm viewing a document if those
2264.80s - 2272.32s |  people have ever commented on it right. I'd love to build that. A challenge that we face is that
2272.32s - 2278.08s |  in order to build and innovate on top of our social media systems we need systems that are
2278.08s - 2286.64s |  technically financially and culturally open to innovation. And unfortunately many of the systems
2286.64s - 2292.72s |  that we collectively use like fail at one or more of those criteria and therefore it makes it
2292.72s - 2297.76s |  difficult for people to create new things that sit on top of them. And we need to create new things
2297.76s - 2304.56s |  in order to make the internet better. So I've talked about curating collections of experts.
2305.20s - 2311.68s |  There are some interesting protocols that exist that people have built over time for endorsing
2311.68s - 2316.72s |  people. Like I really like LinkedIn endorsements not as a tool but as a concept. You know you can
2316.72s - 2323.60s |  say I follow this person and this is why right. But unfortunately that's a closed system. Some
2323.60s - 2328.24s |  of these things out there aren't machine readable. You know I think it would be cool if I when I'm
2328.24s - 2332.80s |  following somebody on social media if I could say why. And that endorsement sticks to them if they
2332.80s - 2339.12s |  accept it. And as long as I continue to follow them. And if we did that then I could do this.
2339.12s - 2344.96s |  I could say who do the people I follow follow who are endorsed for this particular thing like law.
2345.52s - 2350.24s |  And I could get back a list of a bunch of people who are endorsed for this particular topic. And
2350.24s - 2355.28s |  I could ask what are these people saying about this thing right. It gives me the ability to sort
2355.28s - 2361.28s |  of like you know identify the reputation of people on the internet and utilize that in
2361.28s - 2368.08s |  constructive ways to help me figure out what's real. So I think there are lots of there's lots
2368.08s - 2374.08s |  of work to be done in that space. There's lots of like open potential there. Another area is LLMs.
2374.88s - 2380.48s |  You know LLMs have some built in biases. There's challenges dealing with them. They hallucinate.
2380.48s - 2385.84s |  So there's lots of caveats to what I'm saying here. And I know what they are. But at the same
2385.84s - 2391.68s |  time it is a dispassionate computer right. So can it go out and find those missing facts for me
2391.68s - 2398.24s |  that aren't included in a narrative by reading all the things right. And dispassionately present
2398.24s - 2403.84s |  them to me. That's a potentially interesting thought. And I think it's harder than it sounds.
2404.72s - 2410.64s |  But you know there are other things we could do with LLMs. I you know one of the things is that
2410.64s - 2414.88s |  that I mentioned on the last page is that there are like if you're a university professor at an
2414.88s - 2420.08s |  accredited university in a particular subject area your university website indicates that like this
2420.08s - 2424.96s |  guy is the professor of this right. But then your social media profile there's it's not machine
2424.96s - 2430.72s |  readable. Your university website is not machine readable. I can't tell you know automatically that
2430.72s - 2437.36s |  you have this expertise. But an LLM could go read every university website find all the professors
2437.36s - 2442.56s |  find all their social media profiles and created a machine readable you know system that allows me to
2442.56s - 2448.24s |  again ask this question who knows lots about economics. Here they are right. And so I think
2448.24s - 2453.28s |  that those are interesting possibilities. LLMs are really good at turning human unstructured
2453.28s - 2457.60s |  information into like very structured information that's machine readable and we can do things with
2457.60s - 2466.80s |  it. Greg? So beyond these technical solutions we have to think like how can we scale this
2467.76s - 2474.96s |  so for humans right. One is the idea of teaching media literacy in schools to try and have a better
2474.96s - 2481.60s |  informed consumers of information. Media literacy now who I have highlighted here they have a nice
2481.60s - 2488.64s |  depth of resources from K through 12 for for classroom instruction. And the other idea is to
2488.64s - 2494.16s |  emphasize critical thinking both in school and in our day-to-day lives. And this is from and I can't
2494.16s - 2500.08s |  quite see it just in right. The idea there are certain questions we ask that we ask and help us
2500.08s - 2507.20s |  probe through and see through deception. One is who benefits right. Where did this originate. There's a
2507.20s - 2514.80s |  48 questions here and they're very thought-provoking and useful. Yeah so we've put a bunch of references
2514.80s - 2520.72s |  in the slides you know which are like look at this from a bunch of different perspectives.
2520.72s - 2525.92s |  I'm sure that there are ideas that you have that relate to maybe the principles that we've
2525.92s - 2530.64s |  articulated that are different from the ones that I've come up with. And that's what I'm excited
2530.64s - 2536.72s |  about and why I wanted to talk to all of you about this. So hopefully you know somebody out there has
2536.72s - 2542.32s |  been maybe inspired to work on something. And you know there's there's lots more to read about all
2542.32s - 2547.84s |  of this stuff. You know these are our email addresses. You know we'd love to hear from you.
2547.84s - 2552.96s |  We're going to be hanging out outside after the talk is over. So if you want to talk to us or
2552.96s - 2557.76s |  poke at some of the things we're saying we'd love to talk to you more. And again I really appreciate
2557.76s - 2563.04s |  your time and attention this morning. And the fact that you made it here on the last day of
2563.04s - 2568.00s |  DEF CON for a morning session. Thank you.