{
  "webpage_url": "https://www.youtube.com/watch?v=9rt9ErQKnf8",
  "title": "Off-By-One 2024 Day 1- Exploring WebKit\u2019s Just In Time Compilation: Vignesh S Rao",
  "description": "Abstract\n\nJIT compilers have been the subject of numerous vulnerability discoveries. This is due to the nuances of optimization phases and their potential to introduce subtle bugs. This talk aims to unravel some key optimization phases in JavaScriptCore, WebKit\u2019s JavaScript engine that powers Apple Safari.\n\nThe focus will be mainly on DFG intermediate representation and how optimization phases on this can give rise to vulnerabilities.\n\nThrough specific examples and case studies, we will examine vulnerabilities resulting from logic errors in the compiler. These examples will showcase the real-world impact of optimization phase vulnerabilities, highlighting their severity and potential exploitation scenarios.\n\nSpeaker\nVignesh Rao is a vulnerability researcher at Exodus Intelligence. He is currently focusing on bug hunting and exploitation of web browsers, with specific focus on JavaScript Engines. He loves anything system security related and has researched multiple userland and kernel applications before especially in the MacOS/iOS ecosystem.\n\nVignesh also used to be an avid CTF player and regularly participated in CTF\u2019s as a part of the bi0s team in the past.",
  "channel_url": "https://www.youtube.com/channel/UCmrsIbKdxEMBEefD8v8RigQ",
  "duration": 2208,
  "channel": "Off-By-One Comms Team",
  "uploader": "Off-By-One Comms Team",
  "upload_date": "20240831"
}

This text was transcribed using whisper model: large-v2

 Good afternoon everyone and welcome to the talk.  So the title says that it is just in time compilation, but most of what we discussed  is going to be applicable for all other browsers as well.  So thanks Rana for the introduction, we can get straight away to the content.  So JavaScript, I think most of you are familiar with JavaScript.  JavaScript is an untyped and an interpreted language.  So if we have a statement that looks like let x is equal to a to b, what happens is  that it is first converted into byte code.  Byte code is a form of representation of code that is a bit lower level than the original  source code and the byte code is actually executed by the JavaScript virtual machine  which is the interpreter.  Now JavaScript code, short, this is JSC short for JavaScript code and JavaScript code is  the WebKit, is WebKit's JavaScript engine.  The byte code for JavaScript code looks something like this.  So you can see that each byte code consists of an opcode followed by a couple of, a few  operands.  So it is kind of like assembly, but it is a bit higher level.  So now let us talk about the interpreter first.  So the interpreter is the code that actually executes the JavaScript byte code.  To visualize this, you can just think of the interpreter as a huge switch case that switches  on the opcode and each case is a handler for that byte code op.  Let us just see that in action.  So typically JavaScript code is first converted into byte code.  Byte code is represented as an array, where for example the first one is add, first one  was add and the interpreter, what it will do is that it will fetch one instruction  from the byte code.  It will resolve the handler for this instruction and execute it and after that it will update  the PC to point to the next instruction in the byte code and this loop is going to go  on.  So this is basically a fetch, resolve, update.  First fetch the byte code, resolve the handler, update the PC.  However, this has a few problems.  One of the main problems is that the fetch, resolve, update cycle that this is following  is actually pretty slow performance wise, especially when we are talking about repeated  code execution.  For example like your JavaScript code has a for loop.  So each instruction is going to be fetched, resolved and updated like thousands of times.  So this makes a lot of, for a lot of performance loss.  Another issue is that JavaScript does not have types.  So the interpreter needs, so if we have a statement like this, A and B can be any type.  So the interpreter has to provide for all possible types of the statement.  Another issue is that byte code does not have any dependency between opcodes.  For example, if take this JavaScript code, we are actually, if you think, if you assume  that A and B are integers, we are actually computing A plus B three times, whereas we  could have ideally done something like that, add A plus B and store it three times.  But instead we are going to compute it three times.  So this is again leaving performance on the table.  The solution for this is to compile, compile the byte code into native assembly.  But this is only viable if that byte code is going to run multiple times.  For example, if there is a for loop in the JavaScript function, then it is viable to  compile the, compile JavaScript into assembly.  So in order to do, solve the various problems that are faced by the interpreter, we have  multiple JIT compilers implemented in browsers.  One of the first compilers, the baseline compiler, which solves the repeated for, repeated cycle  issue.  Let's see that in action.  So let's take this very simple JavaScript code, addition, multiplication, object creation.  This is first converted into byte code, and what the baseline compiler is going to do  is that, it is going to take one instruction of the byte code and convert that to assembly.  So here, just load the arguments into the registers, and call the handler function.  It does the same for the store, and it does the same for the rest of the instructions.  So this is the pseudo x86 assembly.  Now the interesting point is that in the baseline compiled code, there is no fetch.  In fact, there is no reference to the byte code area at all.  It's all assembly.  So there is no update, there is no, there is no handler resolution.  So the entire fetch result cycle is gone.  We just have assembly code, raw assembly code.  So this provides considerable speed up over base, over the interpreter.  However, the baseline compiler makes very little optimizations, very few optimizations.  We are going to see a couple of them.  So the resultant code is not the most efficient.  You don't have to read this, but this is how, this is how the JavaScript code's baseline  jetted code looks like.  You have the add instruction, and followed by the assembly for that.  One point to note here is that you don't see that call instructions that we actually saw  there.  Call handles some, you don't see that call instruction anywhere here.  That is because baseline is a bit smarter, and when I was compiling this, I used both  the operands for this add as integers.  So when I took the baseline, what it did is that it actually emitted an add instruction  directly, instead of having a call, and followed by a store.  However, it also has checks.  If either of the operands are not integers, it goes to something called a slow path, and  in the slow path, we have that call to the hand resolution function, the interpreter.  This is the generic code.  Now this is, now this optimize, this fast path, slow path thing is the, is one of the  optimizations that are, that is done by the baseline compiler.  Basically optimize the fast, optimize the common case.  That's what this is doing.  Another thing it does is inline caches, but before that we need to look at how objects  are represented in JavaScript.  Consider this object X, which has two properties and two elements.  In memory, this is actually represented as a pointer, as a combination of three pointers,  the shape, properties, and elements.  Just keep in mind that I'm just talking generically here, so each engine might have, might tweak  this a bit.  For example, Chrome might have a slightly different notation, but in essence, it remains  the same.  The shape is something that contains the property names.  You can see prop1, prop2, but it does not contain the property values.  The property values are contained in the properties pointer, and the elements are contained, 1,  2 are contained in the elements pointer.  You can see that in the shape, we have a few offset, and you might have guessed what it  is already.  Prop1 is mapped to 0, that means that if you, if I want the value that is associated with  prop1, all I have to do is look at the 0th index in the property setting, and same for  the 1.  So how do I actually access, find the, for example, there you can see 8, we are accessing  8.property.  What does the engine do, JavaScript engine do?  It first fetches the shape, then it iterates through all the properties in the shape, it  sees prop2 there, fetches the index, goes to the properties array, and goes to the required  index, which is 1, and fetches, and gets 1, 3, 3, 7, which is the value of prop2.  However, this is a little bit slow and can be optimized.  In order to optimize this, JavaScript has something called inline caching, and it attaches  a cache to that property there, property access there.  This is a cache with 3 slots.  So what happens now is that the shape is accessed, it checks the cache, but the cache is empty.  So it goes by the default way, the one we just discussed, however, after the default  way finishes, it updates the cache.  The cache is updated with the shape as well as the property offset of prop2, which is  1.  So the next time we see a shape S1, it will check the shape in the cache with the shape  of the object.  If that shape matches, if that shape matches, we have a cache hit.  So now we don't have to access the shape on top at all, we can straight away go to the  properties and access the first index.  However, what if there is a different shape?  If there is a different shape, then it's a cache miss, because S2 does not match what  is there in the inline cache, so this is a cache miss.  And if there's a cache miss, we go to the default interpreter out, and fill the slot  with the new index.  So basically this cache keeps track of all the structures that are seen at this point  along with the property offset number.  So from the problems that we discussed with the interpreter, the first one is solved by  the baseline JIT.  The second one is also kind of solved with baseline JIT's fast path slow path approach  as well as, as well as the inline caching approach.  However, the third part is never solved, there's still no, the baseline JIT still has no dependence  between objects.  For this, we have something called optimizing compilers.  Optimizing compilers are slow to generate code.  Optimizing compilers do not work with the bytecode because bytecode is not optimal here.  So optimizing compilers always have their own representation of code.  However, the code that optimizing compilers emit is very much more, much much more faster  than any of the other ones.  Slower the optimizations, more efficient is the code, but slower is the compilation.  So typically to offset for the slow compilation, what browsers do is that they have multiple  compilers, not a single compiler, multiple compilers.  Each compiler doing more optimizations than the previous one.  Also this, for compiling code, you need types and JavaScript is an untyped language.  So all the, all the optimizing compilers are going to speculate on types, just like  the baseline compiler did.  So pictorially, the previous slide represent is, it looks like this.  Source code is now parsed into the, by the parser into the bytecode.  Bytecode is consumed by the interpreter.  The interpreter executes the bytecode and the baseline also executes the bytecode there.  And the profiled bytecode is now parsed to the JIT compiler, which emits an optimized  code.  And if there is a speculation failure, it goes back to the interpreter or the baseline  compiler.  Now let's shift gears to focus more on JavaScript core and less on the other browsers.  JavaScript core has four tiers of execution.  We already saw the LLN, which is the base, which is the interpreter.  Then we also saw the baseline JIT.  However, the other two, DFG and FTL are optimizing compilers.  So the FTL is the fastest, emits the fastest code, but it also takes the longest to compile.  If there is a speculation failure in DFG or FTL, control flow shifts back into baseline.  So you can think that, you can see all this complexity there and more the complexity,  more the chances of bugs.  I was saying that interpreter always works with bytecode.  We also saw that baseline also works with bytecode.  However, DFG works with a different representation of code called DFG IR and the FTL works with  three IRs.  It works with the DFG IR of course, but it also has two unique IRs of its own called  D3 and DIR.  Now let's talk about typing in DFG.  In DFG, types of a, JavaScript has variables and types of a variables in DFG is represented  using two things, speculated type and abstract value.  Now speculated, both of them represent the type of a variable in JavaScript.  Now speculated type actually signifies the most possible value of the type.  For example, if I have a JavaScript variable that has the speculated type int, it basically  means that most probably this variable is going to be an int, but it can also be anything  else.  However, if an abstract value says that the JavaScript variable has type int, it is going  to be int.  It can be nothing else.  This means that speculated type needs to be checked at run time because it's for all purposes  it's just a guess.  Educated guess for just a guess, so it has to be checked at run time.  The abstract value is a compile time pro, compiler proves it at the compile time, so  it never needs to be verified.  It is trusted by the compiler.  Speculated type is calculated using profiling data, whereas abstract types are calculated  using something called DFG AI.  AI stands for abstract interpreter not artificial intelligence, and speculated type is used  to construct RIR, whereas abstract values used to optimize RIR.  They have their own functions and they don't conflict with each other.  Now let's look at how abstract values are actually represented in memory.  So if you look at the source code for JavaScript code, everything is in C++.  This is the structure that actually has the abstract value, that actually defines that  abstract value.  So it has a field called mstructure, which has a list of all possible shapes an object  can have.  In JavaScript code that shape thing that we saw earlier is also called a structure.  We are going to use that interchangeably.  Structure means shape, shape means structure.  So this mstructure is a list of all possible structures a variable can have, and mtype  is a list of all possible types this variable can have, kind of conflicting right?  So let's do this with an example.  Let's say a variable has mstructure as let's say S1, structure S1 and a type int.  What this means is that this variable can either be an integer or an object with type  S1.  It can be nothing else, integer or an object with type S1.  We are going to skip the next two objects for the purpose of this presentation.  Finally we have the mvalue, mvalue field what it signifies is that it holds the address  of an object if an object is const.  Let's do that with an example.  Take this JavaScript statement for example.  This is, this has the const specifier added to it.  What this means, what this const tells is that this object can never be modified.  So if you try to do object equal to 5 later, that's a JavaScript error.  So that means the abstract value of this object will have the mvalue field as the address  of this object because it's never going to change.  So the mvalue is the address of the object.  It's important to note that mvalue and structure do not conflict with each other.  Mainly because I can modify the value of the object however the structure, so that the  structure changes.  However the address of object is still constant.  So mvalue and mstructure do not conflict with each other.  There are two special type, special values that each of those fields can hold.  One is called the top which is, which stands for anything and one is called the bottom  which stands for nothing, another thing.  So which, this means that if mstructure is top, this means that this variable can be  any type, any type.  It's an object but it can have any type.  So if the variable is, if the mstructure is bottom, then it basically signifies that this  variable can be, it will have no shape at all.  That means it's a primitive value, integer, flow, whatever.  The abstract interpreter is used to find the concrete type of the node.  It has all, it also has other implications.  For example, it's used for constant folding but, constant propagation but we are not going  to discuss that here.  The other thing is that if you are reading the source code, it's always called DFG-AI  or AI in the source code.  AI stands for abstract interpretation.  Now we're going to look at a bug in the abstract interpreter itself but to do that  we have to be more familiar with property accesses in DFG.  You are probably familiar with this now.  We are accessing a property P1 on that object.  Whenever interpreter sees something like this, it attaches an inline cache, IC.  And the IC right now is populated with S1, 0.  Shape S1, offset 0.  So when DFG tries to optimize this, it splits it into two, sorry, it splits it into two  opcodes.  One is the check structure and one is the get by offset.  The check structure checks the structure of the object, this object, with S1.  Where did it get S1 from?  It got it from the cache.  And the get by offset fetches the actual property from offset 0.  Where did it get the 0 from?  From the cache.  So DFG basically bakes the inline cache into the IR.  An interesting point to note about check structure is that if that comparison fails, this is  basically a comparison, compare, check if object structure is same as S1.  If that comparison fails, this is a speculation failure and no further code is executed.  So, now let us look at an example.  Just take a moment to read this JavaScript code.  It is just creating three objects, X1, X2, X3.  X1 has the shape S1, where P1 is at offset 0.  This one has shape S2, P1 is at offset 0 again, even though shape is different.  Offset is same.  This one is X3.  Shape again is different, but offset is again the, in this case the offset is also different.  P1 has the offset 1.  The other two had an offset of 0.  And a point to note is that we are going to be studying the property access arg.p1.  Now we know that arg.p1 is going to have, arg.p1 is going to have an inline cache.  The data in that inline cache is represented in JavaScript code using a class called GetByStatus.  So, this is again a class and this is used to track the property access.  GetByStatus is used to track the property access of that issue, of that property access.  And now we can forget about all the other fields.  The only field that we care about is this vector.  This is a vector of GetByVariant.  So, now we have to go into GetByVariant and we have to disassemble it.  It's a complicated structure.  You do not have to read any of that.  What you have to note is that the GetByVariant is something that keeps track of structures  with similar property offsets.  Again, we will see this with an example rather than this thing.  So, let's bring that example which we saw earlier.  X1 and X2 have a shape S1 and S2.  And the point to note is that both have P1 at offset 0 even though their shape is different.  So, this means that V1 is a variant.  So, GetByIdVariant with, that holds S1 and S2.  And V2 is a variant that holds S3.  The point here is that if your offset is same, you have a single variant.  If your offset differs, you have a new variant.  So, S1 and S2 have the same offset, offset 0.  So, they are both clumped together in a single variant.  Whereas, S3 has a different variant.  So, it has, S3 has a different offset.  So, it has a different variant.  The GetByStatus is a vector of all these variants.  Now, what we are going to do is, we are trying to ask how do we create this GetByStatus using.  To create a GetBy, to create all these variants, statuses and all, what we need is that at  this point, arg.p1, we need to know what is the structures that arg can have.  What are the structures that arg can have?  One way to find that out is the inline cache.  The inline cache associated with that arg.p1 access will hold all the structures that it  has ever seen.  But, another way that we can compute that is using what we just discussed are abstract  values.  Because abstract values also, abstract values also signifies more or less the same thing.  Speaking of abstract values, let us actually look at some buggy C++ code.  So, this is the code for abstract interpretation of GetById.  What is GetById?  Let us say we have an object.p1 access.  Then, object, then if we have an object.p1 access, then the GetById is an opcode that  is, I mean, is the DFG opcode that signifies that property access.  So, first we fetch the abstract value of object.  Then, we fetch the p1 as a string.  It is string implementation p1.  We fetch that.  We compute the GetByStatus that we just discussed using the abstract value.  We already discussed that one GetByStatus has multiple variants and each variant now  has to be, the for loop has to traverse over each of the variants.  Now, this is a complicated bug.  I am trying to simplify it as much as possible, but still it is a complicated bug.  So, now each variant as it is traversing, it is calling this inferred value for property.  What this whole code is trying to do is to predict the abstract value of the result,  object.p1.  We know the abstract value of object.  What is the abstract value of object.p1?  This whole code is essentially trying to find that out.  So, that is found by this property, inferred value for property.  Now, what this function does is that it checks if object is a constant, conspecifier for  example.  And if it is a constant, then it goes directly and fetches the option that it has passed  and fetches that value.  So, it knows the type of object.p.  And it does that for all the variants and the results are merged together.  However, this has a problem here.  We are actually doing, in the previous couple of slides, we are actually doing, making an  array access on the property offset in this code.  But we are, but the offset is keeping on changing in the for loop.  Initially it will be 0, then it will be 1, offset comes from the for loop.  And that should not happen because we are trying to access object.p1, which p1 is at  offset 0.  But this code is trying to access offset at 1.  So, this will essentially lead to an out of bounds error.  It will lead to all kinds of error.  Long story short, this code makes no sense here.  No sense.  So, this is actually going to give incorrect results of the resulting abstract value.  Because we can see that with an example again.  Let us say we have an object, let us say we have an object obj1 with two properties s1,  two properties p1 and p2.  Then both of the properties here are actually this pointing to the same value.  And we have an access object here, property access.  We are going, trying to exploit all property accesses.  So, let us say that somehow, we do not know how, but somehow that property access has  the abstract value that is shown here.  Two structures s1, s2 and a value, and a const value of obj1.  So, this value is effectively obj1 and the offsets are going to be 0 and 1.  So, what is going to happen here is that, first we try to get the property at offset  0, which is, this is going to be p1, it is correct.  In the next iteration of the for loop, this is going to be 1.  This is an out of, this will, might or might not.  In this case, at offset 1 we have p2.  And we are trying to compile an access to p1, but the compiler is reading other property  p2.  The compiler itself is confused at this point.  So, it reads some incorrect value, the resulting abstract value is also incorrect now.  So, just to take a moment, abstract value is something that is trusted by the compiler,  but due to a bug, as abstract value is now wrong.  So, a trusted internal value is now wrongly computed.  This means that we have avenues for type confusions everywhere here, from here.  So, one of the main places to look for type, where abstract values are used is constant  folding, because it is a constant folding case.  So, what is constant folding?  Constant folding is basically an optimization case in the DFG IR.  And let us see what it does for the check structure opcode.  To recap, when we have a property access like this, DFG converts it into two access.  One is a check structure, one is a get by offset.  Get by offset is basically fetching the property value, whereas the structure check is done  by the check structure.  And what this code is going to do here is that, it first fetches the abstract value  of object.  What does the abstract value of object contain?  It contains all possible structures object can have.  And then it fetches S1 from here.  This set is basically S1.  Now, if the, now the compiler asks the abstract value.  What are the set of structures that, structures that this can have?  What are the set of structures that object can have?  And if all, if the abstract value reports to the compiler that object can only have  one structure, S1, then this entire check structure, entire check structure can actually  be eliminated here.  Which we, and now coming back to our code.  Our bug was that we have an incorrect abstract value for this.  And if we access a property on that, on that value, then check structure, this is, a property  access is actually split into two DFT opcodes.  The check structure is incorrectly eliminated because the abstract value is incorrect, the  check structure is incorrectly eliminated.  Because check structure is, elimination is based on the abstract value which is now incorrect.  So we have an incorrect elimination.  So we just have a get by offset which is a direct pointer access without any checks.  In reality, what happens is that the compiler thinks access object can only have the structure  S1.  However, in reality it can also have the structure S2.  So which means that if it has the structure S2, which we, I did not even show S2 here.  It is just some random structure S2.  Then object.p1 can be a random access, can be a random number.  It can be 1, 2, 3, 4.  For all I know, access can be 1, 2, 3, 4.  And this one is now trying to access, do a pointer dereference on 1, 2, 3, 4.  Which is, which is why.  So if I run that in GDB, this is how it looks like.  I crash with rcx as 1, 2, 3, 4.  Because this crashed the entire engine by doing an arbitrary pointer dereference.  So I am from here writing an exploit is actually simple from here.  So we are not going to talk about writing an exploit, but it is pretty simple.  And this bug was patched in, I think November last year.  It was introduced in 2014.  This is a bug, this is a bug so complex that it lived in the compiler for 8 years.  So 8 years Safari was vulnerable to this.  Safari could have been exploited using this bug.  Only in November it was patched.  So that is the advantages of complex bugs.  Now let us look at a simpler bug, much more simpler bug.  For this we need to know what is a JS value.  We know, we know that if object is equal to,  if we have JavaScript statement like this,  internally JavaScript statements, JavaScript core actually stores obj as a pointer.  Pointer means all upper 15 bits are null.  Because that is how virtual memory works.  Virtual memory only uses the lower 48 bits.  So upper 16 bits are actually null.  If you are storing a number,  JavaScript core actually uses this FFFE.  So upper 15 bits are set.  And finally if we have a float, float is imported using the IEEE 754 format.  This is the 1.1 IEEE 754 will give us some value.  And JavaScript core what it will do in turn is that  it will add 2 to the power 49 to our IEEE imported thing.  Now if you have done bug hunting before,  every addition is suspicious to,  every addition is suspect to integer overflows.  This means that if the upper bits of an IEEE 754 are all set,  then this can overflow.  So the compiler has to protect against it.  In theory it can overflow, in practical it will,  in practice it will never overflow.  This is because the IEEE 754 format says that  if the upper bits are all set, it is not a number.  This is not a number.  JavaScript only honors one not a number value and that is this one.  Everything else it does not honor.  So now let us go back into the code base.  This is the code that converts JavaScript IR,  DFG IR into assembly.  So this is the code that has been compiled.  We have an array access and that array access is  being compiled to assembly.  However this is not a simple array access,  it is a floating point array access.  Speciality of float 64 arrays here is that  float 64 arrays hold raw floats, IEEE floats, not JS value.  And another interesting point is that  they are completely user controlled.  We control every single bit.  So this means that when we do a get by val,  this means that when we compile it,  the compiler should actually check,  the compiler should actually check,  first convert the float into,  convert the float into a JS value  and also check each of the bits.  The compiler does check,  convert the float into a JS value,  but it never checks whether the top bits are set or not.  So this means that we have an overflow here,  which should never have happened.  And we again have an arbitrary pointer dereference.  We actually did a,  me and my colleague did a full talk on this.  I assume you can watch this there.  To conclude,  some takeaways here are  to hunt for assumptions in code  and to compare implementations between various compilers.  Another idea is to look for variants.  This is that get by, that nan value patch,  that was patched.  It was patched two times,  three times, four times, five times.  It was patched.  This work has been there in the compiler since 2022.  Every time in different parts.  It's interesting to look at all the variants  and it's also interesting to look at the depth.  The abstract value is so deep  that it's lived in the compiler for eight years.  So finally, as a demo,  this is the nan exploit running on an iPhone.  And it's iOS 15  and it's actually reading the slash etc slash password.  So that's more or less it.  I'm running out of time.  I'm sorry for overrunning it by a few minutes.  And I'll be around if anyone has doubts or questions,  then I'll be around the place.  Thank you, Ignis.  We can open the floor for a couple of questions very quickly.  If anyone's got any questions,  you can use them now.  Yeah.  With such a complex code base like JavaScript core,  how do you find the ability to track virtual methods  being called in vtables deep and deep into the code base?  Do you usually use that dump disassembly  or dump bytecode thing?  Yeah.  So typically what people do is that you read the source code.  But rather than reading the source code,  I feel like reading the IR  and that dump disassembly is more helpful  than reading the go and reading the source code.  So I would say, yeah,  read the IR and then read the source code.  Thank you so much for your talk.  I was just curious how these two bugs were found.  Was it through auditing or fuzzing or things?  So the first bug was not mine.  The abstract value bug is just a bug  that I thought was so very interesting.  The second bug is mine.  It was found by me and my colleague.  So it was found partially by fuzzing,  partially by auditing  because we were auditing a code  where a fuzzer actually found the crash.  The fuzzer crash was not exploitable,  but when we audited that code,  we found a different bug.  So we found this by looking at just reading code  and yeah, mainly by source code auditing.  Any more questions?  All right.  For any other questions,  you can take your seat with Vignesh.  Thank you very much, Vignesh.  Thank you.