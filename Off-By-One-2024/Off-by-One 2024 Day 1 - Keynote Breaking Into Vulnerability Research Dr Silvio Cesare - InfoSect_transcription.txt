{
  "webpage_url": "https://www.youtube.com/watch?v=tAmjkfO3-Ow",
  "title": "Off-by-One 2024 Day 1 - Keynote : Breaking Into Vulnerability Research: Dr Silvio Cesare - InfoSect",
  "description": "Abstract\n\nThis talk discusses the challenges of starting and running a company that specialises in vulnerability research. The typical problems likely faced include:\n\nHow do you build a new team?\nAnd how do you encourage knowledge transfer and upskilling within your team?\nWhat targets do you focus on?\nHow much engineering is required to support research?\nThis talk will give insights and answer these questions, for the purpose of maintaining reliable, consistent, and high quality research outputs.\n\nSpeaker\nDr Silvio Cesare is a founder and Director at InfoSect, a vulnerability research company. He has worked in technical roles and been involved in computer security for over 29 years.\n\nThis period includes time in Silicon Valley in the USA, France, and Australia. He has worked commercially in both defensive and offensive roles within engineering.\n\nHe was previously the Director for Education and Training at UNSW Canberra Cyber, ensuring quality content and delivery. In his early career, he was the lead architect and developer for the startup Qualys, now the industry standard in vulnerability management. He has a Ph.D. from Deakin University and has published in academia, having been cited over 800 times on google scholar. He is a 4-time speaker and also a trainer at the international industry leading Black Hat conference.\n\nHe has taken his University research through commercialisation and authored a book (Software Similarity and Classification, published by Springer).",
  "channel_url": "https://www.youtube.com/channel/UCmrsIbKdxEMBEefD8v8RigQ",
  "duration": 3059,
  "channel": "Off-By-One Comms Team",
  "uploader": "Off-By-One Comms Team",
  "upload_date": "20240831"
}

This text was transcribed using whisper model: large-v2

 It's a great pleasure for me to welcome our very first speaker, Dr. Silvio Cesari.  So Dr. Silvio here is actually a founder and director at Infosec, a vulnerability research  company that he has set up.  He works in various technical as well as leadership involvements in computer security and has  been doing so the past 29 years and counting.  So his talk today will focus and discuss about the challenges of starting and running a company  specializing in vulnerability research, the challenges involving your building a team,  the knowledge transfers, targets to pay attention to, and these will be some areas of focal  point for his talk.  So without further ado, let's put our hands together to welcome Dr. Silvio.  Thank you everybody for coming off by one, a really special thanks to David and Star  Labs for giving what will be a great conference.  It's the first conference of the many to come.  And like I was introduced, I want to talk about effectively building a vulnerability  research company, not really from scratch.  And so this talk is about some of those challenges and it's really going to focus on building  a team of vulnerability researchers and faculty.  One sort of basic question I suppose that broadly across the sort of the cyber security  industry isn't uniformly known is what exactly are we talking about when we're saying vulnerability  research?  Are we talking about a two week end test engagement to audit some code for a customer?  What is really the point of it?  And in my sort of definition, and everyone's definition will be slightly different, but  my definition of vulnerability research is the ability to reliably and repeatedly discover  and exploit zero days in hardware or software targets or any target.  The targets have to be relevant.  So when we talk about finding bugs and finding zero days in the software, are we talking  about that shopping cart that three people in the world use?  No, we're not.  When we talk about vulnerability research specifically, we're talking about targets  of ubiquitous nature and most likely essential system software.  When we talk about vulnerability research, we're talking about those types of targets  or software configurations in the default configuration.  So it doesn't really matter if you find bugs in some fewer part of the software that isn't  enabled.  It doesn't really count when we say that we're doing vulnerability research.  Typically when we look at a target as well, it's going to be hardened and defended.  There'll be some sort of software team defending that software, implementing mitigations and  hardening, looking for previous exploits that have been used against the target and making  appropriate responses as well.  And really when we exploit these targets, we're looking for some sort of reasonably  strong effect such as remote code execution or local commits or whatever it might be that  pass across a real security value that has a useful effect for the people and widens  their needs for it.  Any attack that achieves the objective, so if your goal is to get an RCE, anything that  achieves that objective, whether it's XSS or SQL injection, whatever it might be, is  valid.  In practice though, realistically most of the bugs that you will find that have real  utility are going to be memory corruption bugs against native code like C or C++.  That's just the nature that most of the software that we use is written in those native languages.  So the typical types of targets that we'd be interested in are operating system kernels  and OSes in general, but kernels are very particularly important.  Operating system network services, that gets you sort of onto a box or remote code execution  and so forth.  Hypervisors are a great thing to look at.  Host escapes, host perverts, guest perverts, all of those things are sort of useful.  Browsers or some of these one-click browser chains are very common and almost synonymous  with vulnerability research in fact.  And then we go on to things like instant messaging apps with three clicks.  Mobile handsets are very much in scope.  Something that's useful and crosses the security boundary if you want it.  And embedded devices are becoming part of this world as well.  So vulnerability research against embedded devices, whether that's security cameras,  NDRs, whatever it might be, have valid validity.  If you're still sort of wondering what type of thing, if I'm finding bugs in software,  is it the concept of usefulness for a vulnerability researcher?  The Zeronium sort of bounty list is a good place to sort of get an idea of what targets  have some sort of utility for vulnerability research.  So Zeronium and exploit broker are probably quite ubiquitous.  They pass on these exploits too.  But we can see at the very top, Android full chain with persistence, zero click.  Then at the bottom we might have lock screen bypasses or qubits or whatever it might be.  But this is just indicative of the type of things that really are essential to systems software  and really what we want to focus on.  Now, ultimately what tends to happen is that we all sort of start off quite broad and say,  well, vulnerability researchers, lots of software might be useful,  but we end up generally all going towards these common targets or these common domains.  In pentesting you might be given any software or hardware target for any nature.  You don't really do that in VR, I guess.  Not generally anyway.  Occasionally you might get persuasive stuff.  But in general you often sort of evolve to these set of standard targets and domains.  Because ultimately the goal is to reliably, repeatedly and consistently develop research outputs.  So the targets that you end up going towards, well, they need to be complex enough  and sort of have enough code to ensure that there's a steady supply of bugs that come out of it.  If you sort of build like a team to look for suit, for example,  you're not really going to maintain bugs in that software.  You might opportunistically find some sort of pre-vets,  but the code chain is quite low, the access is quite small,  so it's probably not going to be where you invest a team to look at.  And even just user-land pre-vets in general on Linux would be a pretty hard target in that sense.  It's probably not going to have a high code chain, a high complexity and a steady supply of bugs.  But operating system kernels might be more useful.  So you need supply of high quality bugs.  And if you get a bug, you need to be able to be somewhat confident that you can exploit it.  So some targets simply are not easy to exploit.  If there's not much programmatic feedback, you can't sort of build your primitives,  your pre-write primitives, get info links, scan over memory in some programmatic way,  it becomes really quite difficult.  So most good exploits or reasonable exploits are going to have heap grooms,  they're going to have leaks, corruption and so forth.  So this idea of this one chop of lines attack,  maybe for a non-interactive program like Sudo or something like that,  it's going to be very difficult.  So programmatic feedback is desirable.  So operating system kernels, hypervisors, browsers,  these are the things that really enable you that when you find a good bug,  you have a pretty good chance of exploiting it.  Also the targets need to be ubiquitous and have desired privileges.  So again, I've sort of said this already,  if you have an obscure package that needs a user to install some weird configuration  or install the package ultimately, it's probably not going to be that valuable.  A little bit about me.  I've been sort of in the hacking world for about 25 or so years or 25 plus years really.  I didn't do bug hunting and exploit development for the entire duration of my career.  Certainly there have been people that have been my peers in that period of time  that have stayed almost exclusively as bug hunters and exploit developers.  I did sort of hobbyist bug hunting at various points in the first half of my career.  And in fact, even back in 2008, I was one of the first sort of people  or individual researchers that did sort of large-scale auditing  of a single learning kernel in particular.  But most of that 25 years or so that I've been working in sort of IT or security,  I've been working on low-level native development, reverse engineering or program analysis.  And in fact, I did a PhD and commercialised some of that PhD research  using program analysis on malware defence actually.  I was also a university educator for a couple of years and still regularly run trainings,  generally private trainings at InfoSec in my home of Australia.  But that was sort of my first part of my career, my first half of my career,  and then I transitioned to full-time bug hunting and exploit development.  So InfoSec is roughly about a 20-person VR company, about 22 people at the moment.  Our team works on-prem.  So it's sort of unusual in today's sort of age where people want either fully remote  or at least a combination of remote and on-prem.  We almost exclusively work on-prem on our facility,  and we have a lab and so forth and all of those types of things.  It's founded by myself as the CTO and Kylie McDevitt as our CEO.  And this talk is about some of the challenges and lessons learnt  in building and running that 20-odd-person VR company.  So, I mean, this almost is going to be like how to build a start-up talk, in fact.  And so the founding team is how do you start a VR company?  Well, you need a founding team that does that.  Now, when you run a business, any business, not just a VR business,  you need to have business know-how.  But this talk is about sort of the technical and engineering challenges.  So we'll just ignore the business part of registering businesses,  getting insurance, you know, getting Superall, all that type of stuff.  I would say your founders need to be generalist specialists.  So founders will be doing all the tasks at the beginning.  They'll be setting up infrastructure, doing research,  finding bug-prone exploits, developing tooling and so forth.  And so your founding team needs to be able to put on many hats  and do lots of different things to sort of build the team over time.  And at Infosec, my co-founder, Kylie, was a generalist.  So she knew very broad IT security and cybersecurity,  but she was also a specialist in infrastructure.  And that's what I mean by generalist specialist.  You can do everything, but you have some sort of unique skill  that has value to the company.  Because no one wants to employ people that are just average at everything.  So you can build customs, all that, but you need to be a specialist at something.  I started sort of as a generalist, but I was also a researcher.  So I was sort of the primary researcher when we started the company,  and I still do lots of research today.  Now, sales is actually a very important thing to start-ups.  And in fact, most start-ups see the main problem with business...  I want to say start-ups, cyber start-ups in general,  not just VR companies here.  In fact, not VR companies here.  Most start-ups see the main problem with business as a sales problem.  And they see that the more sales and the more customers you get,  the bigger and faster you'll grow.  So sales drives growth in most cyber start-ups.  Now, in a vulnerability research-focused company,  that's not generally the main problem.  You have a customer set that finds VR valuable.  The main problem in a VR-focused company is engineering.  The more things you can develop, the more research output you have,  that will drive growth.  So the better you are at your job,  generally the deeper your customer base will go and the stronger it will be.  There are lots of myths about VR.  In fact, you see this all the time.  And one of the common myths even told by people,  like quite a few people today,  is this idea that if you're not doing VR already,  then don't even start.  Because the argument is, if you want to do VR today,  you would have wanted to do it 10 years ago.  And it's only gotten so much harder in that 10-year period.  So if you didn't do it then,  and you're just maintaining your capability, I suppose,  why would you think you can start now  and catch up the past 10 years and the next 10 years going forward?  So the idea is that if you pursue too hard,  you would be already doing it if you could,  so don't even try.  So that's sort of a very common myth, actually,  by people that have consumed the outlets of vulnerability research.  But people break these myths all the time.  You see CTF players jumping into hard problems  and solving hard problems.  You see vulnerability researcher newcomers  enter the field all the time.  There are young people that enter vulnerability research  and are very successful.  And you see existing vulnerability research companies  take on new targets or new complexities  as the technology evolves.  So, I mean, you see VR companies expand their repertoire  so they can do new things.  Now, my own transition, there's a big difference  between hobbyist, bug hunting and vulnerability research.  Vulnerability research is a large, deep and complex field.  In my opinion, it's basically impossible  to find bugs more lively  unless you've invested a large amount of time  studying your target, your real-world code and your targets.  For myself, when I started sort of, you know,  20-odd years ago, 25-odd years ago,  I was always pretty good at finding bugs.  But as I sort of transitioned to doing this all the time,  I lacked focus on finding relevant and impactful issues.  So, I was finding bugs that really weren't that useful.  So, maybe it's good to do sort of advisories  or something like that or public blog posts.  But in terms of finding relevant and impactful issues  that vulnerability research produces,  that was what I lacked.  So, over time, I worked to sort of target...  work my targets that I was looking at  using domain-specific knowledge  and became better at identifying,  focusing on relevant attack services.  So, that's really one of the main transitions  is you're not just finding bugs anywhere,  almost like a developer.  You're focusing and targeting  very specific attack service that has a useful security boundary.  And if you cross it, then that bug is going to be impactful.  And I sort of, as I did this more and more,  I became better and faster at learning new targets  and identifying target-specific bug-hunting strategies.  So, transitioning as a hobbyist bug hunter,  most bugs are actually not that useful, like I've said.  Bugs can be...  if it's non-ubiquitous,  if you think of just general development software,  most developers write terrible code.  That's just the reality of it.  Most software is non-ubiquitous,  so it doesn't really matter that much.  Most software is non-hardened  and it's not defended against...  and the software base is generally extremely buggy.  So, this doesn't...  if you're finding bugs in random software,  it doesn't really matter.  I mean, you should be able to find bugs  in non-hardened software pretty easily.  And even large and flexible hardened code bases,  so operating system kernels and so forth,  have practically an unlimited number of worthless bugs.  So, if your scope is the entire Linux kernel,  you should be able to find tons of bugs.  But at that point,  you're basically becoming a kernel janitor.  You're becoming a developer  and fixing small kernel problems  versus trying to find bugs that are useful  as a vulnerability researcher.  So, it's great if you're a developer,  but not great for vulnerability research.  And identifying the attack surface  and focusing on relevant default configurations  is really paramount.  It doesn't matter if you're finding bugs  in really non-default configurations  that are only used randomly or occasionally.  There's really no value whatsoever  from a vulnerability research perspective.  Now, we started sort of our founding team  at InfoSec, Polly and myself,  and we built the team over time.  I would say that transitioning  from a couple of people to a team  is a challenge in itself.  And I would say that leading by example is important.  Research is hard,  so I would say don't expect  that you can just hire your way  into having a successful VR company.  You really need to sort of set an example  and the team will sort of come  or gravitate towards you.  Hiring is challenging, for sure.  And you have your common startup problems.  I mean, do you hire the very senior people  that cost a lot of money?  Or do you hire sort of new up-and-comers  or juniors that probably are going to be  sort of cheaper to hire,  but probably don't have as much research output?  So those are the types of questions that you have  that every startup has.  Do you hire your first hires  to become seniors or juniors?  So exactly the same in vulnerability research.  And I sort of do believe there is a place  for juniors in vulnerability research.  There's lots of stuff that's needed  to support senior researchers,  tooling, engineering,  all of those things are quite relevant.  So I would say that if you're hiring,  there is a place to hire junior people as well,  and new up-and-comers,  and even occasionally take on interns and so forth.  So where do you hire these vulnerability researchers?  So you could hire well-known, famous  vulnerability research specialists and veterans.  You might see them on the internet.  You might know that they're very good.  They might be inclined to own as individuals,  stuff like that.  CTF players are good.  CTF players that are a very good opponent in RE  can sort of transition into  professional vulnerability research.  University graduates,  we at Infosec have sort of a collaboration  with our local national uni,  and we've had interns come through that process,  and they can be quite good.  But an internship is also an opportunity  to see if they're fit for this type of work.  It's sort of quite an unusual area  to work these days.  You know, from sort of a broad perspective,  you know, most young university people  don't really know that there's a world  of working with sea and assembly  and writing experts and so forth.  Sometimes you might get pen testers  and consultants looking to change careers.  It occasionally does happen.  I would say it's not the usual path  for most vulnerability researchers,  but you do see we have certainly in Infosec  had some pen testers change careers  and work for us to find bugs and write experts.  Software developers, OS kernel  or embedded developers are a good place to look.  If someone's working on a kernel or hard device,  they're probably good at finding bugs  and those types of targets as well.  We also have forensics people.  If you think of IT devices or embedded,  typically you want to get the firmware  off the device so you can start looking for bugs.  Forensics people tend to be quite good  at getting the data off the device  and getting the firmware off the device  so that we can start to turn it  into a software problem.  And then you might have electronic technicians  and engineers.  We do a lot of hybrid Infosec,  so we can have this as well.  The hiring process can be complicated  and like every startup,  how do you know that the person that you're hiring  is fit for the job  or it's a good culture fit and so forth?  And so we've evolved this over a period of time  and now effectively we use a trial process  for people entering or looking to work for us.  We basically get them to come out and work with us,  sit next to us for a couple of days  and then we give them a task  indicative of the type of work that we do  and then we say work on that task  and at the end of the couple of days  they do a presentation to the team  on what you've done.  The task is not unrealistic for the timeframe,  so you're not giving them ridiculously hard things  and normally the process is we take  a fairly pointless zero day  from a real world target  and then we get them to provide a POP to trigger  that verified that this bug is a real thing.  And we say pointless zero day  because it's probably some sort of bug  that, you know, like for example  if they get an info leak out of this code  but you need to be, normally you need to be  root to get sort of access to this part of the OS kernel  so that's sort of a pretty good,  if they can do that, it's pretty indicative  that they know how to write C code,  read a code base and so forth  and it's a pretty good way of doing things.  I think our hiring process has improved  quite a lot and we get better recruits  and better hires because  they know what they're getting into  and we can see how they work with the team as well.  So you can also identify if there's a culture bit  or a culture clash.  So when you're working, you know, sitting next to  the people that you plan to work with in the future,  I mean, you identify pretty quickly  if, you know, this recruit  knows how to, you know, collaborate in a team.  It also lets them know the expectations.  You'll be surprised that there is a sort of a belief  that, you know, people want to be vulnerable in your research  and so they don't want to really read too much code,  they don't want to write too much C code.  It's like, well, that's the job.  And it's very evident if a recruit knows basic skills  around a terminal, that they can write code,  use compilers, read code bases and so forth.  And if they complete that task that we initially give them,  we just basically, we get them to do sort of further work.  So if they've got an info leak,  then you turn it into sort of a KASLR bypass.  Or if you've done that as well,  we'll give them more bumps to sort of work up  in that period of time.  And so we always try to keep them busy and occupied  for the days that they're working for us.  Some people do these tasks really quite fast.  And then other people, you know, basically,  given sort of an unlimited amount of time  with where they're at at this point,  where they're at in their career,  they're never going to complete it.  So you're a VR company,  and VR companies have to set up targets.  The targets in VR are varied, but not unlimited.  You need to aim for realistic targets  if you're starting out.  If you're a very small team of two people  and you've never done iPhone stuff,  and you've decided that you're going to do an iMessage  with zero click, probably an unrealistic target.  You will almost certainly be doing targets  or looking at targets dictated by  what the founding team's specialties are.  And likely, you'll hire people early on  to support those specialties.  And as the company grows,  you can certainly go more broad.  And as the team grows, you'll have more outputs and so forth.  As you grow, you'll typically start off  with a relatively isolated component that you're targeting,  and you'll add more components as your team improves.  These components might be useful together,  you know, when you can chain them together.  And really, I would say that depth and specialisation  is the only way to be effective.  If your goal is to be across as many targets as possible  to some surface level, you will never achieve any success.  And in fact, when you have juniors on the team,  the basic goal of a junior is to get deep enough  into some sort of narrow area  that they can start to be effective.  Because if they just go across lots of broad things,  they'll never reach the depth required to find useful parts.  As they become more senior,  the great sort of this going deeper sort of slows down.  And then they become more broader.  So they start to see that, OK, maybe these things  that I'm working on actually is correlated  to this thing over here.  And then maybe you start to handle the bulk of the components.  Knowledge sharing is paramount.  The goal is to have a team  that lifts each of its team members up.  You don't really want, at least from my perspective,  you don't want a team that is all entirely individual-based  and doesn't want to share anything that they've done  or anything that they've learned or anything that they know.  It really limits how fast your team as a whole can grow.  And so there's lots of ways to sort of encourage  team collaboration and team knowledge sharing and so forth.  And probably most companies have variants  of all of these types of things.  There's things like internal documentation,  so wikis and so forth.  Internal presentations for the team is always good.  You can have a monthly internal presentation or seminar, I suppose,  with people doing what they've worked on.  Having a collaborative team culture is actually a really big thing.  It's harder for remote staff, for sure,  and that's one of the reasons that we're basically all on-prem.  Having a collaborative team culture is easier, I would say,  when you're face-to-face with your colleagues and your peers.  And also having staff and sort of establishing that culture,  having staff feel comfortable in asking and receiving help  or giving information of what they've discovered.  Having knowledge trapped within an individual  and not having an opportunity to share that with the rest of the team  ultimately limits how fast the team as a whole can grow  and what they can achieve.  I've sort of talked a lot about team culture,  and it's sort of clich√© when a company sort of says,  you know, it's all about team culture,  but I would say it really is.  When the company is small,  so when looking at the company size of about less than 10,  that's ultimately when your culture is built.  And then as the company grows bigger,  it gets really hard to change that culture  unless you've nurtured that culture very strongly early on.  And I would say you might have challenging decisions to make early on  to sort of enforce that culture,  but it's something that has to be nurtured and pruned and grown correctly.  If you just let it grow without any regard to what's happening,  you will have certainly a terrible outcome as the team gets bigger,  and it will, I imagine, become complete chaos.  Now, VR is very different to pentesting and consulting.  The culture is not the same.  So when pentesters look at engagements  and the customers that they're working with,  they have a very different view of their customers.  I would say pentesters are generally engaged  to find some sort of sloppy misintegration  or some sort of weakness of the person that's implementing that.  That's generally a very broad brush stroke here.  But I would say that VR people  work against a large team of expert developers  who spend their days, these developers,  trying to write functional and hard-to-attack software.  So you're going against a much stronger person writing code  or teams writing code.  And I would say that you have a greater understanding  of the skill that developers have,  and there's almost like a weird mutual respect.  I mean, I use these software systems myself all the time.  And for me to look and find bugs in the things that I use  as well, I mean, I think they're very good developers,  but our job ultimately is to find bugs in their software.  So I can certainly respect the developers of these systems.  I would say that most generally cyber security people  can't write very good code,  but the developers that we're trying to find bugs in  are very skillful.  When you have a new startup in your team,  you might fall into the trap of giving them  some sort of open-ended problem.  And for some starters, if you're a veteran VR person,  having some broad open-ended problem,  just some sort of target and some desired effect,  that makes sense.  For people new to VR, so you've got your interns  or your juniors or your mid-levels,  it really can be demoralising,  since typically if you're not guiding these junior people,  their output will be slow, inconsistent,  maybe even non-existent, and probably weak as well.  So I do prefer progressing sort of newbies in VR,  sort of juniors and interns,  or juniors and mids really,  from small tasks such as verifying a simple bug  that we found, say by writing a small pop  to verify that the bug exists,  and then progressively getting harder tasks  that make their work more balanced.  Again, you want to get their depth to a sufficient level  where they can actually start being useful  versus not being useful at all  if they only know certain level of information.  The more real and consistent output people have  at the beginning of their employment,  the more confidence they build.  So if you give a junior or a mid busy work,  they won't really build confidence from that,  but if you give them work that,  maybe it's not a big impact, but it's real impact,  and it's a real task,  they'll feel much more confident.  So I'm really opposed to this idea of busy work  for younger people or junior levels.  And broadly speaking, that confidence  also extends to the team as a whole.  New teams need to quickly find confidence,  otherwise it can be quite unpleasant to work  in a place like that,  or sort of having no belief that  you can do the task at hand.  Confidence, I believe, is built by the founders  and the rest of the team  ultimately demonstrating confidence.  If the founders can do it,  or your colleagues can do it,  it's sort of motivating.  You think it's possible, you think it's reasonable,  you think, well I want to do that as well as a junior.  And you can achieve seemingly impossible objectives,  and that really does build strong confidence.  And then ultimately your team just sort of thinks,  well this is business as usual,  our job is to find bugs in hard targets,  and we do that successfully.  Results do not always come quickly,  so we're not finding good quality,  impactful bugs every single day,  but major findings must come at regular intervals.  That's the goal of the job.  As a vulnerability research company,  you have to produce outputs.  So if you do that,  you'll have a tendency for your team to say,  well let's just hire,  I know some people that are my peers  from my ex-jobs or whatever it might be,  and they try to push their new peers as well  into the company.  So you sort of have this idea that  you get referrals from existing staff  to hire new people that are going to be good at the work.  Now if, as a team,  you're not getting findings,  major findings at regular intervals,  and you've gone through some extended period of time  and you're just sort of arguing that,  oh it's just a hard target,  yeah there's probably no bugs there,  well it's really untenable.  You need a direction shift or a change of strategy  must occur to stay on track.  You have to have regular outputs.  Engineering will have a role  in maintaining a VR company,  and so you'll need to do engineering support work  as well as doing pure research.  Some companies that are large enough  have separate engineering teams to research teams,  but as a small team,  even for us at Infosec,  as a 20 person company,  researchers will be required  to do some of the engineering work.  And it can be motivating in a sense  that engineering work tends to be fairly linear  in getting progress,  whereas in research,  it seems to be a bit more lumpy.  And even though it's sort of,  research might be nothing, nothing, nothing, something,  and nothing, nothing, nothing, something,  ultimately under the hood as well,  you can actually see linear progression  in research as well.  So even though the output is what you want,  you can see researchers,  I've ordered this part of the code,  I've identified an attack surface,  I know these APIs are problematic.  All of these things are linear progressions  of getting deep into the target,  and ultimately you have a pretty good intuition  whether your researcher that has followed this path  is going to be successful.  What typically indicates non-success in a researcher  is that they won't have any tangible, measurable output  apart from the bug itself or the exploit itself,  and they don't know what the attack surface is,  enumerate all the APIs,  know the problematic things,  know the architecture of the system.  You can sort of see that they're not going to be successful.  But engineering needs to support that as well.  I mean, there's a lot of engineering work  to support vulnerability research.  But some researchers do prefer just research  and don't want to do engineering work.  Others don't mind a bit of both.  I sort of, as a generalist specialist founder,  I'll end up doing engineering work as needed as well.  At some point, the focus will be  to make everything as professional as possible.  You know, coding and research output standardisation occurs,  they follow standard sort of templates  and standard sort of use of your code.  You build systems and engineering work  to automate things as much as possible  prior to taking the human out of the loop  when it can be done,  just to have consistent output,  even though the human in the loop is always going to be there.  Internal design patterns and coding styles  become solidified and then pushed across  all the things that you're doing.  Now, exploit reliability.  The goal is as close to 100% reliable as possible.  In reality, this is the goal,  but in some cases it just can't be achieved.  In general, it's not desirable to have  a long run time in your exploit.  So if you have a reference count overflow  that takes four hours to trigger,  and the compiler core is spec'd at 100% CPU,  it's not considered practical for most people.  For many people, in fact.  In hobbyist approaches, ROP is seen  as a reasonable exploitation strategy as well.  And ROP is not a good strategy generally.  Sometimes that's all you can do.  So you do end up supporting these ROP chains.  It's sort of considered quick and dirty  to build a ROP chain, in fact.  But if you do that,  your exploit now is version specific.  You have to maintain ROP chains,  and the maintenance burden becomes quite significant.  Infrastructure you need.  We work on-prem.  You will need infrastructure.  Your network on your premises  will be vastly more complex  than is reasonable from a comparable-sized company.  You'll have on-planes  and various other types of networks.  And you need infrastructure people.  Good infrastructure people  can be somewhat challenging to hire.  And the thing is,  you need people that are very seeking  to understand your setup and requirements.  But VR companies generally aren't telco-grade,  work on telco-sized networks internally.  So the work, from an infrastructure perspective,  is interesting to work in a VR company.  It's not classically desirable by infrastructure people.  For me, and InfoSec in general,  my co-founder is a very senior infrastructure specialist  and was able to sort of cross that bridge quite well.  But for many other people,  I imagine building infrastructure  has its own set of complexities.  And if one of your domains is embedded, for example,  at InfoSec, we do hardware,  then your lab is going to be a significant cost as well.  We have an RFC library.  We have an X-ray machine,  rework stations and so forth.  All of these things are quite complex to manage  and complex to build.  And even just moving an X-ray machine,  you have to get forklift licenses.  All of these things add complexity.  Now, is there a technical glass ceiling to VR?  And I would say that many traditional jobs  do have essentially a ceiling  in terms of what you can do,  in terms of career progression.  It's true really regardless of what people advertise  on the brochures.  Certainly true in Australia.  Many techs reach their top level  in their area of expertise.  Their salary effectively maxes out  and the work they do becomes more routine.  And then they struggle to decide  if they want to transition to a non-technical role  for more impact.  So that's sort of the question,  you want to be an individual contributor  and have sort of impact,  or you want more impact by managing a team of techs now  and knowing that as a tech,  your salary is going to max out  and you're not going to be able to influence a company as much.  So this same is true even in academic research.  I've had a few years in academia.  Senior professors tend to see impact  by becoming more administrative and supervisory in nature.  So you see the same sort of things in that as well.  In VR, these things I don't think are the case.  It's simply not the case at all.  The more you learn, the deeper you go,  the more success you achieve.  Proportionally, the higher your salary and your bonuses become,  and really it's sort of a limited amount of depth  in knowing these targets  and being successful at finding both of them.  Is VR worth the hype?  Is it a good job?  I will say yes.  It's certainly the best job I've ever had  as a service in my technical career,  and it's not just because I am a founder.  It is the most technically challenging career I've experienced  in my odd 30 years of working.  I do have an amazing team that I work with,  and I do think we do certainly amazing stuff.  So that sort of brings me to the end of the presentation.  There's lots of things about running a company.  This sort of turned into a start-up talk as well,  how do you sort of build a start-up,  have that culture, hiring people and so forth.  But it's similar in a VR company as well.  That's that specialisation.  I've seen exploits referred to as modern-day magic,  and I do think it is an apt description.  That's it for me.  I'll take any questions.  Thank you, Dr. Sridhar.  Very insightful talk.  Just to check, yes, we do have a first question.  I'm coming.  Thanks.  Why is it that so many EEs end up getting into VR?  I think I like the engineers.  Yeah, the engineers, yeah.  Embedded has become more popular than it used to be, I suppose.  I mean, go back 10 or 15 years ago,  and embedded wasn't really a thing in society.  And now IoT, embedded, even OT,  is so integral into the world that we live in  that we want to look at them.  And so where do you hire people that look at embedded?  Well, I talked about on the slide,  we might hire forensics people to do it.  We might hire electronics or engineers  that look at hardware.  So I think it's sort of a pretty nice fit for IoT embedded.  There's probably a lot of people  that just go into software as well  just because they like the challenge.  But from our perspective, as we hire,  we will certainly say yes to good engineers  that can get firmware off devices,  get serial interfaces, JK and so forth.  So I think that roughly answers your question.  Thank you.  Question?  Thank you for the talk.  You mentioned that it's very important  to have consistent output.  Do you ever see, from your perspective,  you don't know when your researchers  will be able to find something,  but you have to constantly be producing output.  And do you see that time frame or the uncertainty?  How do you manage that uncertainty in your case?  That's a great question.  So it can be perceived as like  there's no output by a researcher  except the research output itself,  which is a bug or an exploit.  And I really disagree strongly with that idea  that research is this completely black box  and that at random point you just have some spike  and then it gets back to zero.  I can see in our team, like every day,  if you're finding new attack surface,  if you're auditing new code,  then you should document that.  And so you can start to see  that they are making progress in their targets.  And you sort of have a pretty good idea  because of this sort of every day  documenting what is being done.  You sort of have a pretty good intuition  whether it's like any day now,  I'm pretty sure something's going to be found.  And most of the time it's pretty accurate.  You can't predict that research output,  the good research output will come  because they've done all the work up to that point.  They remember that maybe they built a buzzer.  They found some sort of secret attack surface  that no one knows about.  They found this weak API system.  They found that the programmers are sloppy  in all their testing of certain cases and so forth.  There's instructions that the developers don't know  that we've identified.  All of those things are sort of  an important part of research,  but not the research output itself.  It's more like an internally focused output  so that for your peers and your bosses as a researcher  versus the customers who will just  prefer the research output itself.  But I do think it's not as completely opaque  the idea that you will be successful in research.  You generally know when someone is not going to be  successful in research because  often you'll see this idea of like  I'll just hop from idea to idea,  never go deep in one area.  And you say well actually you're just  sort of slightly on the same spot.  You need to sort of stop going and  hopping to the next thing that you're looking at  and just go deeper into the thing that you're looking at.  So depth is a pretty good indicator  that you'll be successful as well.  So the deeper you go in some subsystem,  the more likely you are to have a result.  If you have a research that's like  surface level, looks at a subsystem,  says oh it's actually getting really hard  to follow all this and I'll just jump to the next thing.  Well you're never actually going to be successful.  So I think that's from my experience at least.  Thank you.  Any other questions?  We do have time for, okay.  I'd like to take a question  in more kind of business perspective.  As a CEO of your company,  I speculate that  the companies that  manufacture the target  you research on should pay  for your vulnerability or  I think that the business  of that work in a way so  please give me any  episodes or cases that  the company,  the target company doesn't want  to pay for the vulnerability you found but  also  didn't want to publish  the vulnerability that you found.  I think I want to take the American  Hollywood TV legal angle and  say I plead the fifth.  I mean that's a great  question but really  I'm under NDAs and agreements with  all my customers so I can't really go too much  into depth on any of that but  great question though and certainly  I mean the disclosure debate,  if there's one thing that's persistent about the cyber security  industry is that every five years  someone solves disclosure  and then also password complexity.  It's just like passwords get longer  every five years because a big rant about  it becomes a mainstream media issue so  I would say I don't expect the  disclosure debate to be solved  in my lifetime but it will  be solved periodically by random people,  random new people every five years  so I enjoy the rest of my  career where the disclosure debate  is constantly being re-examined.  Thank you.  Hi,  good morning. Thank you for your talk. It's a good  oversight of the industry from a founder's point of view.  A quick question,  in your experience,  how easy is it to keep  key talent, key researchers  I mean because they just hop over  to another company that pays more.  Is cultured unity keeping  your guys intact, keeping your team intact?  That's a great question.  I think a lot of people have thought about  this problem and I would say  from my perspective  there's  not that many offensive security  companies out there and  you want basically the talent to stay  in the offensive industry  and not take terrible jobs  that oppose that.  So I mean how do you maintain  staff? I mean it's classic sort of  start-up things here. So how do you have  staff retention? Well, pay them what they're worth,  give them a good culture,  have people that  they can talk to  and all of those things. So I wouldn't say  we're uniquely unique as  staff retention in broader  cybersecurity. I mean it's still hard. I would just say that  it's not  a terrible thing to have sort of  staff move from company to company so long as they  don't take terrible jobs that oppose  that.  So in your experience with  interns or hires  from universities, how much  do you think that whatever they learnt  let's say in IT  or cybersecurity in the universities,  how applicable is it to  the actual work or do they have to really unlearn  a lot of the things that educators have to  do there? I've got a lot of  views on interns and juniors but  one thing, for example, we've had a lot  of remote  people at university in some other city  in our country say, I want to be an intern.  You do really good work,  that they see sort of thing, I'd like to be an intern.  And in our experience, remote juniors  or remote interns in vulnerability  research, a terrible idea. I mean  it's hard enough in a normal company to be a  remote intern junior  but in a vulnerability research company, the turnaround  time for feedback  of what they're doing and monitoring for what they're doing  and having a colleague next to them say  do this or do that, it's  all practically impossible.  So in that perspective, about  juniors and interns, I would say you can't  really hire them remote and so that  means that you get them from sort of your, they either  relocate to you or you  get sort of a local university or  something like that.  I would say that we  in our university that we have in Australia  we often do, as a company  a guest lecture to the  software security  course that they  have. And we basically talk about  things like keep exploitation. And then we sort of  say, well if you like this type of stuff  maybe apply as an intern to work for  us. And that worked out pretty well.  All the content that we do is  memory corruption and stuff  like that, so they have a pretty good idea.  Then we go through the normal process of talking  to them, understanding where they are  and if they're good at this type of work.  Another good thing about an internship is  it's prior before you buy  from an employer perspective. So if  they do a six month internship or a three  month internship and they're terrible  then they just don't become a  full time grad. That's pretty much  you know, it also gives them the opportunity  to say actually I don't really want  to do this type of work, I want to do something else.  Now you can't really give  interns or part-timers  in that sense good work.  And that's another sort of thing to manage  as well because generally you don't want to give good work  to people that are sort of transient  and might leave in  a few months time.  And so there is that challenge.  So again these are all challenges that  many other start-ups have but  the big challenge  as we are is that remote interns are  generally, that they will have a terrible  experience, they come across, they will see your  company is not really doing  anything useful for them because you can't really  give them good work, it's hard to get feedback and so forth.  So don't fire remote interns, it's quite  awkward.  Is there an age limit  to VR?  I mean there's a lot of  old school hackers that are sort of getting  older now will be like  actually a lot of my colleagues that were  sort of technical on tools  from years ago are now managers  and site leaders and all that type of stuff.  I'm still a diehard, I still have my  best experiences behind a keyboard  bashing away, reading  code and stuff like that so  I'd say that there's definitely a drop-off as you get older  for people to move into sort of the  not on the tools  side of things but I mean  at our company for example we have a mix of people  we have a bunch of sort of  you know sort of a younger  crowd, we have people with families and stuff like that  that are all technical  so I'd say it's a great job for older people  but I mean statistically I'm pretty  sure that a lot of my peers from  10 or 15 years ago aren't  as much on the tools as I'd like to be  today.  There's nothing that I prefer than just  reading code and writing  code and stuff like that.  Any other  questions? We still have about 10 minutes  if not  oh we do, okay.  Hi, given VR  applies to anything with a marketable  code, which areas do you think  needs the most people  to be on and why?  I mean managing  like if you're  if you need a full chain of anything  it's pretty hard for one person to be across all that  so the more components in a chain  probably has some sort of proportion  proportionality to how many team members  are needed to support that and depending on how much testing  you're doing as well you might need bigger teams as well  so I'd say more complexity  more targets, more components  in a target probably is proportional to the  number of staff that you have.  I'd like to exploit my  MC capacity to also ask  a question. So  where do you see  invulnerability research is  a skill gap or skill shortage in  general, that if there are  existing or aspiring VR  practitioners, if they want to  prepare for and address the skill gap  what would it be?  So for sure most people coming through university  today, like writing in C  isn't the  language that they normally learn to do  computer science. But then you see  these emergent communities, like the C camp  community is really good  and pwning an artery is  pretty good to do that  type of stuff. So I would say that in some parts  of universities the pipeline  isn't sort of,  the pipeline doesn't favour native  code, native languages  that type of stuff. But then you see  most universities now will have C  camp groups that do this type of  binary exploitation. So maybe  it's good, maybe it's bad. I don't know exactly how  to encourage more  juniors to get into the industry  but we do internships, we do  guest lectures, stuff like that  so I think it's a cool industry  hopefully other people come along  that pipeline as well.  Thank you.  Any last  questions?  Yes.  What's the most exotic target  you've overcome that you can talk about?  I don't know,  good question, maybe something to talk about  afterwards but very  I think that's the end of your answer, right?  Okay, got it.  If not,  I think we've asked  Doctor quite a bit so we want to  put our hands together again to thank him  and his generous service.