{
  "webpage_url": "https://www.youtube.com/watch?v=cDcMlMH-XjU",
  "title": "Off-By-One 2024 Day 2 - Love and hate - The cyber tale between fuzzer and exploits in Linux kernel",
  "description": "Abstract\n\nContinuous fuzzing has become an integral part of the Linux kernel ecosystem, discovering thousands of bugs over the past few years. Interestingly, only a tiny fraction of them were turned into real-world exploits that target downstream distributions, e.g., Ubuntu and Fedora. This contradicts the conclusions of existing exploitability assessment tools, which classify hundreds of those bugs as high-risk, implying a high likelihood of exploitability.\n\nOur study aims to understand the gap and bridge it. Through our investigation, we realize that the current exploitability assessment tools exclusively test bug exploitability on the upstream Linux, which is for development only; in fact, we find many of them fail to reproduce directly in downstreams.\n\nThrough a large-scale measurement study of 230 bugs on 43 distros (8,032 bug/distro pairs), we find that each distro only reproduces 19.1% of bugs on average by running the upstream PoCs as root user, and 0.9% without root.\n\nRemarkably, both numbers can be significantly improved by 61% and 1300% times respectively through appropriate PoC adaptations, necessitated by environment differences.\n\nSpeaker\nZou Xiaochen is a Ph.D. candidate at University of California, Riverside, advised by Professor Zhiyun Qian. Xiaochen earned his bachelor degree from University of Electronic Science and Technology of China.\n\nFollow Xiaochen on X @ ETenal7",
  "channel_url": "https://www.youtube.com/channel/UCmrsIbKdxEMBEefD8v8RigQ",
  "duration": 2162,
  "channel": "Off-By-One Comms Team",
  "uploader": "Off-By-One Comms Team",
  "upload_date": "20240901"
}

This text was transcribed using whisper model: large-v2

 Hello everyone, good morning or afternoon.  I don't know what time is it in Singapore right now.  I hope you have enjoyed the weather and the food.  I really wish I could be there to watch all your talk and have great conversation with  you guys.  But due to the visa issue, I am not allowed – like, I am allowed to leave U.S., but  I don't want to risk my visa to leave the U.S.  That's why I give this video talk, and I'll have a live Q&A afterwards, I guess.  So my name is Xiaochen Zhou, I'm a senior year PhD student at UC Riverside.  Today I'll present my recent work about Linux kernel bug exploitability assessment.  I call it Love and Hate, the cyber tale between father and exploits in Linux kernel.  This work has done by me and Professor Jun Qian.  Yeah, let's get to our – bugs are errors that cause computer program to behave unexpectedly.  Most of the time the normal behavior only cause minor issues, or sometimes we don't  even notice.  However, some bugs are much more severe.  So one day people realize this severe behavior could lead to a total compromise of the application.  We call it exploits.  And for all these bugs that can lead to exploits, we call it exploitable bugs.  Now all these years, security researchers have developed different ways to discover  exploitable bugs.  So in the beginning, we start with manual code auditing.  We read hundreds of thousands of lines of code with our bare eyes to just find one tiny  variable misuse or missing log.  I really admire those people who can do the manual auditing, and they're the hero of cybersecurity.  Well, in later stage, people find manual auditing is low-efficient, so they build program to  find bugs.  Because we have two automated solutions for bug hunting, dynamic way, aka fuzzing, and  static analysis, the static way.  But with the decades-long iteration, some software become shockingly huge.  For example, Linux kernel source code contains 28 million lines of code and countless indirect  call and global cross-reference and dependencies.  That creates plenty of problem to manual auditing and static analysis.  However, by the nature of a dynamic approach, fuzzing won the competition with unbeatable  efficiencies and the lowest false negative rate.  But one problem with fuzzing is the blindness, which means we have less control during the  fuzzing process.  Randomness seeds are generated, and test cases are guided by coverage feedback.  All these undeterminable factors add up to the blindness.  So sometimes, we may find a lot of bugs.  We find a lot of bugs, but none of them are security bugs.  And less security bugs means less exploits.  So this suspicious gap between the fuzzing-exposed bugs and the real-world exploits is what we  want to discuss in this talk.  But can we make more fuzzing-exposed bugs to be exploitable?  So the first question is, is Linux kernel really safe?  Here is an excellent Linux kernel security channel on Telegram.  They collect every Linux kernel exploit write-up that we can find online.  And here are samples of kernel exploits from 2033 to 2024.  That's like 10 to 20 exploits every year.  Like 20, 10-ish, 20-ish exploits sounds like a reasonable amount.  But if I tell you how many Linux kernel bugs out there, you will be shocked.  So let's introduce Sysbot.  So Sysbot is a fuzzing platform developed by Google.  It deploys Google kernel fuzzer, syscaller, to fuzz Linux kernel 24 hours a day and seven  days a week.  The Sysbot is so powerful, it funds so many bugs that even overwhelm the kernel developers.  So they don't have enough time and resources and people to fix all these two to three new  bugs every day that are found by Sysbot.  In the past six years, Sysbot has found more than 10,000 kernel bugs.  And up to now, there's still a thousand bugs that are not fixed by Sysbot.  Well, not fixed by the developer.  They were found by Sysbot.  So if you look at this graph, this graph, the red line is the new bugs, open bugs.  And the green line is the fixed bugs.  So you will notice there's a gap between the green line and the red line.  That means the bugs is unfixed.  And this gap expanding every year.  In March 2003, the gap has become 6,000 bugs, that means 6,000 bugs has not been fixed at  that point.  Well, this gap has been snubbed back due to multiple reasons, like after the code iterations,  so some bug may be silently fixed or become invalid.  Despite the huge number of unfixed bugs, thousands of them, why we didn't see a clear spike of  kernel exploits in the past few years, still only 10 to 20 exploits in the past every year?  Well, so our current situation is like this picture.  We have a significant amount of kernel bugs, but we have only so little exploits.  Why did that happen?  To answer this question with confidence, we need to learn some background knowledge of  fuzzing and of Linux kernel.  The fuzzing pros and cons.  The syscaller is so efficient, it generates hundreds of valid test cases per second.  I say valid test cases, that means syscaller knows the many kernel dependencies according  to the manual graph database.  So on the left-hand side, this picture is what we call description.  This describes the kernel dependencies to the syscaller.  The syscaller will understand this.  For example, this simple program, the socket will return a file descriptor, and this file  descriptor will be used by other system calls.  This is one typical dependency.  Because syscaller knows this dependency, it can generate the valid test case very fast  and find the bug with efficiency.  For example, in order to find the bug hiding here, deep down in the kernel space, syscaller  will call different system calls in a sequence, and each system call will make the kernel  enter a specific state that's a dependency.  So calling system call 1 will enter a kernel state, and calling system call 2, because  the kernel is set to write state, we can go to state 2, and call the final system call  will trigger the bugs.  And more importantly, the dynamic approach fuzzing, it generates a concrete test case  after finding a bug.  So we will have a concrete POC that can actually trigger the bug.  Neither static analysis or manual auditing can do this job.  So fuzzing is so efficient, but it's blind.  It generates test case based on randomness, which means it does not do any favor of finding  security bugs.  Actually, finding bugs is fuzzing all care about, regardless if they are security or  not.  And even worse, in order to find more bugs, kernel fuzzers are developed by good privilege,  are deployed by root privilege.  This equips fuzzer with better chance to explore bigger code space in kernel, without worrying  being rejected by the privilege problem.  However, as security researcher, if a bug has to be root to trigger, we're not interested,  because they are not exploitable bugs.  They request root, what's the value we exploit them.  But okay, we've been talking to these two major problems about fuzzing, but even with  all these flaws and problems, C-Spot is still very efficient and still managed to find a  significant amount of security bugs in the past six years.  So 24.1% bugs found by C-Spot are memory errors.  And memory errors like use-after-free or auto-bound and double-free, they are memory errors.  And among these memory error bugs, 18.2% are likely exploitable bugs.  So we are talking about use-after-free write, auto-bound write, and double-free.  So they are the most common exploitable bugs that are on the market.  That gives us 232 likely exploitable bugs.  Well, that's actually a very big number, considering we only have so little exploits every year.  And another research, actually my previous research that published in Usenix Security 2022,  we assessed the bug capability, and we realized the bug initial capability does not represent  the most critical capability.  So that means a lot of low-risk bugs, like memory read bugs or warning or other low-risk bugs,  they can be converted to high-risk bugs.  So they contain the high-risk capability.  The number can only be more than 232 bugs that are likely exploitable.  So there are so many likely exploitable bugs, but we still find so little exploits.  So for the bugs that originated from C-SPOT, there are only around seven that I can find on the internet.  Well, there are more kernel exploits, of course, besides originating from C-SPOT,  but now we're only talking about the one big database, it's the upstream C-SPOT, upstream kernel bugs.  So there's only around seven, 232 versus seven.  That's kind of shocking.  Well, another inconspicuous factor contributing to the gap between the bugs and exploits is the structure of the Linux community.  So Linux has upstream and downstream.  Upstream kernel is where people are developing and debugging, and it's not a daily-use kernel.  But upstream kernel is ideal for bug-finding, and C-SPOT deploys its fuzzer only on upstream kernels.  So here I mentioned upstream kernels, that includes all the upstream branches,  like long-term support branches or Linux Next branches, not just the upstream kernel.  However, nobody used upstream kernel in production environment.  The stable upstream kernel branches will be pushed to downstream once in a while.  So based on those stable upstream branches, the downstream will have different distros,  and we have Ubuntu, Fedora, Debian.  Most importantly, they are stable and well-maintained,  so people are using it on a daily basis in their production environment, and that's why it got attacked.  So nobody attacks the upstream kernel because nobody is using it.  That's why people are always attacking the downstream kernel.  That causes a problem because upstream fuzzer-exposed bugs can trigger a bug on upstream kernel,  but it may not trigger the bug on downstream kernel.  But this does not mean the downstream kernel is not affected by this bug.  Their triggerability is not equal, but their POC can be adapted to downstream, making it triggerable.  So we visualize this gap between upstream fuzzer-exposed bugs and kernel exploits.  It's not just the imperfection of the bug itself.  It's a long-existing gap between the upstream and downstream.  The major difference in these two kernels causes the asymmetric number of upstream bugs and downstream exploits.  So is it possible to turn more upstream fuzzer-exposed bugs to downstream exploitable bugs?  We want more bugs, more exploits, or even like this,  we want every upstream bug to be exploitable.  Well, not quite possible, but we can think about it.  So how to make it happen?  Our first step is to understand how many upstream bugs can actually be reproduced in downstream kernel.  So we have designed an experiment.  We prepared four downstream distros, Ubuntu, Fedora, Debian, and SUSE.  Next, we gather 50 upstream kernel bugs from six bugs,  and then we run their POC against all four real-world distros.  And we choose the major release that is close to the bug discovery date.  So which means, for example, if a bug was found in September 2021,  we will choose, for example, a Ubuntu release that closes to September 2021,  which might be the June release.  By doing this, we make sure the bug always reproduces on a vulnerable version,  or the patch will not exist in the prior version because the bug was found afterward.  So 50 bugs for four distros.  We got 200 bug and distro pairs.  We found 120 pairs that failed to trigger the bug  because the distro does not have the bug you can meet.  That means the bug was never introduced.  For the rest 80 pairs that were vulnerable to the bugs,  we find only 18 of them have successfully triggered the bugs,  but all of them were triggered by root privilege.  So none of them are exploitable bugs because they require root privilege.  For the remaining 62 bugs that have failed,  we find 41 of them failed due to logic missing.  That means the vulnerability code exists in the kernel source code,  but it does not exist in the kernel binary,  most likely because they are not compiled.  This is a common case that the downstream distro  will not compile every single upstream kernel module,  even though the bug you can meet exists.  But not compiling the kernel into the binary means the same as the no bug you can meet,  is that the distro is not affected by the bug.  For the remaining, we find one pair failed due to the code context change.  That means the vulnerability logic has been completely rewritten,  and thus the old POC cannot trigger the same bug,  and 20 other pairs have failed due to what we call environment change.  The environment change will be the main topic for the following talk.  We categorize the failure reason of the environment change.  You will see their number adds up to be more than 100%  because one bug could fail due to multiple reasons.  The first failure reason of the environment change is what we call preparation failure.  One typical example is setting up the USB fuzzing.  This caller will try to open a device called rawgadget.  This rawgadget device exposes the USB interface,  so you don't need actual USB hardware to interact with the kernel USB logic.  Instead, directly interacting with this rawgadget virtual device,  it makes testing USB interface possible for the kernel fuzzing.  However, due to the blindness of kernel fuzzer,  it may find a completely irrelevant bug rather than a USB bug.  While fuzzer doesn't know that, it will still think it's a USB bug  and it will keep the USB preparation function in the POC.  However, the downstream kernel will not have this virtual interface  because you always use actual hardware USB device when you're using Ubuntu.  When the POC tried to open this rawgadget device, it failed  because this path does not exist.  Oftentimes, if a POC fails, like the preparation has failed,  they will terminate itself and exit.  That makes the POC not reaching the core POC function.  They will terminate before reaching the POC core function  and make the bug not triggered.  Another reason that upstream POC failed is because of the background noise.  In upstream kernel, there are only a few background processes running  and the POC process can easily win the data race.  If a risk can be found, it can easily win the data race and trigger the bug.  However, in downstream, there are much more services running in the background,  so the chance of the POC process can win a data race is much lower  than in the upstream kernel.  For example, we have SSH, we have APT, we have some desktop environment processes.  If this kind of find, the minimal resource can trigger a bug in upstream,  it will generate the POC, only use that minimal resources.  We are talking about the number of CPU cores, number of iterations and processes.  Sometimes the upstream can even trigger a risk condition bug with only one attempt.  At that point, SysConnect will even not think it's a risk condition,  but think it's just a normal bug and generate POC according to that.  And the same POC likely failed on downstream.  The third further reason, I always take 50% of the case, is the missing module.  For further inconvenience, the kernel modules are always compiled into the kernel binary,  versus downstream distro often compile them as separate loadable modules.  Therefore, the upstream kernel have every module ready to use.  In this case, a valid case can always successfully interact with the desired module and trigger the bug.  However, downstream kernel, choose another way, they compile such module but not load it by default.  You have to load it yourself as needed on demand.  If the desired module is missing, the kernel will choose either return an error,  or choose a default module to perform the operation.  And because it's not doing anything to the vulnerable module, the same POC will fail to trigger the bug.  So to overcome these three problems, we came up with three automated solutions.  For the preparation failure, we minimized the environment preparation steps to rule out the unnecessary steps.  So if a POC can still trigger the bugs in upstream without these preparation steps,  we think they are unnecessary steps, so we will rule out the unnecessary steps to only retain the necessary steps.  And after removing the unnecessary preparation function, we can successfully reach the POC core function and trigger the bug.  The second solution for the background noise is, well, the upstream kernel is the minimum kernel,  and it has so little services running in the background, and it's very easy to win the data race, as we already know.  And here, this is the resources for the data race.  So the POC process can easily win the resources and trigger the bug.  But the same POC on downstream is very different.  There's more processes competing the same resources,  so you will often find the POC function fail to win the data race with other processes.  So our solution is we force the data collision.  That means more CPU cores and infinite for loop and longer execution time.  By doing that, you will find your POC process eventually win the data race and trigger the bug.  Okay, for the third problem, the missing module.  To find the missing module, we use ftrace to extract the execution trace from both upstream and downstream.  Then we compare the execution trace to find the deviation point.  In this example, we notice the deviation point start at node 3, where the upstream called xfrm since they notify,  while the ubuntu called another function.  This caused the ubuntu fail to trigger the bug.  But in order to trigger the bug in ubuntu, we need to first load the xfrm user module.  Well, this module already compiled in the upstream kernel, so only ubuntu need to load this module.  And a common way to load module is through mode probe.  And that is the privileged operation, which means you have to be root user to load the module through mode probe.  But we find a way to load this module by unprivileged user, which we will talk about later.  If you still remember, all these previously triggered bugs were all triggered by root user.  So we are thinking, is there a way to make them triggerable by unprivileged user?  There are several privileged checks.  One is the capability check is well known.  And the privileged downgrade technique is also well known.  So kernel uses this capability to provide fine-grained control over the large code space.  The low-level kernel function ns cable common checks the process capability.  So the ns is the namespace, and the cap is the capability.  For example, this code snippet checks if the current process namespace has the capability cap net admin.  Luckily, this capability can be granted in user namespace by unprivileged user when the unprivileged user ns clone is set to 1.  But most distros, like 1, 2, Fedora, Debian, Suse, they all allow unprivileged user namespace.  So this is doable. It can be granted by normal unprivileged user.  However, not every capability can be granted by user namespace.  If a capability checks the initial namespace instead of the user namespace, a normal user cannot get such capability.  Only a real root user can do that.  So we monitor this low-level kernel function to know if POC requires a real root capability or user namespace capability.  If it only requires a user namespace capability, we will grant them to the POC.  Another privileged requirement is the module loading.  As mentioned earlier, the universal way to load a module is through mode probe.  Mode probe invokes the system called initial module.  And the initial module checks whether the process has the cap system module capability.  Unfortunately, this capability, this function checks the initial namespace.  That means only root user can call mode probe and unprivileged user cannot have such capability.  That's why the mode probe can only be run by root privilege.  But we find another interesting kernel function called request module.  And we find plenty of request module call sites across the whole Linux kernel.  And some of these call sites even have a format string to pass the module, to pass the minor number to the actual module name.  So you will see there are different number indicates different network modules.  So one request module call site can load multiple module.  To understand how request module load a module, we look at the source code.  And we find it first get the mode probe user space pass.  And then they get the final module name from the format string.  And the module name will be passed to the call mode probe function.  Well, from that name, you already guess what this function does.  The call module name will prepare the arguments.  The first argument is the pass.  And then we have the module name over here.  And then they do an op call to user space.  So this op call will, interestingly, this op call will be executed as root.  They will call the mode probe by root user.  So we have a new concept of how to load a module.  An unprivileged user somehow call a request module kernel function through some system calls.  And this function proceeds an op call to user space and root user.  This root user executes the mode probe to load the dedicated kernel module for us.  So we are actually asking a root user to load module for us.  Like very cool. That's very cool.  So instead of calling mode probe XFRM user to load a module, which requires root privilege, by the way,  we can simply call this system call with unprivileged user.  So that makes our unprivileged user very happy, you can see.  And that's just one example.  But we want to know how many, like what is the module that can be loaded by unprivileged user  and what module cannot.  By simply searching the request module, we find there is 249 call sites across the kernel source code.  And a lot of them, they are format string.  That means one call site can load multiple kernel modules.  So we're thinking, well, is there a possible we can load arbitrary module,  like we get a module name directly from user space  and we pass this argument directly to the request module.  By doing that, we can load arbitrary modules.  So we don't need root privilege to load even like very critical module.  But the kernel developer found that stupid.  So we couldn't do that.  We didn't find anything like that.  So we have to collect or categorize every single request module site and their loadable module.  But this problem is very exhausting, but by the nature of the problem,  that makes us thinking about the only effective approach, which is fuzzing.  Although we have been talking down about fuzzing all along,  but nothing can do the same job as providing concrete test case and invoking kernel call sites,  only fuzzing can do that.  So we build our customized request module fuzzer.  We intentionally instrument the request module function to notify the fuzzer  and we reproduce the results by unprivileged user to make sure that the normal user can load such module.  Our fuzzing results turn out to be very good.  We find hundreds of normal user loadable modules across all four distros.  The number has the network has the most module.  Well, this is a sample of the modules and that's not all of them.  And next is the crypto.  And then we have file system.  Please note that loading a file system module by normal user does not essentially mean you can mount the file system by normal user.  So mounting is another privilege operation that only a few file system can be mounted by normal user,  like fuse or overlay FS.  And it's time to do some number crunching.  We prepare 282 likely exploitable blocks that contain at least one of the following high-risk primitive used after free write,  out-of-bound write, double free, counterflow hijacking, arbitrary address write and constrained address write,  arbitrary value write and constrained value write.  So they are all high-risk capability and make the bug to be likely exploitable bugs.  So without any adaptation by running the original POC as root privilege,  we want to see how many bugs can be triggered on the downstream kernel.  On average, 44 out of 282 can be triggered.  And that's 15.6 percent.  Ubuntu 54, Fedora 48, Debian 47, Suse 27.  Then we applied our automated adaptation to all the 282 POCs.  And we increased the number by a lot.  And now, by average, we have 73 out of 282 bugs.  That's 25.8 percent.  We improved the result on average 65.9 more.  We do the triggerability test by root privilege.  But because they are likely exploitable bugs, we want to know how many of them are actually likely exploitable on downstream.  So we have to run the POC again by normal user, by unprivileged user.  So now we do it again by running them with unprivileged user.  The result is very bad.  Only 1331 bugs can be triggered on Ubuntu, Fedora, Debian, Suse.  That's on average 0.7 percent.  Well, we have this question why there's so little exploitable bugs on so many bug databases, so big bug databases.  This result somehow proves that's why there's so little sysbug bugs were turned into real world exploits.  However, after applying our privileged adaptation, we dramatically increased the number of normal user triggerable bugs.  So for Ubuntu, we increased the number from 1 to 35, Fedora from 3 to 50, Debian from 3 to 31, and Suse from 1 to 9.  Well, on average, 31 out of 282 bugs, that's 25.8 percent.  We improved the results by 14 times.  Note that these bugs are all likely exploitable bugs.  Comparing the past, there's only 7 bugs were turned into real world exploits.  The bugs from sysbug, only 7.  To prove the effectiveness of our tool, we picked one unfixed bug at a time for our results.  And we successfully developed n to n exploits to escalate the local privilege on the latest Ubuntu.  And we plan to use that exploit, participate in the Pontoon event here.  But unfortunately, the bug was tragically fixed one month before Pontoon.  Well, so we didn't get a chance to participate, but at least the exploits proves the effectiveness of our adaptation method.  So here are three case studies that we find interesting.  Well, their original POC cannot trigger the bugs on any downstream.  Bug 1 requires additional module.  Except if I'm a user, we talk multiple times, you can use this simple system call to load such module and then you can trigger the bug.  The bug 2 requires RDMA UCM module.  Loading this module is a bit complicated.  You need two system calls and a well-prepared data structure.  After you run this program to load the module, you can trigger the bug.  Well, bug 3 is even more complicated.  It loads IPv6 tables, which require a sophisticated data structure.  And this module uses alias in the request module, not the IPv6 table name.  This alias is ICMP6.  You have to use that alias, but our father managed to find a concrete POC to load that module.  And after loading that module, we can trigger the bug.  So the key takeaway from this talk, upstream and downstream have different environments.  And fuzzing is efficient on upstream kernel.  And fuzzing neglects the privilege and environment factors.  And the fuzzer-generated POC often failed on real-world OS.  But real-world OS may still be affected.  And don't give up.  Remove unnecessary preparation steps.  And allocate more resources to the POC.  Finding missing kernel modules.  And the privilege requirement can be downgraded.  Check whether the namespace can bypass the capability.  And if there's any missing modules, check whether they can be loaded by unprivileged users.  Because the unprivileged user is capable of loading hundreds of kernel modules.  I think that's everything about my talk.  And you can access my portfolio by scanning this QR code.  I also have my CV.  Also, I'm in the job market in 2025.  I will be graduating soon.  I'm looking for a security-related job.  Well, I think I'll have a live Q&A somewhere here.  I'm ready to take questions.