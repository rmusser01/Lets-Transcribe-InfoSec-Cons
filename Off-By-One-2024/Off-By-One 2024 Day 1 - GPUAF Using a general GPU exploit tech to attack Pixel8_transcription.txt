{
  "webpage_url": "https://www.youtube.com/watch?v=Mw6iCqjOV9Q",
  "title": "Off-By-One 2024 Day 1 -  GPUAF   Using a general GPU exploit tech to attack Pixel8",
  "description": "Abstract\n\nLast year, we developed an advanced exploit technique capable of transforming a conventional out-of-bounds (OOB) bug into a more potent exploit primitive, specifically a page Use-After-Free (UAF). Utilizing this technique, we successfully exploited a vulnerability in the Pixel series, achieving Kernel Code Execution.\n\nThis presentation will commence with a thorough examination of the component where we identified eight vulnerabilities, all of which were patched this year. We will delve into the root causes of these vulnerabilities.\n\nSubsequently, we will demonstrate how we applied our exploit technique to convert one of these bugs into a Page UAF (PUAF), and subsequently construct a physical memory read/write primitive on a Pixel 8 with Memory Tagging Extension (MTE) enabled.\n\nFurthermore, this talk will address the challenges we encountered during the development of this exploit, highlighting the differences in exploitation techniques between the Pixel 6 and Pixel 8 models.\n\nSpeakers\nPan Zhenpeng (@peterpan980927) is a mobile security researcher at STAR LABS SG, focusing on Mobile(iOS/Android) and Web security, he was the speaker of Zer0Con, POC, OffensiveCon, 0x41Con and HITB Armory.\n\nJheng Bing Jhong (@st424204) is a security researcher at STAR LABS SG, focusing on Linux, VM and mobile security.",
  "channel_url": "https://www.youtube.com/channel/UCmrsIbKdxEMBEefD8v8RigQ",
  "duration": 2138,
  "channel": "Off-By-One Comms Team",
  "uploader": "Off-By-One Comms Team",
  "upload_date": "20240831"
}

This text was transcribed using whisper model: large-v2

 Today, everyone, today we will research into a top-level GPU exploit technique to target  the PSoS kernel.  GPU-UoF, short for GPU-Patch-Level-Use-Factor-Free, represents an approach to exploit vulnerability  within the PSoS kernel.  In this presentation, we show that how GPU can exploit from a limited vulnerability,  transform into a full and complete exploit.  Hi, I'm Billy, currently working at Star Labs.  I am focused on the Linux kernel and Android kernel.  Hi, everyone, I'm Peter, currently working at Star Labs.  I'm focusing on iOS and Android kernel.  Today, we will focus on two areas, ARP analysis and GPU-UoF exploit.  In this introduction, we will briefly discuss how modern Android kernel can protect the  attacker from a privileged escalation.  First, we will examine the recent ARP report, their root cause and demand, and the patch  to enhance the system security.  Next, we will explore the GPU-UoF exploit, understand its mechanism, the vulnerability  exploit, and how we can get rid of the lost modern protection.  Finally, in the conclusion, we will summarize our thoughts and their implementation on our technology.  Our research focuses on Android 14 with Linux kernel 5.10 and up.  Privileged access network and privileged execution network protect kernel space to intentionally  access and execute from the user space.  UAO uses SS override against the common address limit override.  PSE is a security feature that addresses and encrypts calls to the pointer to verify their  security and prevent control for hijacking attacks.  MTE is a hardware-based security feature that adds memory tags to each data wall to detect  and mitigate memory-safe vulnerabilities such as buffer flow, overflow, and UAF errors.  KSALR is a security technique that recognizes the location of the kernel memory to prevent  memory-based attacks, making it harder for the attacker to predict the memory layout  of the kernel.  Configure initial stack or rerun to initialize everything on the stack with a rerun variable.  Configure initial allocative OR to initialize everything on the heap with a rerun.  Configure debug list to check the linked list activity.  Select free list random, then pick a patch from the free list to prevent easily heap  overflow, and some other independent mitigations that Samsung cannot anticipate.  UAO is a notable mitigation for the address limit issue involving overriding unprivileged  load, store, and instruction, typically used in a function like copy from user and copy  to user, when in the kernel DS.  Before the introduction of the UAO, operations like the run to the kernel buffer followed  by the read to the user spec will function normally.  However, with UAO enabled, this scenario will change.  Run to the kernel buffer is unaffected, but read from the user spec will trigger a fault  due to the privileged access scenario.  MTE memory tag extension has support in the KSAL app, represents one of the most powerful  mitigations available against memory-based attacks.  By running the setProperty command, user can enable MTE.  Many blocks have been mentioned already, such as MTE execution.  Essentially, MTE function is a hardware-supported sanitizer, capable to detect and mitigate  memory-safe vulnerability.  Even in the event of a fault during the check, MTE will cause the kernel to crash, but the  target process will be killed.  This configure is a way to enhance security in more presentable use of virtual addresses  for the cache or ROM.  Similar to the ROM BA sequencer feature found in iOS and macOS, this approach ensures that  the virtual addresses are pinned to the special cache or ROM region, with the physical memory  only recycled during the compilation process.  Implementation of this feature will significantly mitigate the risk of the fault cache or ROM  exploit.  Secondly, it is worth noting that this feature has not yet been introduced on the Android  platform.  This configure is to introduce multiple general-use cache for each size.  Similar to the KMLK type found on iOS and macOS, KMLK updates by the KMLK to one of  the multiple caches.  This approach reduces the success rate of the hit-or-run bugs.  Specifically, enhance the security.  This feature has not yet been enabled on the Android platform.  Cannot detect a physical cache, and enhanced SES networks could be a major security mitigation  in the Android ecosystem.  KNOW-ELO2, performed at a high-hypervisor level, provides a security-execution environment  while defending only a long-run-to-do operation in the file list.  Physical cache, as well, redundantizes the physical memory layout against memory-based  attacks.  Additionally, enhanced SES networks that use more restricted policies or disable kernel  configurations.  SES networks deliver, make kernels always enforced and could not be disabled.  Many researches have uncovered exploit privileges within the kernel mainstream, particularly  targeting the vulnerability such as write-on-the-read-only-page bugs.  Violations liberate structures like a structure buffer in a 30-page attack, or spring user  control data into the kernel structure, including the type data page, SK-bundled data and AIO  page.  Additionally, there is a considered interest in exploiting vulnerability alone or obstructing  physical rewrites by compromising the page table.  There is also an introduced target amount research in target GPU bugs.  However, it is necessary to consider whether the GPU can be exploited by the bug or literally  outside of the GPU itself.  A large GPU vulnerability used in the wild has been detected by the corporeal link as  shown in the picture.  Let's start at the bug analysis.  We recently do research into the bug hunting, a hardware device used by the Kerala subsystem  user for a certain purpose.  This device, accessed through the device LWIS by a system user with Kerala health contents,  has been associated with the page table highlighted in the resource security printing.  We decided to give it a shot since we are new to the Android.  Here is how we uncovered.  During our bug hunting, we discovered a denial-of-service vulnerability residing in the LWIS IOControlHandle  command packing function.  This vulnerability arises from the usage of the file loop to copy IOControlMessaging links  from the user's back.  Such an implementation leaves the system vulnerability to explode, potentially leading to the DOS  attack.  By manipulating and using the linked list to point to the expel, the attack can trigger  a dead loop, resulting in a system-free and unresponsive state.  We have identified another bug named IntegerOverflowVulnerability, which is a prepareResponseLock function.  This vulnerability occurs when calculating to see if the maximum value of the integer  can be represented.  Where the TransactionResponseBuffer was allocated based on the overflow response size value.  LWIS process transaction in the queue is invoked by another kernel thread, leading to the call  to process IO entries, which triggers an outbound SS issue.  To address this vulnerability, the patch involves incrementing a check step to check the read  buffer size before allocating memory for the read buffer type.  Verify the read buffer size before allocating, the patch presents a potential integer overflow  or outbound SS.  An outbound SS vulnerability within the LWIS InitializedTransactionBase function.  This vulnerability arises due to the failure to properly initialize certain transaction  structures, such as those created by the structure TransactionFromCommit function used from the  CopyFromUser function.  This vulnerability, from the fact that the value of the InforTriggerConfigurationNumber  node, which determines the number of nodes, is entirely controlled by the user.  A tech can use this value, potentially lead to an outbound SS and memory compilation issue.  To enhance the LWIS InitializedTransactionBase function, it adding a chain to keep the number  of nodes under the sum estimate value, if the number of nodes is type size, which cannot  be a whole additive value.  I think there is no need to check for the active number.  After the contractual transaction from the commit function, the canSenseTransactionValue  node is used and is sanitized.  Immediately after work, perform another sanitization check, once it is successful to ensure the  integrity and security of the transaction data.  We also have discovered a vulnerability in the LWIS AccomplishedFetch function, specifically  considered as a type confuse.  This vulnerability arises from the pursuit of the file type without properly verification.  To address this vulnerability in the LWIS EndingCompletionFetch function, to evoke type  confuse, a patch has been written.  This patch evokes to modify the structural LWIS fetch to include a new field name, structural  ID as a possible file.  By introducing this new field, the patch to provide a clearer indication of the structural  type.  Then, directly access the LWIS EndingCompletionFetch field as a patch.  The patch introduces a chain to the structural ID field.  This chain ensures that the structural being patched as a patch is correctly identified  by its structural ID.  Next, Bangden, Peter and Yu.  I will explain the next four bugs and exploit techniques.  Bug 5, this issue shares the same cause as the previous integer overflow, but is from  a different calling path.  Both entry.readWriteBatchSizingBytes and info.numL entries are user control values, which can  lead to an overflow of the read buffer size.  This patch mitigates the read buffer size overflow by checking in each loop if adding  the readWriteBatchSizingBytes to the read buffer size will cause an overflow.  If an overflow is detected, the process will bail out and return an overflow error code.  This type confusion bug shares the same root cause as before.  It directly converts the 5-pointer private data to a specific struct without verifying  its actual type.  Additionally, although there is a check to see if the LWIS FenceFD and the FenceFD are  the same, this can be easily faked and lead to further harm.  Since it shares the same root cause, Google now uses its newly designed function LWIS  FenceGap to perform the root type check based on the structure ID and FenceFD.  This approach is more robust and harder to bypass with a different type of private data.  And bug 7 is an uninitialized bug in the constructTransactionFromCommand function.  The kTransaction variable is allocated from kmerk from the kernel heap, while some fields  in it will later be used and they are never initialized.  The transaction variable here is actually passed from the previously allocated kTransaction  and the nonTriggerFences field is not initialized since the nonTriggerFences is an integer type.  So if it initializes with a negative value, it could bypass the highlighted check here  and cause an auto-unaccess.  However, the config on pixel 8 reveals that the kernel is compiled with init all zero  mitigation, ensuring all stack and heap memory is initialized to zero.  Therefore, this cannot be exploited under the current config.  Nonetheless, other models without this config remain vulnerable.  And I'm not sure which specific commit patched this, but after emerging from the Android  15 DB branch, the kzalloc replaced the kmerk and this change ensures that even without  the init all zero mitigation, the bug cannot be used.  And the final bug is the third type confusion bug caused by not checking the real type.  It happens in the LWISTriggerEventAtWeek transaction.  The preconditionedFenceFB here was added in the week transaction by fget.  It seems okay for now because the preconditionedFenceFB is still a general structure.  And later, this variable is used in the loop within the LWISEventTriggeredConditionReady.  In a specific case where the info.triggerCondition.triggerNodes.eventCounter is equal to the LWISEventCounter  on next occurrence, it will directly take the preconditionedFenceFB's private data  and translate it to the LWISEvent without further checks.  A fix involves replacing the fetch with the LWISEventFenceGet, of course, same as before.  And additionally, it cracks the inaccurate error code return.  And next comes to our exploit part.  Here I will introduce a general exploit method and use one of the bugs we discussed before  to get the physical memory read-write on PixelSeries.  So in the mobile market, there are three main types of GPUs with its own driver,  the MediaTek's Mali, the Qualcomm's KGSL and Apple's own GPU driver,  and each used by different brands and models of phones.  Although PowerVR GPU is there and I think they are not as popular as these three in the mobile market,  so therefore not discussed here.  These GPUs share same functionality but implemented differently.  For example, they both support memory allocation from the GPU driver, but name is different.  Like Mali uses the KBaseAPMM analog, KGSL uses the KGSL IOControlGPU analog,  and Apple uses the C++ device user client new resource.  And the difference in the Apple GPU name arises from the unique driver framework called IOKit,  which is the C++ subset.  And of course, all these GPU drivers support importing memories from the CPU side.  And Mali uses the function called KBaseAPMMImport,  and KGSL uses a flag called MAPFLAGSUSECPUMAP in GPU-alloc functions.  As well, Apple uses the same function routine, just specifying a field called IOServiceID in the input struct.  And technically, the shrink-layer interface is not specific to the GPUs.  It's a mechanism within the memory management subsystem that allows for the freeing of cached items,  so their memory can be repurposed.  In Linux, various drivers and subsystems will register their own shrink-layer callback functions,  and when the system is low on memory, these functions are invoked to release memory back to the kernel for other use.  In the case of GPUs, we can leverage this mechanism to shrink memory and create a page-user-free primitive.  And page-user-free is a strong primitive in Xbox.  It can allow us to fake kernel objects from the user space, or fake the page table to read and write arbitrary physical addresses.  Many mitigations are based on virtual memory, like KSR, heap isolation, and read-only mappings.  If we can reuse the page as a kernel object, or even page tables,  we can easily bypass those mitigations and get a kernel-arbitrary read-write.  After reviewing the GPU mechanism, it seems it can give us such a primitive,  and here we will dive into Mali driver for an example.  In Mali, the structure kbase-v8-region represents a GPU memory region.  It contains the attributes for CPU and GPU-side mapping.  In the alloc function routine, Mali will use kbase-mem-alloc with a user-space-passed flag  to alloc memory and return the attributes to the rep variable, which is the kbase-v8-region.  In the free function path, it will use the user-provide-gpu-v8 to find the rep structure on the arbitrary maintained kbase context.  If the memory region is valid and not free, it will free the structure as well as the memory region represent value.  If the memory is invalid, just log error and bail out.  After knowing it's allocation and free, we can dive more into the structure itself.  Here we can skip those irrelevant parts and only pay attention to the flags and the kbase-mem-physics alloc in here.  Flags can show this region is free or not, and the attributes is read-only or read-write.  And we can see there's two structure kbase-mem-physics alloc in the kbase-v8-region.  It represents the physical memory mapped to CPU or GPU when mapping it.  So the struct kbase-mem-physics alloc is a physical pages tracking object and its reference content.  The k-reference will record the number of users of this alloc.  The gpu-mapping will represent the count number of times mapped on GPU.  For example, if we alloc a region in GPU, then we alias it this region, it will pass one for the alias operation.  As for kernel-mappings, it's same like gpu-mappings but you record the CPU-side map times.  Then comes to the next, it's the number of pages that is valid.  Actually, there's other fields will be interesting in exploit, but here is what we need for the tech.  More, the structure kbase-mem-physics alloc is an elastic object in the general snap patch.  And the size is the base, which is the size of alloc plus 8 multiply the pages.  And the pages is controllable by us.  We can see from the red line place, it will use the calculated object size to alloc the memory from kzalloc  with the gap-kernel flag, which is also general for using.  And one of the IO control called kbase-mem-commit can help us to reach the shrinker function.  But to trigger the shrinker, we need to fulfill some requirements.  First is gpu-mappings of our memory region should be 0 or 1.  And the kernel-mappings should be 0, means a region that only mapped in GPU-side once  and never mapped in CPU-side can be shrinked.  Otherwise, it will cause a side effect.  Then the shrink new pages need to be less than the old pages to let us enter the kbase-mem-shrink path and shrink the pages.  And after the background knowledge expanding, we will introduce the exploit we use here.  So if we first allocate the native page from GPU and align this region, the gpu-mapping field should be 2.  And since we allocate it in GPU and not imported by the CPU, so the kernel-mapping is always 0.  Then we could use the bug to override it to 1.  And then we trigger the kbase-mem-commit on it.  GPU will shrink the page and return it back to the main pool.  After the page is recycled, we will still hold the handle point to the free page by a large region.  That's turned out of bound.  Relative to a stronger page use of the free page.  Another thing is the GPU mapping is usually less than 256.  Which means we just write one byte and achieve this.  After we have the UAM page, we need to read and write from it.  Because we hold the large region handle, which is the GPU virtual memory region,  we can only issue the GPU read and write request to Debian.  One of the ways is to use OpenCL.  OpenCL is a framework for writing the programs that execute across platforms like CPU, GPU, DSP, FPGA,  and other processors or hardware accelerators.  Programming language we use for above-mentioned devices is based on C99, C++14, those standards.  Another way is to reverse engineering the GPU instruction set.  Luckily, we don't have to do that ourselves.  Thanks to the Panverse project.  And the IO control for running GPU instructions is the KBase IO control job submit.  Each job contains a header and a payload.  The type of the job is specified in the header.  And the job type write value provides a simple way to write to the GPU address.  After knowing how to read and write the UAM pages...  I think we're being attacked by GPU.  We need to know how to reuse the pages as an other object, like path struct or page tables.  When we allocate memory from GPU, we first allocate from the KContext mempool.  If insufficient, we will allocate from the KBDevice mempool.  If also insufficient, we will allocate from the kernel.  And the free process is like the same sequence.  We first add the pages to KContext mempool.  If the mempool is full, we add to the KBDevice mempool.  If also full, we free the remaining pages back to kernel.  To exploit it, we have two options.  Option one is to reuse it as GPU PGD.  In the structure KBase MMU table, we can see there is a PGD field.  It represents the physical address of the page allocated at the top level of each table of the context.  In fact, every context maintains their own GPU MMU translation table.  And the KContext pointer is pointing to its corresponding KBase context.  Just like every user space on the CPU side will have different address space.  And in function MMU.getNextPGD, which is called when we try to access the GPU memory.  If target PGD is not accessed before, we will allocate now by the KBase MMU allocate PGD from the KBDevice.  Then it will add the new allocated PGD to PTE.  You may wondering why here is like set PGD to PTE.  Since on CPU side, the PGD is the page global directory that manages PMD and PMD manages PD.  But I think here is just naming problems.  So we don't need to confuse about this part.  We can consider the PGD we talk about next as the PTU in CPU.  As the code shown before, most address are unused.  PGD and PTE are only created when they needed for an access.  So the page that inspecting PGD is allocated from the KBDevice mempool.  And which is shared by all KContext.  Which means with proper mempool function, we can reuse our free pages as GPU PGD.  So our step will be first reserve page for spraying PGD later.  And arrange the memory to fill up the free list.  Then we spray this KBaseMemPhysicAllocStructure and trigger the outer bound to overwrite one of the GPU memory.  After KBaseMemCommit shrink and free the page because KContext mempool is full.  It will return to KBDevice mempool.  Then we allocate some free pages again which we previously reserved.  And we will take the memory page we just freed into the KBDevice mempool as the PGD of our new allocated pages.  After we use UI page as GPU PGD, we can make GPU virtual address point to arbitrary physical address.  By reversing firmware, we can calculate to know kernel global variable physical address such as AC Linux state or code pattern.  Use GPU write to modify the AC Linux 0 to disable AC Linux.  Even config static user mode helper path is read-only on CPU.  But we can mark it as read-write in the GPU PGD.  And we can overwrite it with BeanShell.  Then we overwrite code pattern to the payload we want to execute by BeanShell.  And finally, trigger the segment 4 to trigger the core dump to exploit payload in the root bridge by the code pattern tree.  Next, I will pass the bidding for the option to exploit.  As we mentioned before, if the next pool does not have the space, KBase allocate page is used to allocate page directly from the kernel.  Similarly, in the free case, when all pools are full, return the page back to the kernel, create an opportunity for reuse as another kernel object.  We can then reuse the free page as another kernel object to continue the exploit.  There is a type of way to achieve kernel address rewrite.  The exploit scenario involves several steps.  First, we will reserve page in the GPU for later allocation of the PGD.  Then, we use impulsory to position a KBase memory physical allocation structure behind the LWS translation response buffer.  Trigger an integer overflow to overwrite the GPU memory.  And then trigger the memory coming and find out the UAF page.  Allocate the reserved page and reuse the UAF page as PGD in the GPU.  Use a latency handler to modify the page table entry to point to the physical address we want.  We can disable X-initialize app, limit the competent trigger to get root, and launch a virtual shell for example.  When we try to port our exploit on the PISO app, we encounter the issue to use a latency handler to modify the PGD point to the physical address.  On the PISO-6 device, the KBase IO-control job submit IO-control can be used to write to the GPU memory.  However, on the device featuring the CSM competent system feature start from the PISO-7 generation and above,  this specific IO-control may not be compiled or available due to the change of in-system architecture.  In this scenario, where the KBase such IO-control is not available, we can resort to use OpenCL GPU memory rewrite operation.  Here we can approach it. Use the DLSIM tool and let me point out the necessary functions from the OpenCL library.  Initialize our GPU rewrite function. Use the gpurewrite.cl file.  This contains the required OpenCL kernel and function for the memory access operation on the GPU.  This approach alone performs the GPU memory rewrite operation without the KBase IO-control job submit.  Thereby, maintain the physical and access the different device modules and software versions.  So we can work our rewrite into the C support.  Indeed, use the OpenCL introduces another problem.  Due to its automatic create a new memory file descriptor and manage its own GPU address page table.  Attached to write to the memory created by the OpenCL, use a different file descriptor will result in page 4 on the GPU side.  For more, both screens in the OpenCL FD will break our CPU function, prevent the reuse of the UF page as the PGD.  So we use a shell library known as convent tree to hook the OpenCL function.  For set up the device and reserve the screen page can ensure the capability with.  By interpolate and modify the name of this function, we can reserve the necessary page before GPU opens CL.  The memory object cell can contain a region of memory and its different objects.  Besides caused by the shrinker mechanism, we can use KFreeze to achieve page UF.  Qualcomm GPU or PowerVR GPU should have the similar memory object as Mavic GPU.  The exploit properly deploy on the shrinker mechanism to achieve properly escape from the page UF.  Without directly engage MTE, the initial outbound as if it detect may trigger a KSL or warning in the deep messenger.  Potentially hold the exploit flow.  And the chance of detecting the outbound is low from our test, less than 50%.  Offer a chance to execute the exploit flow and up the root access.  We can run the exploit a few times to expound the root shell.  And we can connect our root messenger in the deep messenger.  Then we can show the device demo that we use to GPU technique exploit for the integer overload.  Okay, so...  So here we can see that MTE is enabled and the AC Linux is enforced.  And we trigger the exploit and it quickly pop a reverse shell back above.  And we can see that we are the root bridge and AC Linux has been disabled.  Okay, so this is our final part.  We will do some conclusion based on the previous sharing.  Mitigation is sometimes hard, it may be weak from another level.  We should think other supports and defeat mitigations by our boosting features.  And targets not only have vulnerabilities but also can be part of our exploit path.  And with more and more software and hardware mitigations,  exploit 1.0 is harder but with good exploit package is still possible.  And finally here are some references we use when we prepare the slide.  And you can refer to it.  And above is what we share today.  It's supposed to be the Q&A session but I think our time is left.  We are still around.  If you have any question, you can come and ask us.  Thank you.  Thank you.