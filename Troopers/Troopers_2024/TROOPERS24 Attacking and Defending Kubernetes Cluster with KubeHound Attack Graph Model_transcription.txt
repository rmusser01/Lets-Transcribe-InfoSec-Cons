{
  "webpage_url": "https://www.youtube.com/watch?v=JLmEsT-89Xo",
  "title": "TROOPERS24: Attacking and Defending Kubernetes Cluster with KubeHound Attack Graph Model",
  "description": "Talk by Julien Terriac - June 27th, 2024 at TROOPERS24 IT security conference in Heidelberg, Germany hosted by @ERNW_ITSec\n\n#TROOPERS24 #ITsecurity \nhttps://troopers.de/troopers24/talks/t8tc7m/\n\nMore impressions:\n  / wearetroopers  \n  / ernw_itsec  \nhttps://infosec.exchange/@WEareTROOPERS\nhttps://infosec.exchange/@ERNW https://ernw.de",
  "channel_url": "https://www.youtube.com/channel/UCPY5aUREHmbDO4PtR6AYLfQ",
  "duration": 3071,
  "channel": "TROOPERS IT Security Conference",
  "uploader": "TROOPERS IT Security Conference",
  "upload_date": "20240909"
}

This text was transcribed using whisper model: large-v2

 So, welcome everyone.  I'm going to present Attacking and Defending Kubernetes Cluster with Kubehound, an attack  graph model.  For first, I wanted to thank Strupers for having me here.  It's really an honor to be at this conference, and since I'm going to speak for about an  hour, I'm going to introduce myself pretty quickly.  I used to be a pen tester, then I switched to the engineering side as the developing  side, but really with a real interest in offensive security.  So if you didn't notice, I'm French.  I've already apologized for that, but we will go try that later.  So this project is not my own project, it's a team effort.  The lead tech on this project was Jeremy Fox, who has left the company since, so this is  why he's no longer with me today.  He's now a staff engineer at Oracle and also had a lot of background into offensive security.  Also Edward, I will not say his last name because even though I'm still working with  him, I can't manage to actually say it, so we just call him Edward, was also part of  the project and the team in Datalog.  So his agenda seems pretty long, but don't worry, we try to go pretty quickly over everything.  So first, I need to do some introduction.  I wanted to know who is aware of Kubernetes stuff, like who is playing with it from offensive  or defensive side.  So I'm just going to go over some pretty basic stuff, but that you actually need to understand  before continuing.  So first, what is Kubernetes?  So Kubernetes is an open source platform where we actually managed to have some containers  application being shipped, and it allows you to have scaling capabilities and high availability.  Then you have container, and container is like the smallest unit that we would actually  be part of the Kubernetes model.  It is actually able to ship sandboxed application, but here, sandboxed is not the way we intended.  It's not really for security, but it's for a developing point of view.  So it allows you to ship an application that if it is working on your laptop, it will also  work on the Kubernetes, but sandboxed was not made actually for security purposes, and  we will go on that a little bit later.  Then you have pod, which is like a deployment unit into the Kubernetes world.  So basically it can contain one or more container, and it's been designed to run stuff basically  on this Kubernetes platform.  And last, you have the node, and the node is the closest thing you can have to a real  machine.  It's where it can actually parametrize CPU, memory, and stuff like that.  And when you group all the nodes together, you actually get a cluster.  So to get the picture, you go to the container.  On the container, you have the pod.  On the pod, you've got the worker, and everything together, it's a cluster, a Kubernetes cluster  with a K8s API.  K8s where you can ask for information about your cluster.  And you have also the cloud provider, but this will not be part of the talk.  We will only focus on the Kubernetes environment itself.  So again, who has done some offensive work on Kubernetes?  Okay, so some of you.  So again, I just like to have the basics.  So first, it's like container escape.  And container escape, the goal is actually get from a container and usually escape to  a node.  It's basically try to break your boundary and try to access to other type of information  that you were not supposed to.  And usually, it's like through misconfiguration.  You have after Kubernetes identity.  So everything that is actually being run into a cluster is attached to an identity, usually  service account that are linked to the container which is being run under.  And you have attached to that roles, and roles actually allow you to get some resources from  the API.  And of course, some of the sources have like obvious security issue, like if you can release  a secret, that's going to be an issue, or if you can execute some pod, and so on.  And last, in the model, you have volumes.  And usually, volumes can be like a way to actually make a bridge between container and  nodes.  And this is why we put it also, it's like something we really want to emphasize because  it's really important into the model.  So again, you have the container.  So the container, you can escape to the node.  You can do some pre-verification through the wall, and so on.  And that's really what we want to try to tackle with KubeHorn.  So of course, there are a lot of other attacks, but we do not have time to cover all of them.  And that's not the goal of this presentation.  But that's really just to give you the 101 basics out of it.  So the problem in space.  So first, let's say you have two vulnerabilities, and two are container escape.  And the first one is actually a privilege-facing container, which should not have this kind  of right.  So here, he has the privilege true being activated into the container configuration.  And on the other hand, you have another container escape, which is in the control plane, DNS  container, and it has a cat-sys module capabilities.  And both are container escapes.  So both usually are the same in term of criticity because it allows you to escape from it.  But one is not public-facing.  The other one is like have solicited access, like a lot of audited in place.  But to get this context out of it, you have to do some manual processing.  So if I ask you to do that on the 1,000 container escape, well, that's going to take you a lot  of time to process each one of them and try to get to figure out what is it.  So let's say we have a cluster where we have like 14 container escapes, a lot of privilege  creation, and a lot of vulnerabilities into it.  And I'm going to ask you, how secure is it?  Well, you can't tell me because basically, you don't have the context about it.  So it is another adage that was actually said by John Lambert a long time ago.  It's like defenders think in list and attackers think in graph.  And as long as it's true, attackers win.  And that's basically what we did.  And we took him to the letter and try to be able to get this graph thinking to get  a security posture that can actually give you some value KPIs really for free at scale.  So the goal is really to shift from a list approach.  So like we were saying, you know how many vulnerabilities, CVE, and stuff like that,  and get to the newer graph approach where you can actually get some concrete information  out of it that will make a lot more sense than the traditional way.  And basically, what we want to do by having the security posture is basically try to have  it for the current state.  But if we have it for the current state, we can also measure changing over time.  So if we know how many percentage of internet facing stuff that are actually being exploitable,  we can measure it over time if you can do it at one specific time.  So at Datalog, we have a lot.  We are really a Kubernetes company.  I used to do consulting before, and I never encountered anything as big as Datalog ecosystem.  So it's really big.  And the traditional pentest is not enough.  You can really scale.  You can really have this value out of it.  So I will try to show you pretty quickly how we can actually get.  So it would not be against Datalog, of course.  But I will try to do a quick demo on the tool.  So just play with me, because that's his live demo.  So everything can go wrong here.  So first, I'm going to actually deploy a later cluster on my laptop to do the testing.  Like I was saying, I don't want to do it on the real environment.  So I will go on that a little bit later.  Here it's scan cluster, and that's basically allowing me to speed up a small cluster on  my laptop with vulnerable configuration.  And when it's being done, I'm going to ingest it into KubeHound, and then show you some  basic KPIs that are being processed automatically.  So yeah, I just need to fill the time here.  There we go.  Just for the sake of purpose, I could have spin it before, but I'd really like you guys  to have the real live demo experience.  So here it is.  Now I'm just going to run KubeHound.  It's going to spin up everything it needs.  So we are, of course, using this Docker stuff that needs to be run.  They're actually going to get spin up by KubeHound.  So again here, live demo, so it takes about 40 seconds, 50 seconds maybe to get spin up.  And once we have that, we run a small Python script that would actually create a dashboard  with the basic metrics that I just talked about.  So let me drink a bit.  Here we go.  So I'm asking you, do I want to dump this?  I say yes.  So I'm sorry.  I don't know if you guys can actually really read back then, but TV is what it is.  Now I'm just going to run my small Python script.  So this is like more of a POC than the actual application itself.  It's just to really emphasize and show how it can be done.  It's really something sketchy right now.  We try maybe to blend it into a more formal application later.  It's more to show you the capabilities and what you can actually do and how easy actually  to get or retrieve the KPIs that you actually want and that actually matters to you.  So here I'm going to add some global KPIs, some KPIs about endpoints, volumes, are going  to be identities and containers.  So the last one is identities.  There we go.  It should be pretty.  So everything is working so far, so here we go.  So this works.  So now we're just going to...  So here we have like the...  So you had to make it big, otherwise the folks on the back can read it.  So I'm sorry it doesn't fit in the screen.  So you have like all the different attacks that you have into your container.  So you got some global statistic.  So half of the assets are actually vulnerable to critical pass, which is bad.  Like 100% of my endpoints are actually can lead to complete takeover of the cluster,  which is bad.  Again, it is like that's what we intended here.  Same for containers, half of them can actually be compromised, identities and so on.  And you also get the list of everything that is actually linked to the vulnerable attacks.  So this works.  Thanks for playing with me and let's get back to the slide.  So of course I'm going to talk a little bit like how did this magic happen.  So I'm going to talk about graph theory.  So that's...  Well, it's not going to be about financial advice, but you know about like the study  of mathematical stuff.  And basically again here, I'm just going to do some go over of like taxonomy 101.  So we all speak the same language.  So first we have a graph.  Because it's like the complex representation of what we want to output.  Then we got vertices and vertices can also be called as node.  But for obvious reason, I will try to avoid it because after you will not see the difference  between a Kubernetes node and like node from a graph theory.  So I will call it vertices and not node.  You have edges.  So basically edges is where you link one vertices to another.  And when you have like several vertices being linked by several edges, it's what you call  the path.  So if we output it here, it's like you got vertices one linked to another one by an edge  and you get like a full, you know, path when you link more of them together.  So why Kubernetes?  First it's really the goals like having this visualization capabilities and graph technologies  into the, you know, apply to the Kubernetes world.  And when we did the research, I know actually, so we started like maybe a year ago, a little  bit more now.  And there were no tool existing except, you know, well, I will not introduce it here,  I guess, but the Bramham one, we really think like make a game changing into the Windows  security world.  And we say why not just reapplied that basically, you know, was applied to Active Directory's world.  So in our world, in Kubernetes world, you got entities.  So basically an entity is like an abstract representation of a Kubernetes object.  So usually when you go to container, we call it container, but sometimes we had to, you  know, add our custom entities or permission set is one of them.  It doesn't exist into the Kubernetes world, but we made it as an abstraction on the world  and world binding for engineering reason.  I will come to that a little bit later.  You got the critical assets and critical assets are important in our model.  It's basically the end goal where we try to create the graph.  It say when you reach a critical asset, we end the graph.  It's like, okay, it's done, it's game over.  It's like B-domain admin, but it's here, it's more cluster admin that is in our interest.  And basically it's like a path that leads to this critical asset, that's what we call  a critical path.  So you can start from an entity, so it's an endpoint, and end up to cluster admin, and  there you have your critical path.  And attacks, it's what we call edges, and it's what's being linked from an entity to  another one.  So every time we link two entities together, they are basically linked by an attack.  So again, if we take the same model, we got an endpoint that is linked to container.  And if you link from the endpoint to the permission set, you got this critical path.  So if you read it as an offensive guy, you can see that actually endpoint has been exposed  by a container.  From this container, you can actually use it right by the service account to assume  an identity, as an identity can actually lead to cluster admin because it has its own permission  being cluster admin.  So that's pretty simple, of course, and the goal is really try to get more completed one.  So in a nutshell, basically this attack graph model, it's really trying to represent all  the hops and everything that is being graphed together.  But what is really important, it's we try, if there is a link between one object to another,  it will not get missed by KillHound.  If you get a link, if there is some link, the graph actually is going to get computed  and you would be able to get this path from point A to point B. That's really important.  As right now, it's working as a snapshot.  So as you saw, I have to retrieve everything on a specific time and then do my analysis.  It's not live, it has to be like an image of the Kubernetes cluster at a specific time.  So again, just to explain what I just ran on my laptop, so you got KillHound that actually  asks the Kubernetes API to get all the resources.  From it, we compute the attack path tool in database and from there, we actually ingest  the attack path into a graph model and from it, you actually query the graph model to  try to do the hunting and get what we want.  So the goal, because you will see that a little bit later, it's sometimes what you get because  you will see that your cluster actually has a lot of attack paths, but the goal is really  to get from this kind of a lot of stuff, kind of worms, to try to pinpoint the ones  that actually matter and that's also what we want to do, KillHound, to achieve is really  having this ability to actually pinpoint where the real security, the real problem are and  what you want to tackle.  So like I showed you earlier, it was like a dashboard, it's not really like the way  we use it, like if you want to do manual stuff.  So we are using the Gremlin language.  So who knows Gremlin here?  Actually, so I might need to talk to you guys after because to be honest, first time I said,  oh yeah, it's pretty easy, it's pretty cool, but after a month, you were like, ah, it's  like I would never manage to get it work.  So it was really, really hard.  So we managed to understand most of it, but we still have difficulties around it.  So we decided to develop our own domain-specific language to have a learning experience that  is not as hard as just learning Gremlin because trust me, it is hard.  So the goal is to have those huge Gremlin requests that are actually really complicated  to get something really easy that actually can be a lot more obvious to you.  So for instance, you just say, okay, I want the pods, from all the pods, I want the critical  path and I just want to get the first 100 out of them because for performance issue,  I just want to scope to limited.  But try to read the one on the left, well, good luck.  So we documented everything on our website.  So we have a documentation of all the DSLs that you can actually use in the model.  And we try to put a concrete example so it can be easy for you to actually use.  So UI, that's a complicated topic because in our team, we just prefer back-end stuff  and it's really hard to be front-end.  So we focus more of our energy on the back-end stuff and we try to get out-of-the-box UI.  So we first went with an application called g.v, but we went away from it because first  it was free, now you have to pay.  So it was against our mindset, we wanted everything to be open source, so at least free.  It was really oriented developers and it was really hard to, it was like a rich client,  you had to install on your laptop, you couldn't ship it pretty easily.  So we went to Jupyter Notebooks.  We actually are pretty cool, I just discovered it on the project, I never used it myself  before.  But it's really nice, you can share results, highly customizable, and there is like a plugin  directly being available for Gremlin, which was pretty cool for us.  So like I just showed you earlier, you don't have to do anything, so it should be pretty  easy to use, you just run QHound and it will connect to your cluster you are currently  being connected to, and it will dump everything, ingest, and put it into the graph database  and that's it.  There is no fancy command or anything, you download the binary from the GitHub and that's  it.  So again, pray with me, really hard, because that's again a live demo here.  So I'm not going to attempt too much of the gods here, I'm just going to, so I'm not going  to re-ingest it, I'm just going to use like a special notebook I made for Troopers.  So you saw the data was already, I've been ingested previously, so I just will not go  over again, so I'm going to reuse the same data here, and we are going to try to go over,  you know, try to show you the capabilities of how QHound can actually be useful.  So first, I'm here, I'm just going to, so qh.v, actually just print out all of my cluster,  is just to show you, so let me, one second, because, here we go, let's gain some space,  here we go.  So that's our cluster, so that's represent all the vertices in the cluster, so the blue  dots I think is the endpoint, each color has its own type, so that's a pretty small cluster,  let's face it, we have like 300 something entities here.  So I'm going to ask to get all the critical paths from anything, basically, and limit  it to the 500, and that's where the problems begin, because actually what you get is this,  so it's not really readable, it's really hard, like where do I start, just too many stuff,  so it's not really human, it's hard to process from a human point of view.  So okay, maybe asking for many things is not that great, so let's start with containers,  because you know, usually we are interested in containers where the application actually  are and where the vnp actually leads to.  So I'm going to ask again here, I'm limiting 5,000 for the demo effect, but also you will  see that even doing it on a container, we still have way too many stuff, and it's hard  to really know where to begin, so you're like, okay, a container is not, but let's start  with endpoints, because endpoints is actually what's facing a cluster from a user point  of view, it's where an attacker is likely to, you know, try to compromise it, so you  do ph, the endpoints are critical paths, so again here, it's like all our DSL, because  we think it's like a lot easier to process and to do like the crazy, all the queries,  so here we go, huh, I guess not everyone pray in the room, here we go, so let me reload it,  nope, there we go, there we go, so endpoints was here,  that's sad, what, yeah, yeah, that's true, yeah, yeah, sometime, but shouldn't be like  too many, so let's hide it, I could limit here, huh, so that's, wow, wow, wow, wow,  that's demo effect, restart, here we go, so is it back on, okay, and here we go, sorry,  so wow, so we got like endpoints from a critical path, so that's not endpoints, is it, yeah,  yeah, my, you know, colleagues advise me to do video, I was like, ah, that's fine,  I've done it before, maybe I should have listened to them, so come on, you have to be, no, I don't want to do that,  I don't want to rerun all, shut down, shut down, restart, there we go, so I guess that's going to be good introduction,  it's because also we introduced, because while sometime running on the laptop has, you know,  well, it's own difficulties as we can see that's for, you know, even we have good laptop in Datalog,  sometime, well, it's not enough, so, yeah, well, that's not too bad, so from the endpoints, I want to try to,  actually, let's do some limit here, okay, I'm going to try to, yeah, I don't have that many, I don't have the one that actually,  10,000, 20,000, here we go, so, well, you will see that it's going to be a little bit more, so here it's like I limit it to 20,000,  let's pull the lock to 30,000, and here I'm trying to figure out, like, which of my endpoints are actually,  oh, here we go, I got the result I wanted, and it's printing out, like, all the services that actually are vulnerable to critical path,  so, like, I guess most of you here are, like, actually saying, hmm, that's looking yummy, I got, like, gmx endpoints,  that looks cool, and we have on the other one, kubedns that I talked on the introduction on case that we don't really care about,  because, well, we know that it is actually not really a security issue, because it has to have this, like, rights into it,  so I'm going to try to put them aside, and I'm going to try to ask to get all the critical paths,  or maybe I should add some limiter back here, again, and, you know, try to add and see a specific focus for all the endpoints except the kubedns one,  and here we go, you know what, let me just back it down, here we go, and I will come to that a little bit later, let me, yeah, so,  didn't pray enough, we come back a little bit later, if we have time, to try to finish the demo, as a demo gods, that's definitely against me,  so, how this, I don't know if that's magic anymore, but, you know, how, what's happened under the hood, so, the architecture here is pretty easy,  we have a collector that actually, you know, try to retrieve all the information from the k8s API, we got an ingester where I actually parallelize and ingest everything into the database,  and we got the builders that actually build the graphs that, you know, what we are interested in, so, how it's being processed, so you got, you know,  you can recognize here a hem chart, got, like, pushed into our Mongo database, and from there we just, like, translated into genus graph information,  so, from architecture point of view, collector again, pushing to a builder that actually pushes a graph, and from it you can actually visualize with the Jupyter directly,  so, well, it's, you know, pretty simple architecture, you know, so, again, ingester, collector, builder, and then visualization,  so, the collector, we try to make it safe, because we don't want to break your cluster, because, you know, we can hammer the k8s API,  so, we try to limit, and we got, like, all the specific limitations, so, we limit it by default to 100 requests per second,  the size of the different stuff we try to retrieve is by default, and you can actually configure any of that if you want to test your, like, and make it faster,  but that's really where you also see, like, in the demonstration, having everything on a rich client sometimes can have a limitation,  also, it doesn't scale well, so, this is why we try to introduce CAS, so, you know, of course, Cuban has a service, so, I don't know if there is, like, if she's a big star in Germany, but,  so, how can you use, you know, QHON at scale?  So, one way, one would you need to change was actually, you know, to handle all the airbag stuff, which can be a pain, you know,  we have needs a collector to actually try to get the right resources, and from that, you need to have a way to handle all those airbag issue,  then, it has to be easy to deploy, because, like, if you have, like, hundreds of cluster you want to cover, you need to be something that can be shippable pretty easily,  and then, it has to be also scalable, because, like I said, if you have, like, unlimited cluster, you need to be able to handle all of them,  so, of course, we make it to the challenge, so, that's basically what we wanted to put, so, we have, like, all the cluster on the left,  so, let's say you have three cluster, production, standing, and dev, so, we put the collectors directly, that would actually get the information,  then, we push it to, like, data storage, so, it can be S3 buckets, or whatever cloud providers that you are using to push it to somewhere,  then, it's going to actually push a signal to the Kubernetes, to the Kubehound ingester, which would actually retrieve the data,  and from it, we will actually, like, create and push the data into the MongoDB and the genus graph one, and then, you can, like, visualize it for the Jupyter one,  and that's what we call, like, as a service, we have this capacity to actually, you know, split between the collectors, the ingestion, and everything,  and also, allow you to have, like, a big, you know, a big genus graph instance, where you don't have such limitation as we had,  when you try to make, like, queries that are actually too big for your laptop, so, in a nutshell, what is it?  It's Kubernetes service, it's, like, distributed, it's a distributed collector, it's a centralized ingestion, it's, like, a unified source information,  where you can actually get all the information that you actually need about the security posture of your cluster.  So, some metrics in Datalog, so, that's my laptop, but what we use is more of, like, 60 gigs RAM, just for genus graph, which makes the query go a lot faster,  so, we don't have, actually, issue, like, a lot of CPU, but the size of everything that we collect is actually not that big,  it's about, like, 10 gigabyte per day, so, for all the cluster, and the average time of, like, ingestion to really rehydrates, you know,  when we get the dump and push it back to the genus graph, it's about one minute, which is, like, pretty short.  But what if, I guess, there is also a lot of security consultants here that, you know, don't have this really problematic,  so, how this Kubernetes service can actually help?  So, we try also to make it, you know, available for people from, like, a consulting point of view, so, you can actually do the dump, you know, offline,  like, I can just do, like, two-arm dump, and then we put, like, we spin up everything and do the dump, actually, locally,  and then you can re-ingest it directly on your instance, you know, in your office, or on your laptop, or you can, you know, just use something pre-built.  We just, like, you know, try to split everything, so you can use it the way you want to.  Also, we try to make it, also, a good thing, a good tool for consulting people.  So, another part I wanted to talk about is, like, the research and development process that we made on the tool,  and why we wanted to talk about it is, basically, we think it can be actually applied to other stuff,  like Archicorp Vault, you know, AWS IAM, and stuff like that,  because we believe that the graph technology can actually be a good thing to implement into other security problems that need to be solved.  So, first, you need to research, like, everything that is about Kubernetes security,  because all the attacks that we implemented into the tool were not found by us.  It's, like, public knowledge, basically. It's everything.  But you have to do, like, you know, regroup everything, and first understand, so you can actually know what to build.  Then, when you get everything, you need to, like, sketch out the design, you know, what vertices you need,  what properties you need, and stuff like that, and then, of course, port it to a graph database.  So, the first, like, main topic we tried to tackle was airbag stuff, because, you know, who doesn't love airbag?  It's always, you know, easy stuff, of course.  Not really. It's always a nightmare, especially in a Kubernetes environment.  So, we had to read a lot of blogs, read, you know, a lot of official documentation, a YouTube channel, and stuff like that.  So, for instance, so, compromising Kubernetes cluster by, you know, cyber art was really good stuff,  where we actually tried to understand what actually was made.  So, that's, like, a first sketch of what we have done.  So, you see here, we try to, so, at this stage, there was nothing being designed.  So, we wanted to say, okay, we need secrets, we need roles, we need identity, which properties you need.  So, we need resource, we need verbs, all those kind of stuff.  And, basically, we tried to do that to every single attacks.  And then, we put it, like, as a Neo4j for the first POC of the tool, and that's basically how it looks.  So, we try, also, sometimes to push it a little bit further than what was available out there.  So, for instance, it's, like, about the role binding attacks.  So, we made, I know the guys on the back can read it, sorry.  But, basically, you can find everything online, and we try to push all the research that was made on our website.  So, also, once you have the attack, you want to do it yourself.  And, one way we found it was the Client Cluster, which was, like I showed,  it allows you to actually spin up your own Kubernetes cluster on your laptop.  And, it is actually easy to set up, and it is so easy that you can actually automate some end-to-end testing.  And, that was really valuable for us because, as I will describe it a little bit later,  we use it as, like, a regression model for our tool.  You have to keep in mind that Client Clusters have some limitations because it's like sharing a kernel.  So, for some vulnerability, like the image core pattern stuff, it will not work,  especially if you're on a Mac because the kernel is not really shared.  And, it implies that there is some limitation.  But, for most of them, you are perfectly fine by, you know, testing or, you know,  doing all your testing into this simulated cluster.  So, like I said, everything has been referenced on our website.  So, we've made the prerequisites, the exploitation step-by-step,  the checks that you actually need to do to see if there is a vulnerability.  And, we also try to push the defense or the mitigation against all of them.  So, I really invite you, if you are interested into it, to go over.  We listed over 26 attacks for now.  And, everything is being described.  And, we really want it to be as practical as possible.  So, those attacks, sometimes it's not that long, but it's, like, really what matters.  And, this is why we try to back everything that is being implemented into the tool.  It's actually backed as a research being described on our website on kubern.io.  So, like I was saying, that's really cool to make all of this.  But, how can you make sure you don't actually break stuff when you try to add a new feature?  So, first, we try to make, like, unit tests.  Because, that's really popular into the engineering world.  But, not that much into offensive security world.  Because, usually, well, you know, we don't have time to do so.  Especially, when you are a consultant.  So, we try to push, you know, unit testing to make sure that we don't introduce, you know, regression.  The code shouldn't break stuff.  But, it's not enough.  And, this is why we try to introduce system tests.  And, basically, every time we push a PR, we spin up, like, a venerable token cluster on GitHub Action.  We translate the configuration from this cluster into Golang code.  So, we can actually match.  Okay, do I have all the pods?  Do I have all the nodes, actually, in the end results?  We automate the ingestion.  So, we build the application, run the ingestion, and then compare.  Do we get this attack?  Yes, we still have it.  Does the DSL still work?  Yes, it does.  And, so on.  And, this gives us confidence that every time we, you know, add a new feature,  actually, the model that we put in place is actually still working.  So, I know I've been talking for a long time.  So, I guess it's time, you know, for a fun fact.  I call it, you know, when the CTO joins the party.  So, actually, at first, we made, you know, our first POC of the application.  It was Neo4j base.  It was pretty long.  It took, like, more than 10 hours to ingest pods.  One hour to dump everything because we are using, like, the dirtiest bash script you can think of.  And, we push it, you know, as, like, we want it to shift.  Okay, now, let's be full open source.  Let's say we have, like, one hour to ingest everything.  It's pretty fair to us.  Like, 10 minutes to retrieve all the objects from the API.  And, you know, that was the goal that we set to ourselves.  And, you know, we're happy.  You know, we made it.  It's, you know, we released it.  We were happy.  And, we say, okay, next quarter, what we are going to do?  And, we are going to try to, you know, put it as a service.  So, in Datalog, we have, you know, what we call OKR.  So, I don't know if, like, every one of you is aware of OKR.  But, you try to describe what you are going to do the next quarter.  And, you know, it's like a small document.  Like, maybe one paragraph where you try to emphasize what you are going to do.  And, you know, you got a CTO who, you know, doesn't have a clue of, you know, a clue of what is KubeHunt.  Because, you know, it's like a CTO of 5,000 tech companies that, you know, has a lot of other projects.  And, he's saying, wait, guys.  I mean, you are saying it's taking one hour?  But, you know, if I do, like, some narking computation, it's, you know, should be a matter of seconds and not hours or days.  Like, what's going on?  And, you get, like, these comments.  So, you are like, oh, that doesn't look good.  So, you know, we try to do everything.  So, of course, you never say no.  Because, usually, when those guys kind of, you know, do some comments here, they know what they are talking about.  So, you know, we put, like, memory graph, tunes, you know, the queries about it.  We optimize how we generate the edges.  We optimize the query APIs call.  Because, there are some tricks you can actually gain a lot of time.  And, we actually went from, like, 35 minutes to 30 seconds.  So, you have these guys with, like, CTO.  Like, read, like, in 10 minutes your paragraph.  And, you know, pinpoint, say, oh, you are doing something wrong.  And, you are like, oh.  And, you have been working on the project for, like, several quarters.  I guess this is why it's CTO.  And, this is why, you know, I'm just, like, you know, building the project.  So, but that was, like, a really good comment.  And, that managed us to actually, you know, improve a lot the performance around it.  So, the key takeaway I would have, it's like, we really think that, you know, power of automatic graph is really the next thing for offensive security.  And, we really think it's, like, the natural evolution of the security tooling.  And, we think there's going to be a lot more of different projects around it that will actually be really useful.  As for, you know, offensive, but also for defender.  Because, it allows you to get, like, you know, this big vision pretty easily.  So, what's next?  First, we want to be able to tailor you to your, you know, your own environment.  Because, you know, we know you can have your own specifics.  So, we define critical asset the way you maybe have different aspects of what is a critical asset.  And, we want to give you a way to actually be able to customize it in an easy way.  So, you don't have to change the code of what is a critical asset.  So, also, you know, if you want to discard stuff from your graph and stuff like that.  Basically, we really want to enable you guys to be in control.  To, you know, tune the model to your own environment.  We also want to, like, it's also something really important to our eyes.  We want to put weight on the edges.  Because, we know that all attacks are not equal.  Some are really easy. Some can be hard.  Some can, you know, take time.  So, you know, do a lot of noise.  And, we want to be able also to, like, put in front the attack that actually matters the most from an offensive point of view.  And, we think that, you know, weight can actually be a good way to differentiate all the different attacks.  KPIs. Leadership loves KPIs.  So, we want to give you, especially for defense team, you know, we want to put you, like, KPIs for free.  So, you can actually say, hey, my cluster is getting better.  But, you know, like, those KPIs actually matter.  And, I'm not, you know, some just, you know, how many CVE I got in my cluster.  You know, like, real KPIs that actually make sense.  So, you know, a lot of stuff.  We also want to our own UI someday be able to do some diff checking, CI, CD integration.  You know, a lot of different stuff.  We have, like, a lot of other stuff in our backlog.  But, you know, it's, we are a small team.  And, you know, also hard to keep up with all the, we have more ideas that actually manpower to cover them.  So, let me just, if I have a few seconds.  I think I do.  So, let me, yeah, still have five minutes.  So, let me do just one last ingestion.  Ingestion.  Come on.  Here we go.  Almost.  Yes.  Dumping it.  Storm.  Yeah, no, you're not happy.  Leave.  Guess what is the password?  No, it's admin.  It's a really strong one.  Here we go.  Troopers.  So, let's do the initialization phase.  And let's go back where we were.  So, we were saying endpoints.  Here we go.  Critical path.  What is this word?  Still not.  That's a pity.  Yeah.  Yeah.  Yeah.  Oh, here we go.  No, no, we don't.  Oh, yeah, we do.  Wonderful.  So, you have like this.  So, I don't.  It's definitely like it.  So, from here.  Touching.  Okay.  So, here we go.  It's just a bit.  So, you got all this, but you can pin out that here you got the three endpoints that actually matters to us.  So, you see like the, you know, gmx1.  So, we know gmx can be like always sketchy.  And we get like everything is connecting to one container.  And, you know, you got like escape to the node.  And from there you got a lot of different stuff.  But I guess what really matters is only this phase.  So, if we go back and, you know, if you really want to pinpoint all you need is actually like this specific stuff.  And that, you know, that's actually what matters.  So, you know, we went from the big chain of everything to actually one query that actually pinpoint like what actually matters into your cluster.  So, well, it was a break live demo, I would say.  But so, for instance, like I said, like a few queries, it's actually like enable you to pinpoint where the vulnerability are.  And can actually say that you can actually see that, you know, all those three is like the weakest link on your whole cluster.  If you want to, you know, spend a lot of your energy, this has to be where to focus.  And now we go back to the presentation as it is my last slide.  So, I will thank you all for listening to me.  We are recruiting for the team.  So, if you are interested to be paid to, you know, to develop on this project, don't intend to pick me.  We are looking for replacement for Jeremy who left us.  And thank you all again.  All right.  Thank you, Julian, for your contribution.  Sadly, because we don't have much time and we need to set up the next talk.  We don't have time for a Q&A session.  If you have questions, I think you can feel free to approach him afterwards on the coffee break or right now.  But yeah, big, big shout out again for your contribution.  And thank you.  Thank you.