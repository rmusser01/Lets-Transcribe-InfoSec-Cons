{
  "webpage_url": "https://www.youtube.com/watch?v=mI0teN4hPYQ",
  "title": "TROOPERS24: WatchWitch \u2014 Hacking the Apple Watch",
  "description": "Talk by Nils Rollshausen - June 26th, 2024 at TROOPERS24 IT security conference in Heidelberg, Germany hosted by @ERNW_ITSec\n\n#TROOPERS24 #ITsecurity \nhttps://troopers.de/troopers24/talks/h7mlua/\n\nMore impressions:\nhttps://twitter.com/WEareTROOPERS\nhttps://twitter.com/ERNW_ITSec\nhttps://infosec.exchange/@WEareTROOPERS\nhttps://infosec.exchange/@ERNW https://ernw.de",
  "channel_url": "https://www.youtube.com/channel/UCPY5aUREHmbDO4PtR6AYLfQ",
  "duration": 3082,
  "channel": "TROOPERS IT Security Conference",
  "uploader": "TROOPERS IT Security Conference",
  "upload_date": "20240902"
}

This text was transcribed using whisper model: large-v2

 Hi, thank you all so much for being there.  This is my very first time at Troopers, and it's my first proper conference talk in general,  so I am very excited to have you all here.  As you heard, I work at CMO doing research on Apple stuff vaguely, and for the past year  or so, I've been looking at the Apple Watch.  To get started, maybe we have to understand a little bit about why this is interesting  in the first place.  I think one of the aspects that makes the Apple Watch so interesting is just how ubiquitous  it is.  I'm wearing mine today, and if I could have some brief audience participation, just raise  your hand if you are wearing an Apple Watch right now.  Oh my God, that's more than I expected.  Thank you.  So yeah, we have this very ubiquitous, very common kind of nugget of compute tech, and  that is not just like a tiny computer that you wear 24-7.  We have smartphones for that, but it's also packed to the brim with interesting sensors.  So a modern Apple Watch can do geolocation using GPS.  It can measure your heart rate using two different heart rate sensors.  It can do activity recognition using motion tracking.  It can record electrocardiograms if you are into that.  It is also kind of always listening to you, though not to what you say, but the ambient  noise around you.  If you don't happen to be in the United States, it can even measure your blood oxygen saturation,  and it will also record your long-term skin temperature as you sleep, for example.  So right off the bat, we have this treasure trove of highly intimate health data and sensitive  information going on there.  But then also, the watch, of course, very tightly integrates with your phone or your  iPhone more specifically.  And using either Wi-Fi or Bluetooth, these can be used interchangeably here, Apple does  some wireless magic to just seamlessly transfer a lot of information between your devices.  And I think that includes things like instant messaging notifications, that includes all  of the health data that the watch collects and that is sent over to the iPhone so you  can look at it.  But it also includes things like contacts and calendar events and device settings and  pictures and so on and so forth.  Now, the question is, if Apple spends all of this time making this work seamlessly for  us and magically, why should we even have to care about this?  Why should we have to think about how this works in the background?  And I think we can look at that, again, from two different perspectives.  The first of which is looking back to all of this health information that is collected  by the watch and that is, of course, very sensitive.  And I know that there are some people out there who like to post the heart rate of their  most recent breakup publicly on social media for everyone to see.  But I, for one, think I am not the kind of person to do that.  And I suspect that most of you aren't either.  So I think one aspect of why we want to look into this is that we want to make sure that  this highly intimate data that our watch collects is kept secure and that we can understand  how Apple keeps that secure, who has access to it, who it is shared with, who it isn't  shared with, and how all of that is done internally.  But then there's also a second perspective.  And that is that Apple's ecosystem looks something like this.  You have a very slick user interface that lets you do a lot of things and most users  will probably be happy with that for the rest of their lives, right?  You can do everything you want to do and it looks pretty.  But this is a very small part of my soul, this kind of hacker instinct that says, okay,  this is a very beautiful walled garden that you've built here.  But I don't want to walk around in a walled garden, right?  I want to play in the mud.  I want to get messy.  I want to ask weird questions like, am I more likely to complete my activity goals on days  where I opened the weather app more than three times in the morning?  And that's a question that Apple can't answer.  Of course they can't answer it.  It doesn't make sense to answer it.  But I would like to really be able to use this device that I wear 24-7 more or less  if I want to use sleep tracking as well to the fullest and maybe go beyond what Apple  wants to allow me to do and go beyond what the UI offers and write raw SQL queries to  query all of the data that is gathered by the watch.  And so that's kind of the second approach.  On the one hand, we want to make sure that this is secure and your data remains secure.  But on the other hand, we also want to find out how we can kind of break out of this walled  garden, how we can play with it, how we can get creative and make this very cool, very  powerful device do things beyond Apple's wildest dreams of what we were expected to  do with that device.  And with that, I hope you are all sufficiently motivated to dive into a little bit of technical  detail on how this actually works between the watch and the phone, how data is sent  back and forth.  And we are going to look at this through the lens of health data synchronization.  So whenever my watch collects a new health measurement, that could be a heart rate measurement,  that could be that I start a workout on my watch or end a workout or just some background  measurement that the watch is always doing, the watch somehow has to inform my paired  iPhone that this new sample is available, it has to send it over, and then the phone  has to acknowledge that and somehow the two devices have to stay in sync.  The way that works is that the health daemons on both devices basically keep a local database,  an SQLite database that contains all of the health samples that either device collects.  And then they use a protocol called NanoSync to basically provide a very thin synchronization  layer between these two databases.  So in this case, once I started a workout and I started collecting samples for that  workout, the watch will send this NanoSync message that contains a change object.  And that change object then contains a collection of samples.  In this case, you can see a basal energy burn sample there that basically just says I burned  this many calories in the last, say, five minutes or so.  And then this is somehow wirelessly sent to the phone, and the phone can then process  that within the health daemon locally to keep the databases in sync, and it can then respond  with this sync status reply that says essentially, okay, yeah, I got your change, we are back  in sync, everything's fine.  But that's still very high level, right?  These are operations that the health daemons do kind of by themselves, and we have seen  nothing here of how this actually goes over the wire.  And what comes in there is Alloy.  Alloy is Apple's name for the main messaging bus that really drives all of the communication  going on between your Apple Watch and your iPhone.  So this is handled by the identity services daemon, and essentially what happens there  is that we have a collection of different messages, for example, one of the most prominent  is just a data message.  And these messages are exchanged over a couple of long-running TCP connections, it's basically  just a common TCP server, and these messages will contain a topic string, and that topic  string identifies which service on the watch or the phone this message is destined for  and should be delivered to.  And so in this case, for example, the watch will see that it has a new measurement available,  it will create this nano-sync message, it will pack that into an Alloy data message  with, in this case, the topic com.apple.private.alloy.health.sync.class.c.  And that is then sent over the air, and on the other end, on the phone end, the identity  services daemon receives that message, checks the topic, and sees, okay, this is a topic  that the health daemon is interested in, and then forwards the payload to the health daemon,  and that can then handle that in whichever way it likes.  Now just to show you what most of my actual research looks like, this is the protocol  structure for an Alloy data message.  You can see that we have space for a topic there, and then also every message has a UUID  and potentially a different UUID to identify replies to previous messages, and so on.  But I don't want to bother you with too much detail, so let's see how this is actually  sent wirelessly over the air in the end.  Now I already mentioned that the watch can use Wi-Fi and Bluetooth interchangeably, and  that actually does not make much of a difference for the higher-level communication at all.  So what Apple does to keep all of this Alloy communication secure is basically they build  a VPN tunnel, an IPSec tunnel, between your watch and your phone, and then all of the  higher-level communication is encased in that and is provided with authentication and encryption  using IPSec.  So on top of the Wi-Fi or Bluetooth encryption that we might already have, we have this additional  VPN tunnel that is being established using the Internet Key Exchange protocol, and then  data is carried over that using ESP, so it's a very basic, very regular VPN tunnel.  Now what you also see on this slide that I haven't talked about so far is Shoes.  Shoes is kind of the second big watch protocol, the second high-level protocol, and that is  what powers the Internet sharing feature.  So as you will know, if you have an Apple Watch, your Apple Watch can share, for example,  your phone's cellular connectivity over the Bluetooth connection, so you can use the  Internet on your watch even while you're on the go and not connected to a Wi-Fi network.  And the way this works is also basically just a TCP server that is running on the iPhone  within the Terminus daemon, and the watch can send a special request to that server  over that VPN tunnel that we've just seen that basically says, okay, I would like to  contact the weather API, and I would like to do that in the following network conditions.  So if I want to download a large binary file, for example, I might want to specify that  I only want to download this file if I'm connected over Wi-Fi and not if I'm on an expensive  cellular connection.  And then the phone can receive that request and process it and check it against the actual  network conditions that we are experiencing right now, and if the request can be fulfilled,  it will send some quick feedback back to the watch saying, okay, I accepted your connection.  By the way, I'm currently connected to a cellular network or whatever.  And then from that point onward, the phone basically becomes transparent to the watch.  So any byte that I send to this TCP connection that I've established will be forwarded to  the destination host in the internet, and any reply will be forwarded back to the watch  by the phone.  And that way the watch can kind of transparently use arbitrary internet connections, even if  it's not connected to Wi-Fi.  With that, we can kind of draw a high-level message flow, message handling diagram.  We have the terminus daemon, which is responsible for establishing this VPN tunnel that will  handle all further communication.  So that receives internet key exchange messages, sets up the tunnel.  Once that tunnel is set up, the actual payload data will be contained in ESP, encapsulated  security payloads, which are decrypted by the kernel, as you would do for any regular  IPsec connection as well.  And then the TCP traffic contained in this VPN tunnel will be received either by the  terminus daemon for the shoes protocol that we've just seen, or by the identity services  daemon for the main messaging between the two devices using Alloy.  And the identity services daemon will then just forward the contained payload data to  whatever service on the iPhone that is interested in that kind of message.  Now, with that, we have enough of a technical foundation to start talking about security,  which I think is what most of you are here for in the first place.  Looking back to that diagram we've just seen, we can start drawing in some trust boundaries.  We have the terminus daemon in an interesting position, because that is what actually handles  the unencrypted, unauthenticated data coming in, and everything that passes the terminus  daemon should then be part of the established VPN tunnel, within which we already have some  sort of trust, because it is encrypted and it is authenticated.  We can assume that that is only possible for a genuine paired device.  Then what is really interesting to me, I think, is the identity services daemon, because as  the main hub for all Apple Watch communication, this has a lot of implicit trust in the system.  The identity services daemon interacts with a huge quantity of services and binaries on  the rest of the system.  In that way, it has a lot of implicit control over many, many different features of the  phone, so that could very well be an interesting attack surface.  Then finally, of course, we have the actual destination services that provide the feature  that we are trying to use, for example, receiving health information, and so on.  These will be your average collection of iOS daemons and iOS binaries, but of course some  of them might also be particularly interesting, for example, in the case of the health daemon,  which has exclusive access to the health database on your device that you otherwise cannot get  information out of or into.  We've also seen this slide before, but this time looking at it from a security perspective.  We can already make one statement, which is that the Apple Watch does pretty well at security.  That is in large part thanks to this VPN tunnel that they establish on top of Wi-Fi or Bluetooth  transport encryption.  A lot of fitness trackers out there typically only rely on the encryption that comes with  Bluetooth, and I think here using this very established, very well understood standard  of IPSec, using very modern crypto, very strong crypto, provides an incredibly strong base  layer of security for all of the watch communication, because essentially once this tunnel is established,  as an outside attacker, you don't really have any way to get in.  This is really solid crypto.  This has been tested.  This is standard stuff that has been understood for decades at this point.  But looking at this slide, you might already see one possible avenue where we could get  into the system in some way, shape, or form as an unauthenticated attacker, and that is  the initial IKEv2 handshake.  IKEv2, as a key exchange protocol, by definition cannot use encryption or authentication in  all of its messages, because the whole point is to exchange key material.  So when I start the handshake, I don't have key material yet.  Now I also just told you that most of the security of the system comes from the fact  that they are using well-understood battle-tested standard protocols, like ESP and IPSec, and  all the same things apply to IKEv2.  So is that secure?  Well, it turns out that you can, as a vendor, define your own extensions to IKEv2 that is  usually used to signal particular feature support or version information.  And Apple makes very extensive use of that.  I've included a couple of the private Notify types that they define, and you can see that,  for example, device names or build versions are included there.  That would be a very common use case for that.  But there's also others.  And the way that Apple uses these is that they only include these private Notify types  in messages once the handshake is in a phase where I have authentication and encryption.  So once I have my key material established, IKEv2 will be encrypted, and at that point,  Apple uses all these private Notify payloads to communicate some settings and configuration  and so on.  Now the thing is that the excerpt from the standard that I've included on the slide for  you very clearly says that a Notify payload can appear in any message.  And that includes these initial messages that are neither authenticated nor encrypted.  And when we look at the private Notify types that Apple defines, we can see some that look  kind of interesting.  For example, the proxy Notify payload is used to configure the IP address and port of the  shoe server that is running on the iPhone.  So that is the port and IP that the watch will attempt to connect to for internet sharing.  Or in a similar way, the update Wi-Fi IP address payloads actually contain the entirety of  the Wi-Fi discovery mechanism of these devices.  So once my watch connects to my iPhone over Bluetooth, in the IKEv2 handshake, they will  include these payloads telling each other about their local Wi-Fi IP addresses.  And then later on, when we are outside of Bluetooth range, the watch can decide to fail  over to Wi-Fi using the address that I got in the initial Bluetooth IKEv2 handshake.  And now it turns out that, well, on the one hand, Apple continues to accept unencrypted  IKEv2 messages even after the key exchange has already been completed.  And I could and should encrypt all further messages.  And also, they do not check when they receive one of these private Notify payloads.  For example, a Wi-Fi IP address update, they don't check if this update has been received  in an encrypted context or an unencrypted context.  So what we can do here is we can take an existing Bluetooth connection, assuming that we can  somehow inject packets into that connection, right?  And we can take a IKEv2 heartbeat that is just sent every 10 seconds or so to keep the  connection alive, and we can just replace that with an unencrypted, unauthenticated  plain text message that contains a forged Wi-Fi IP address update.  And the watch will then receive that and accept it as if it was a regular part of the genuine,  legitimate communication.  And it will update its internal IP address that it associates with the iPhone accordingly.  And then if we just somehow move the devices out of Wi-Fi range or we start jamming or  we shield them or whatever, the watch will fail over to Wi-Fi, reaching out to our attacker-controlled  device.  And to me, that definitely feels unintentional.  That feels like something that you should not be able to do.  But I should also mention at this point that this doesn't let us do a lot of malicious  stuff really, because while the watch will reach out to our attacker-controlled device,  it still expects to complete the IKEv2 handshake.  And to do that, we would need key material from the iPhone.  There is, however, a different version of this attack.  This one is more theoretical, because I could not get it to work in a real-life setting.  But from looking at the code, that's my understanding of how things work and how things should work.  It's basically the same attack.  Just instead of the Wi-Fi IP address update, we are using a proxy update.  So we tell the watch that it should reach the shoes internet sharing proxy endpoint  at a different port than it usually does.  And in that way, we should be able to redirect all of this internet-bound traffic from its  genuine destination in the terminus daemon to an attacker-controlled app that we might  be able to place on the iPhone.  So that could be an unprivileged app that just listens on any arbitrary port.  And then when the watch sends its internet-bound traffic there, we are suddenly in a proxy  position for all of the watch's internet traffic.  And from then on, we could imagine that we could mount things like TLS downgrades attacks,  or maybe just log all of the traffic, see which hosts are contacted, how much data is  exchanged, stuff like that.  Okay.  With that, I am done with IKEv2 for now.  But surprise, there is another encryption layer that I didn't mention so far.  And that's called A over C. Apple uses A over C to protect particularly sensitive data.  Usually that just translates to health data.  And the way they do that is instead of using some sort of established standard, they really  homebrewed it here.  You can see that it looks kind of complicated.  What it does is essentially it uses the message protection framework, which is the same crypto  that iMessage uses, as a very complicated key encapsulation mechanism.  So in the end, we just generate a random AES key, and we encapsulate that in this top  part, and then we use that key to encrypt the actual health data that we are sending.  Now the iMessage crypto in the top part has been analyzed before.  There's a great paper on it by Garmin et al., and that paper also includes this very fun  figure that I did not want to keep from you.  But essentially what they found is that in the state that they looked at iMessage, iMessage  was vulnerable to replay attacks, it used malleable crypto, it had no forward secrecy  to offer at all, and they could even manage to decrypt arbitrary payloads by mounting  some sort of Oracle attack based on the fact that Apple uses gzip compression inside of  their ciphertexts, but I won't go into too much detail on that.  Their end conclusion was that this is very weird and custom crypto, and that in the long  term, Apple should probably replace that entirely with something more standard.  They did address some of these issues.  As of now, the replayability, for example, appears to be somewhat inelegantly fixed,  but fixed at least.  But it turns out that we don't even have to care about that.  We don't have to care about the weird iMessage crypto part, because there's an even weirder  part in the crypto that happens outside of this message protection framework, because  in the end, our actual health data is encrypted using plain AES CBC, cipher block chaining  mode with no authentication at all.  I would hope that in some of your heads, there are little alarm bells going off right now,  because I think many of you will have seen a diagram like that before, and there are  just some very interesting, very fun properties of cipher block chaining mode that allow us  to do weird things that we should probably not be allowed to do, and in particular, that  happens when we flip some bits in a given cipher text block.  So in this case, I flipped a couple of bits in the second cipher text block, and now,  because I slightly changed the input to the block cipher, kind of by definition, the output  of that block cipher will look completely random, right?  So the corresponding plain text block will decrypt to random garbage, but because in  the decryption process, I take the previous cipher text block and XOR it with the raw  decryption result of the next plain text block, these bit flips that I performed on the second  cipher text block will get reflected in the plain text of the third block, and that's  already enough to say, okay, we as an attacker are in some way able to manipulate the plain  text of an encrypted message without having the proper key material, and we are able to  do so in a somewhat targeted way, so that's already bad, but it's very different to point  at this and say AESCBC is bad and you shouldn't use it, which is true, and actually showing  that we can build a real attack out of this.  And so what I brought for you here is a real health sync plain text that I captured from  my Apple Watch.  There's my real health data in there somewhere, if you look close enough, and what you can  see is that this is basically a protobuf encoding that contains a couple headers, then there's  a heart rate sample, and then there's a bunch of active energy samples saying I burned this  many calories.  And each of these samples will have a random UUID that identifies that sample, and it also  has a type which identifies that this active energy sample, for example, is an active energy  sample and not something else.  Now if we put the corresponding cipher text on the other side, that still has the same  structure of course, the bytes are different because duh, it's encrypted, but now remembering  the previous slide and these bit flip shenanigans, we can start wondering what would happen if  we change this 74 byte to a 7B byte.  And now applying the same logic from the previous diagram, we know that the block that I made  this change in will decrypt to completely random garbage, like so.  But also the bit flip that I applied here will be reflected in the line below there  on the plain text.  And now crucially, because this random UUID perfectly aligns with the block size of the  cipher, this garbled block is still a valid random UUID, and so the message as a whole  remains valid, and all I have changed essentially is the type byte, which now is 05 instead  of 0A, and that makes this a heart rate sample and no longer an active energy sample.  And so in this way, given a somewhat reasonable best guess as to what the contents of a given  encrypted messages are, we can do targeted manipulation and essentially insert forged  health samples into the health database on a device.  Yeah.  I reported both of these issues to Apple.  I am very happy to announce that the first issue, the IKV2 handling issue has been fixed  in iOS, macOS, tvOS, and watchOS releases earlier this year.  And the second issue, the A over C issue, well, it remains out there.  Apple's position is that this is not really relevant, because you would have to already  compromise the VPN tunnel between the two devices, so it's really difficult to exploit  this in a real-world setting without an artificial jailbreak and insight into this VPN tunnel,  but I don't know.  You can keep that in mind.  Maybe it comes in useful for you someday, I don't know.  Now some security takeaways.  First up, I have standards exist for a reason.  The main reason why this architecture as a whole is so secure is that they use established  standards that have been battle-tested for many years and that use solid cryptography.  And that crypto will save you from many, many, many, many different attacks and makes this  whole system very resilient to outside attackers.  But also, crypto won't always save you, especially when you have to take into account how different  complex systems can interact.  In this case, we've seen that the way that Apple extends the IKEv2 standard, which in  itself is well-understood and well-tested, kind of introduces this subtle new vulnerability  that you can get into a situation where you handle input that you assume is trusted but  is really not trusted in all circumstances.  So really think about interactions of all of the systems that you build, and crucially,  if you ever want to roll your own crypto, think really, really, really hard about it.  Because it's difficult to get right, and you probably won't get it right on the first try,  but you kind of have to get it right on the first try, because then you're going to be  stuck with it for a long time for backwards compatibility reasons.  I think that's one of the core reasons why this A over C crypto is still in modern iOS  versions and modern watchOS versions.  And if you can at all manage to do so, just try to reduce complexity.  To illustrate that in the context of the Apple Watch, this is a list of all the alloy message  types.  What I've highlighted in green are the ones that really carry most of the actual payload  communication, and the other ones are also sometimes rarely used, but there's also some  in there that are just completely deprecated and not used any longer for many, many years.  And those I've highlighted in yellow.  And these here are referring to an entirely different encryption mechanism that Apple  used before they used this VPN tunnel between the two devices.  So before we had that, there apparently was an entirely different protocol around based  on off-the-record messaging.  And despite that not being in use for many, many years and many, many versions, the code  is still there.  And I would not be terribly surprised if someday someone found that some vulnerability stems  from this kind of long-abandoned code that still haunts these modern implementations  today.  And then just in general, the Apple Watch is incredibly complex.  And this is a list of most of the alloy message topics.  There are around 230 different message topics for different services.  And on the iOS side, there's 151 different binaries, different daemons, different services  involved with the Apple Watch communication.  And you can tell me that all of these 151 binaries do parsing exactly right and have  no memory corruption issues.  But I kind of find it hard to believe that.  So there's a lot of surface there for people to look into in the future.  But for the remainder of the talk, let's look into something a little bit more fun.  Because the second motivation that I mentioned in the very beginning of why this is interesting  for was that we want to use our devices in ways beyond what Apple expects us to use them  for.  And we kind of want to break free out of this walled garden.  And it turns out that I am not the only person thinking about this.  Because earlier this year, the United States has filed another antitrust complaint against  Apple as they like to do from time to time.  And this one, I think, addressed some very interesting issues that I also tend to agree  with.  So Apple identified that Apple really likes to cite security complaints or security fears  as reasons for not making their devices and their services more interoperable.  And I just thought that the quote was very nice that Apple selectively compromises privacy  and security interests when doing so is in Apple's own financial interest.  Such as degrading the security of text messages.  And that feels true to me.  Because Apple seems to care a lot about security when it comes to locking their systems down  and creating walled gardens.  But then suddenly when it comes to offering iMessage to Android users as well, the security  that might be gained by enabling all users to exchange messages suddenly is much less  of a concern.  Anyway, the same report goes on to mention the Apple Watch explicitly and identifies  it as part of the alleged smartphone monopoly that Apple holds in the U.S.  And also identifies how Apple kind of actively limits the way I can use a third party smartwatch  with an iPhone.  For example, in that I can only reply to text messages that I get on my watch if I'm using  an Apple Watch.  For third party watches, that functionality just isn't available.  In response to that report, there was a very nice headline about Apple saying that they  tried really, really hard to bring Android interoperability to the Apple Watch.  For three years, they said they tried.  And when I read this earlier this year, well, I didn't really buy it.  And I had kind of a good reason to not buy it.  Because I was sitting there in my office with my Apple Watch and with my Android phone running  my Android app that could talk to the Apple Watch just fine.  So this is WatchWitch.  It's an Android reimplementation of all of these protocols that I've talked about in  the talk so far.  That runs on Android and that is able to talk to your Apple Watch in just the same way that  an iPhone would.  And while it is a bit beyond the scope of my work to reimplement all 151 binaries and  features, I did manage to include support for a couple very cool smartwatch features.  So I can receive all of my health information that the watch collects.  I can sync that to a drop-in copy of the health database that I keep on the Android device  offline and encrypted.  I can also use shoes to have Internet sharing just as I would have with an iPhone.  And there, going beyond what Apple usually offers in the UI, I can also use this proxy  position that I have with the watch to build a really cool and really fine grained firewall  that allows me to decide on a host by host basis which connections I would like my watch  to make and which I want to forbid it from making.  And in that way, for example, I could disable all of Apple's logging services, logging hosts,  and very selectively enable, for example, the weather API so I can still use the weather  app on my watch.  And then I can also do text messaging.  So if you send me a message to my Android phone on Signal, watch which can receive that  message, forward it to the Apple watch, I'll get a ping there, I can reply to the message  on the watch, and the reply will be forwarded back to the Android phone and to the person  I'm texting with on Signal.  And at this point, I said earlier that I am not the type of person to share my health  information publicly, and I think I have to make a little exception for that today to  show you a bit of a demo.  I really hope that works.  We should have, yeah, the screen share from my Android phone.  It's not too high resolution, but it's going to have to do.  What I can do here is I can see the watch state, I can see open apps, I can see that  my watch is muted so I don't distribute you all with any reminders to stand up or move  around or anything.  And most importantly, I have, that's fine, I have the health view, which shows me in  even more detail than I would usually have on the iPhone, just all of the samples that  the watch collects.  Here you can see how it interprets me gesturing around as taking a lot of steps over the last  30 minutes or so.  We have a couple heart rate samples in there.  So, yeah, that can do some cool things.  We can also receive screenshots from the watch.  Yeah, just a couple fun features.  Now, thank you very much, but I am afraid I am going to have to add some caveats.  Because this is, we are not quite at the point where we can really replace the iPhone  in this connection.  Because as I've said earlier, we use both Wi-Fi and Bluetooth to communicate, and for  this demo, we are only using the Wi-Fi part.  We can do everything over Wi-Fi, but to do the initial setup, to do the initial pairing  process, we do need Bluetooth connectivity, and that's just a lot more annoying to work  with on an Android phone and to speak all of these proprietary Apple protocols.  I think it could be done.  We are working on getting it there, but it's not there yet.  So for now, we are using a jailbroken iPhone that runs a setup app.  That setup app will extract long-term key material from the phone and also instruct  the terminus daemon to send these Wi-Fi IP address updates, basically telling the watch  to reach my Android phone over Wi-Fi instead of my iPhone.  And then once I have done that initial setup, I can completely turn off my iPhone, right?  The iPhone will no longer be involved in the communication, and my watch will notice that  it has lost Bluetooth connectivity, it will reach out over Wi-Fi, it will connect to my  Android phone, and from there, just these two devices are talking and using all of these  services that we might want to reimplement in the same way that the real iPhone would.  Within the app, we kind of replicate a lot of the same structure that is present on iOS,  so we have servers for shoes and for alloy and for IKB2, and in the end, we just deliver  alloy messages to particular services, which are pretty straightforward reimplementations  of the original services found on iOS.  So we have a lot of the same infrastructure, and that can also be extended with new services  that then won't have to deal with all the plumbing behind it.  And because Apple likes so much to say that interoperability always comes at the cost  of security, we really tried to make this as secure as possible and maintain a comparable  security level as we find on iOS.  So all of the health data we receive and all of the long-term key material is stored on  the Android device in encrypted form using key material backed by the trusted execution  environment, which gives us a very similar level of protection compared to storing the  keys in the iOS key chain, for example.  Okay.  Some takeaways for interoperability.  People like to say it can't be done.  I think it can be done.  People also like to say that it cannot be secure.  I think that's also wrong.  I think it can be secure.  And what I also really want to stress is that this is not just about allowing Android users  to use the Apple Watch.  This is about really being in control of the devices that we own and being able to  create software that really suits our needs and not necessarily the needs of the device  manufacturer and that lets us do things that maybe go against even Apple's direct interests.  I'm sure that Apple would like to receive logging information from my watch, but maybe  I don't.  And why should I not be able to run my own software on there that does the things that  I want to do and not the things that Apple wants to do?  And so I think it's worth keeping that vision in mind of a world where we have deeper control  of our devices, where we can do what we want, where we can play in the mud if we like.  And I think it's worth pushing for that, for a better world in that sense.  Now, what can you expect in the next couple of months or so?  I have a paper ready in review.  And once that hopefully gets accepted, we will release the app that you've just seen  in the demo alongside with all of the source code.  We have a lot of tooling to support that.  We have Wireshark dissectors for some of these protocols coming up.  A lot of documentation, a lot of cool things in the pipeline.  We're also working to get this all working on Bluetooth without having any iPhone in  the loop at all.  So yeah, lots of interesting things.  And before I let you go, I brought one more thing in good Apple tradition.  Because over the course of my research, I've been writing a lot of parsing code for different  serialization formats.  And that can get really annoying.  And I often thought that it would be nice if I could just throw this into a website  and get a decode and see what's actually in there.  And so I thought, now that I've written all this code, I should just make that.  So I made ByteWitch, which is kind of the answer to the question, I have this long hex  string.  I think it contains a protobuf payload.  Can you just quickly show me what's going on in there?  And maybe your protobuf payload will also contain a binary plist nested within it.  It can also decode that.  And if within your binary plist, you happen to have an nskeed archive in there, it can  also decode that.  It's been very useful to me in the past couple weeks since I built this.  And I figured it might be kind of useful for some of you as well.  So you're welcome to give it a try.  It's also open source.  It's on GitHub.  If you have your own weird protocol that you want to add support for, you can go ahead  and give that a try.  Yeah.  Play around with it.  Okay.  And with that, I'm already at the end of the talk.  I'd be very happy to take questions from you.  Otherwise, you can also reach me via email or via this very freshly created Mastodon  account that does not have anything on it yet.  But it might in the future.  But it also might not have.  But I will probably respond to DMs on there.  So...  Yeah.  Thank you very much for the talk.  Do we have any questions?  We have time for some questions.  And there's a microphone.  So...  Yeah.  Hi.  Thank you for the talk.  It was super great.  Just one question regarding the AOC encryption.  You showed basically the property of its malleability.  And you reported that to Apple.  Did you explore whether the type field you were manipulating, if that could serve as an  oracle?  Because there might be invalid types where you get maybe feedback.  That's a very interesting idea, actually.  I haven't tried that.  But from my experience with the HealthSync service in particular, you in general don't  get a lot of feedback.  And the feedback, of course, is in itself encrypted.  And you can't decrypt that because we don't have access to keys.  So it is possible that you might be able to mount something there by observing differences  in response length or getting a response or not getting a response.  But I haven't looked into that.  Okay.  Thanks.  Hi.  Really nice talk.  Quick question.  So did you jailbreak the Apple Watch itself?  No.  No.  The Apple Watch is unmodified.  I think there is a jailbreak for the Apple Watch out there.  But it's seven years old at this point.  So if you have an Apple Watch 2 or something, you might be able to jailbreak it.  But since then, there have been no public jailbreaks of the Apple Watch.  So all of this is working with the Apple Watch just running stock watchOS.  But to intercept the communication, did you jailbreak the iPhone as well?  Can you repeat that?  To intercept the communication, did you jailbreak the iPhone?  The iPhone is jailbroken, yes.  Okay.  That's probably how you're intercepting the Bluetooth messages using Frida or something,  right?  Yeah.  Yeah, yeah, yeah.  Exactly.  Yeah.  Okay.  That's right.  Sounds good.  Thank you.  Any other questions?  Maybe I have one.  So you told about the notification, the custom notification messages with the IKEY.  Did you do any fuzzing with that?  Because I thought, okay, that's an interesting attack surface, even for the iPhone part where  it accepts unauthenticated messages that are sounding really interesting, like IP data,  configuration data.  Yeah.  Did you do any fuzzing or other testing with that?  Or is this maybe still an open project?  No, not yet.  That's still out there.  You can look at it if you like.  So I do hear that this issue of accepting these notification payloads in context where  you shouldn't has been fixed, but that's still definitely an attack surface that you can  look into, for sure.  Cool.  All right.  If there are no more questions, then we have a short break where we hook up the next speaker.  Please give another round of applause.  Thank you very much.  Thank you very much.